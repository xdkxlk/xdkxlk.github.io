title: 面试
author: xdkxlk
tags: []
categories:
  - 面试
date: 2018-12-17 15:57:00
---
# TCP/Http
## 5层结构
![upload successful](/img/a1c0oAx2XK2McoyqwdVD.png)
- 物理层
- 数据链路层  
在原始的物理线路上传输数据信号是有差错的。  
设计数据链路层的主要目的就是在原始的、有差错的物理传输线路的基础上，采取差错检测、差错控制与流量控制等方法，**将有差错的物理线路改进成逻辑上无差错的数据链路**，向网络层提供高质量的服务。  
从网络参考模型的角度看，物理层之上的各层都有改善数据传输质量的责任，数据链路层是最重要的一层  
**数据链路层仅能实现无比特差错的传输，但不提供可靠传输**  
数据链路层的差错控制: 收到的帧并没有出现比特差错，只实现无比特差错传输，不提供可靠传输  
无比特差错与无传输差错区别：无传输差错还包括帧丢失、帧重复、帧失序等。
- 网络层  
主要协议：IP，ARP  
IP地址在网络层定义，用于标识两台电脑
- 传输层  
主要协议：TCP，UDP  
端口在传输层定义，用于标识进程
- 应用层  

## 输入网址后的一系列事情
- 查询DNS，获得域名对应的IP
	- 浏览器搜索自己的DNS缓存
    - 搜索操作系统的DNS缓存
    - 读取本地HOST文件
    - 发起一个DNS的系统调用
    	- 宽带运营商查看本身缓存
        - 运营商服务器发起DNS查询
- 浏览器获得对应IP之后，发起HTTP三次握手
- TCP/IP建立起来之后，开始发送HTTP请求
- 服务器收到请求，返回HTML页面代码
- 浏览器拿到HTML代码进行渲染

![upload successful](/img/CkmvH0SrfG0J3gsT1132.png)

## Http的组成
![upload successful](/img/k1A8yZOFuLZ5Q9SilOb2.png)

![upload successful](/img/4zjd13L4o4m9bZVAo9Re.png)

## 状态码
![upload successful](/img/Qvh5RxjdzmMna95xB1RE.png)

![upload successful](/img/noUNgWWaMa7Mp0F3pEXK.png)

## DHCP
![upload successful](/img/CH1ys63FBcS8reiXYCIe.png)

# JVM
## 内存模型
[Java8内存模型—永久代(PermGen)和元空间(Metaspace)](https://www.cnblogs.com/paddix/p/5309550.html)  
根据 JVM 规范，JVM 内存共分为虚拟机栈、堆、方法区、程序计数器、本地方法栈五个部分
- 虚拟机栈  
**每个线程私有**，随着线程的创建而创建。栈里面存着的是一种叫“栈帧”的东西，每个方法会创建一个栈帧，栈帧中存放了局部变量表（基本数据类型和对象引用）、操作数栈、方法出口等信息。栈的大小可以固定也可以动态扩展。当栈调用深度大于JVM所允许的范围，会抛出**StackOverflowError**的错误
- 本地方法栈  
与虚拟机用到的 Native 方法相关
- PC寄存器  
JVM支持多个线程同时运行，**每个线程都有自己的程序计数器**。倘若当前执行的是 JVM 的方法，则该寄存器中保存当前执行指令的地址；倘若执行的是native 方法，则PC寄存器中为空。
- 堆  
堆内存是 JVM **所有线程共享**的部分，在虚拟机启动的时候就已经创建。所有的对象和数组都在堆上进行分配。这部分空间**可通过 GC 进行回收**。当申请不到空间时会抛出 **OutOfMemoryError**
- 方法区  
方法区也是**所有线程共享**。主要用于存储类的信息、常量池、方法数据、方法代码等。方法区逻辑上属于堆的一部分，但是为了与堆进行区分，通常又叫“非堆”

PermGen & Metaspace  
**方法区是JVM的规范，而这两个是它的一种实现**  
最大的区别在于：**元空间并不在虚拟机中，而是使用本地内存。**因此，默认情况下，元空间的大小仅受本地内存限制
- 默认情况下Metaspace会自动增加其大小（直到底层操作系统提供的内容）
- 删除PermGen并不意味着您的类加载器泄漏问题已经消失

## 类加载机制
![upload successful](/img/k108zeoEofBs0ZS7UTp5.png)

- Bootstrap类加载器 – JRE/lib/rt.jar
- Extension类加载器 – JRE/lib/ext或者java.ext.dirs指向的目录
- Application类加载器 – CLASSPATH环境变量, 由-classpath或-cp选项定义, 或者是JAR中的Manifest的classpath属性定义

# 基础
## Map
- HashMap  
	- K，V都可以为null
    - jdk1.7以前put是插入到链表头部，jdk1.8是尾部（没有调整成红黑树的时候）
    - resize的时候，会遍历所有key并重新hash
    - 链表状态 get 最坏是O(n)，put 最坏是O(n)。(如果所有的hash值都一样且需要遍历链表)
    - 红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4
- TreeMap  
	- K不可为null，V可以为null
    - 红黑树
- ConcurrentHashMap   
K，V都不可以为null

# 数据库
## 锁
![upload successful](/img/zJaTAM691EudkRICrdA7.png)

```sql
SELECT ... LOCK In SHARE MODE;
SELECT ... FOR UPDATE;
```
## 索引
innodb引擎有一个特殊的功能叫做自适应哈希索引，当innodb注意到某些索引值被使用的非常频繁时，它会在内存中基于btree索引之上再创建一个哈希索引，这样就让btree索引也具有哈希索引的一些优点，比如：快速的哈希查找，这是一个全自动的，内部的行为，用户无法控制或者配置，不过如果有必要，可以选择关闭这个功能（innodb_adaptive_hash_index=OFF，默认为ON）。

```sql
## 前缀索引
alter table city_demo add index (city(6));

## 索引添加示例
ALTER TABLE `table_name` ADD [UNIQUE] INDEX `index_name`(`col1`, `col2`) USING BTREE;

ALTER TABLE table_name ADD PRIMARY KEY (column_list)
```

## 为什么MyISAM会比Innodb的查询速度快
https://blog.csdn.net/fei33423/article/details/72229677  
主要是因为一个聚簇一个非聚簇  
1）数据块，INNODB要缓存，MYISAM只缓存索引块，  这中间还有换进换出的减少；  
2）innodb寻址要映射到块，再到行，MYISAM记录的直接是文件的OFFSET，定位比INNODB要快
(phil 注: myisam 更新频率低,所以 索引变更少 . 所以允许每次更新 即更新主索引,也更新付索引,更新 offset)  
3）INNODB还需要维护MVCC一致；虽然你的场景没有，但他还是需要去检查和维护
MVCC (Multi-Version Concurrency Control)多版本并发控制  

**所以，读写分离的时候，读数据库可以使用MyISAM**

## 其他
- 在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格。



# 红黑树
## 红黑树的定义
红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求:
- 性质1. 节点是红色或黑色。
- 性质2. 根是黑色。
- 性质3. 所有叶子都是黑色（叶子是NIL节点）。
- 性质4. 每个红色节点必须有两个黑色的子节点。(从每个叶子到根的所有路径上不能有两个连续的红色节点。)
- 性质5. 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。

## 红黑树插入后调整原则
- 由于红黑树的性质 5 被破坏后恢复极其复杂，所以红黑树插入算法的第一个原则是插入后，性质 5 不变，所以，我们要把**新插入的节点涂为红色。**
- 新节点为红色，则可能产生的冲突只有一种，那就是刚好他的父节点也为红色。
- 递归下去 ， 我们在调整当前局面时，决不能破坏性质 5 ，在保持每条分支黑色节点数量不变的情况下，将红红冲突一直向上移，直到根节点变为红色，此时把根节点涂黑，然后就可以了。
- 局部分支调整策略，其实就是能变颜色就变颜色，不能变得就左旋和右旋。

# 堆
添加删除元素主要是一个调整的过程，为 O(logN)  
构建是一个自低向上的循环过程，为 O(N)  
查找和遍历就跟数组一样，为 O(N)，（因为它仅仅只是上面的元素大于或小于下面的元素）  
堆排序的时间复杂度，O(NlogN)，（N个元素交换，调整是logN）

# 线程
## 状态
- NEW
- RUNNABLE
- BLOCKED
- WAITING
- TIMED_WAITING
- TERMINATED

## 基本方法
- sleep会让出CPU
- yield会让出CPU，告诉CPU不急用，但是CPU可以忽略这个建议

## synchronized
- 任意一个对象都有一个锁和等待队列
- 可重入的
- 可保证可见性

## Collection.synchronizedXXX
- 是在所有容器方法上都加上synchronized来实现安全的
- 虽然单个操作是线程安全的，但是迭代并不是
- 性能较差，应该使用 `CopyOnWriteArrayList`, `ConcurrentHashMap`, `ConcurrentLinkedQueue`, `ConcurrentSkipListSet`

## notify/notifyAll/waite
- 通过interrupt结束线程
```java
Thread t = new Thread(() -> {
	// isInterrupted 判断是否被interrupt了
    while (!Thread.currentThread().isInterrupted()) {
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
        	// 因为InterruptedException是受检异常，所以必须处理
            // 又因为 run 方法不能抛出异常，所以抓住异常之后，重设终断标志位
            // 一些清理操作
            Thread.currentThread().interrupt();
        }
    }
    // 一些清理操作
    System.out.println("interrupted");
});
```
- 必须在 synchronized 里面

## AtomicInteger
- 使用了自旋锁（例如，incrementAndGet）如果通过CAS设置值失败了，那么就再次尝试，直到成功。这是一种乐观的锁
	- synchronized是得不到锁就进入队列等待，有上下文切换的开销
    - 自旋锁没有上下文切换的开销，但会占用CPU
    
## ABA问题
- 当前线程为A，一个B线程先将值x改成y然后又改回成x，这个时候CAS无法分辨是否发生了变化
- 可以使用AtomicStampedReference解决，compareAndSet向对于普通的Atomic多了一个时间戳

## ReentrantLock
- ReentrantLock 依赖于 LockSupport 的一些方法
- LockSupport.park 放弃CPU，进入WAITING状态
- park不同于yeild，yeild仅仅只是告诉CPU可以让出CPU，但自己本身其实是可以运行的；park会直接放弃被调度
- 主要实现方法：
	- 基于AQS
	- 尝试加锁的时候，主体是一个死循环，首先检查当前节点是不是第一个等待的节点，如果是且可以获得锁，则返回，否则就等待
- 默认是非公平的，公平和非公平的主要区别是，如果是公平的，那么如果在等待队列中，不存在其他等待时间更长的线程，才会获得锁
- **注意，即使设置fair为true，不带参数的tryLock也是不公平的**
- ReentrantLock 同 Condition 配合使用

## CopyOnWriteArrayList/Set
- CopyOnWriteArraySet基于List实现
- 读不需要锁，读写可以并行，写需要加锁不能并行
- 迭代器不允许修改操作，不会抛出ConcurrentModificationException
- CopyOnWriteArrayList实现原理： 底层是一个数组，每一次修改都是先复制原来的数组到一个新的数组，在新的数组里面修改，修改完了，直接将原来的数组的引用指向新的数组。所以，如果边写边读，还没有读到的数据是可以被访问到的，修改的效果是可以反映出来的

## ConcurrentHashMap
- 对应于非线程安全的 HashMap
- 基于分段锁。读完全并行，写一定程度上并行
- 和Collections.synchronizedMap相比，迭代不需要加锁，不会抛出ConcurrentModificationException
- 弱一致性。写的数据不一定马上反映到迭代器里面，如果发生在已经遍历过的部分就不会反映出来

## 并发版本的Set
- 没有内置提供
- `Collections.newSetFromMap(new ConcurrentHashMap<>());`

## ConcurrentSkipListMap/ConcurrentSkipListSet
ConcurrentSkipListSet基于ConcurrentSkipListMap实现，对应于TreeMap和TreeSet，虽然不是通过树来实现的，但是它两也是有序的  
下面就只谈ConcurrentSkipListMap
- 内部数据结构是跳表
- 没有锁，所有操作都是无阻塞的，基于CAS实现，所有操作都可以并行
- 迭代器不会抛出ConcurrentSkipListMap，弱一致性
- 一些方法，如putAll，clear 不是原子的
- size() 需要遍历所有元素，时间复杂度为O(n)，而且遍历结束后大小可能已经变了，在并发环境下没有什么用

## BlockingQueue
它的实现有
- LinkedBlockingQueue 链表，可以指定长度，但默认无界
- ArrayBlockingQueue 数据，有界
- PriorityBlockingQueue 基于堆，底层是数组，无界
- SynchronousQueue 没有存储空间，有可以用的线程则运行，没有就阻塞

## Semaphore
- 不可重入

# ClassLoader



# 基于Redis的定时任务是如何实现的
- 实现 `ImportBeanDefinitionRegistrar` 从 `AnnotationMetadata` 获得SpringBoot启动类basePackage
- 使用 `reflections` 扫描有 `DelayTaskMethod` 注解的方法，并解析保存下来
	- 数据结构
    - clazzName => TaskWrapper
    - TaskWrapper: taskName => method 和 clazzName
- 提交任务的时候，的参数 clazzName, taskName, 参数，时间
- 将参数通过 `ByteArrayOutputStream`, `ObjectOutputStream` 序列化为 `byte[]`
- 将任务保存到redia
	- 保存方式
    - zset: taskId => 执行时间戳 (命令：ZADD key score member)
    - hash: taskId => 序列化的TaskWrapper`byte[]` (命令: HSET key field value )
- 扫描任务
	- 使用spring的定时框架，定时执行任务扫描
	- `ZRANGEBYSCORE key -inf 当前时间戳 0 10` 找到要执行的任务
- 执行任务流程
	- 因为是微服务，所以有可能有同时找到了同一个任务，所以，需要加锁
    - `SET lockKey lockValue EX 3 NX` 加锁，`lockValue` 为 `随机数`
    - `MULTI` 开启事务
    - `HGET key taskId` 拿到`byte[]`数组
    - `ZREM key taskId` 移除任务
    - `HDEL key taskId`
    - 通过反射执行代码
    	- 从`ApplicationContext`拿到Bean
        - 执行method
    - `EXEC` 提交事务
    - finally, `EVAL "if (redis.call('get', KEYS[1]) == ARGV[1]) then return redis.call('del', KEYS[1]) else return 0 end" 1 lockKey lockValue` 解除锁
    
# Redis-MySQL缓存的思考
- 查询的时候更新缓存，修改的时候删除缓存
- 先删除缓存，再更新数据库，(再删除缓存)
	- 如果先写数据库，再删除缓存，如果缓存删除失败，那么缓存里面就是脏数据
    - 如果先删缓存，再删数据库，就算数据库修改失败了，大不了下一次缓存不命中，再查一次
    - 为什么是删除缓存而不是更新缓存？因为，如果先缓存更新成功了，数据库更新失败了，那么缓存里面的数据就和数据库不同了
- 在先删除缓存，再更新数据库的前提下，为什么最后还要再删一次缓存  
	- 如果要更大程度的保证数据的一致性，那么就可以这样。
	- 假设两个线程A, B，A更新数据，B查询数据
    - A先淘汰了缓存
    - 这时候B查询，看见缓存里面没有，将原来的数据放入了缓存
    - 然后这时候A才更新数据库，这个时候，数据库就和缓存不一样了
- 缓存都需要设置一个失效时间（除非特殊情况，比如地区划分这种）  
设置失效时间在一定程度上也保证了Redis-MySQL数据的一致性
- 缓存穿透
	- 查询本来就没有的数据造成直接落在数据库上
    - 解决方法1：缓存为null的数据，当然这种为null有可能是系统故障，所以它的过期时间应该设得比较短
    - 解决方法2：使用布隆过滤，redis的`setBit`, `getBit`可以实现布隆过滤。对于数据的删除布隆过滤不是很好解决，可以给这个布隆过滤器设置一个过期时间
- 缓存雪崩
	- 由于设置了过期时间，所以，又可能某个时间缓存都过期了，然后全部都落在了数据库上
    - 一个简单的方法：在基础的过期时间上面在加一个随机的offset
    - 加锁的方法：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待
- 缓存击穿
	- 热点数据的缓存失效的时候，大量请求落在数据库上
    - 解决方法1:
    	- 发现为null，尝试对这个key加锁
        - 如果加锁成功，那么这个线程从DB获取数据并设置缓存
        - 如果加锁失败，那么这个线程等待一会儿再尝试从缓存获取数据，直到获得数据
        - 使用这种方法，会出现很多线程等待一个线程完成缓存更新的情况
    - 解决方法2:
    	- 在物理层面不设置缓存的过期时间
        - 每一个key有一个逻辑的过期时间，这个时间保存在redis中
        - 当查询这个key的时候，如果缓存里面有，那么就返回这个值
        - 同时，在返回之前对于过期时间进行检查，如果发现过期了，那么在子线程中异步的刷新缓存。
        	- 步骤：
        	- 尝试加锁，如果加锁失败，那么线程结束
            - 加锁成功，那么就更新缓存
        - 使用这种方法，会在缓存过期了，后台线程还没有来得及刷新缓存的时候会出现脏数据，但是性能上更好
        
# Redis主从，哨兵，集群
## 主从
```shell
SLAVEOF 127.0.0.1 6379
```
```
min-slaves-to-write	3	# 3个或3个以上从数据库连接主数据库的时候主数据库才可写
min-slaves-max-lag	10	# 从数据库最长失去连接的时间-秒
```
**主库崩溃后恢复的执行步骤**
```shell
# 在从库
SLAVEOF NO ONE
# 主库恢复后
SLAVEOF 从库ip port
```
## 哨兵
![upload successful](/img/t82eV37gY2H12CtFasxO.png)

- 首先配置主从数据库 `SLAVEOF`
- 新建一个`sentinel.conf`
```
sentinel monitor mymaster 127.0.0.1 6379 1
```
- redis-sentinel sentinel.conf

- 多个哨兵之间可以相互监督
- 当发现有主库down掉后，这几个哨兵会通过raft选出一个leader
- 由哨兵leader选择一个从库提升称为主库

## 集群

# Redis持久化
## RDB
```
save 900 1	# 900秒之后至少有1个key被修改，就快照
save 300 10	# 300秒之后至少有10个key被修改，就快照
save 60 10000	# 60秒之后至少有10000个key被修改，就快照
```
`BGSAVE`, `SAVE`
## AOF
`BGREWRITEAOF`


# 算法
## 时间复杂度为O(1)的LRU算法
https://blog.csdn.net/qq_32459653/article/details/82766468  
大体思路：  
使用双向链表和map，双向链表存实际的数据，map里面存key到链表的node的映射  
map中存放key -value(node)对，查找时可以通过key快速定位到value  
value存放的是node节点，所有的value，都是双向链表中一个node。  
如果满了，删除时直接移除尾部节点即可，为简化操作，链表自带头节点head和尾节点tail  
查询时，先通过map拿到node，如果拿到了，那么就将这个node放到链表的最前面