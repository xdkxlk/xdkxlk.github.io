<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kafka 原理总结]]></title>
    <url>%2F2018%2F11%2F20%2FKafka-%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[整体架构 名词解释 Broker消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群 Controller控制器其实就是一个broker，除了具有一般的broker的功能之外，还负责分区首领的选举 TopicKafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic Producer消息生产者，向Broker发送消息的客户端 Consumer消息消费者，从Broker读取消息的客户端 ConsumerGroup每个Consumer属于一个特定的Consumer Group，一条消息可以发送到多个不同的Consumer Group，但是一个Consumer Group中只能有一个Consumer能够消费该消息 Partition物理上的概念，一个topic可以分为多个partition，每个partition内部是有序的 Segment在物理上，一个partition的保存是由很多个segment文件组成的 保证 生产者发送到特定topic partition 的消息将按照发送的顺序处理。 也就是说，如果记录M1和记录M2由相同的生产者发送（成功发送到了broker），并先发送M1记录，那么M1的偏移比M2小，并在日志中较早出现（但这也意味着，如果有多个partition，这多个partiton之间的消息的顺序并不保证，而且实际情况下，由于可能出现的网络延迟和重试机制，需要一定的配置才能保证顺序） 一个消费者实例按照日志中的顺序查看记录 对于具有N个副本的主题，我们最多容忍N-1个服务器故障，从而保证不会丢失任何提交到日志中的记录（ISR） Topic &amp; Partition对于每一个topic， Kafka集群都会维持一个分区日志，每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。追加是直接追加到partition的尾部，顺序写入，所以，写入的速度是很快的。每一条消息被发送到broker中，会根据partition规则选择被存储到哪一个partition。如果partition规则设置的合理，所有消息可以均匀分布到不同的partition里，这样就实现了水平扩展。（如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个topic的性能瓶颈，而partition解决了这个问题）默认的partition的数目在 server.properties 配置，默认为11234# The default number of log partitions per topic. More partitions allow greater# parallelism for consumption, but this will also result in more files across# the brokers.num.partitions=1 生产者重要配置元数据请求生产者要自己负责把消息发送到正确的broker上面。直接发送数据到主分区的服务器上，不需要经过任何中间路由。位置通过元数据请求获得，客户端一般会将这些信息缓存起来，并时不时的刷新元数据（通过 metadata.max.age.ms 配置）。如果客户端收到了“非首领”错误，那么在重新尝试发送的时候，会先刷新元数据。 顺序保证kafka支持消息的重试，由 producer的 retries 控制，默认为0。若设置大于0的值，则客户端会将发送失败的记录重新发送，尽管这些记录有可能是暂时性的错误。请注意，这种 retry 与客户端收到错误信息之后重新发送记录并无区别。还有一个配置是 max.in.flight.requests.per.connection 默认为5。代表在发生阻塞之前，客户端的一个连接上允许出现未确认请求的最大数量。所以，如果在某些场景下，要求消息是有序的，那么这种场景下消息是否写入成功也很关键。所以，retries 不建议设为0。又由于重试的原因，max.in.flight.requests.per.connection 应该设为1，保证不会在重试的时候，后面的消息先发送成功了。但是这样的配置会严重影响生产者的吞吐量最终配置12retries = 3 #设为大于0的数字max.in.flight.requests.per.connection = 1 消费者重要配置pull &amp; pushkafka采用的策略是：producer 把数据 push 到 broker，然后 consumer 从 broker 中 pull 数据。所以，消费者要不停的进行轮询消费者采用pull的原因： 当消费速率低于生产速率时，push会使consumer不堪重负（本质上类似于拒绝服务攻击） pull-based 系统有一个很好的特性， 那就是当 consumer 速率落后于 producer 时，可以在适当的时间赶上来 push-based producer拿不准消费者能处理多大的数据。是一次发送一条数据呢，还是一次性发多条数据呢 pull-based consumer 总是将所有可用的（或者达到配置的最大长度）消息 分区和消费者在一个群组中，一个分区最多对应一个消费者，所以如果同一个群组中的消费者大于分区的数量，那么就会有消费者处于闲置状态，所以，不要让消费者数量超过主题分区的数量 再均衡分区的所有权由一个消费者转移到另一个消费者，这样的被称为再均衡。再均衡期间，整个群组会有一小段时间不可用，同时，分区重新分配给另一个消费者之后，消费者当前的读取状态会丢失（要做到安全的再均衡，offset提交） 触发条件 组成员发生变更(新consumer加入组、已有consumer主动离开组或已有consumer崩溃了——这两者的区别后面会谈到) 订阅主题数发生变更——这当然是可能的，如果你使用了正则表达式的方式进行订阅，那么新建匹配正则表达式的topic就会触发rebalance 订阅主题的分区数发生变更 加入过程消费者想群组协调器（它其实就是一个broker）发送 JoinGroup 请求，第一个加入群组的消费者成为“群主”。群主从协调器那儿获得成员的列表，并负责给每一个消费者分配分区。kafka将分区的分配的权利下放给消费者，提高了扩展性。 分配策略由 partition.assignment.strategy 指定，默认是 range 还有一个 roundRobin 策略。 rangeC1、C2订阅T1、T2，每个主题又3个分区。那么C1可能被分为T1、T2的0、1两个分区，C2分为T1、T2的2分区 roundRobin这个就是把主题的分区逐个分配给消费者，各个消费者的分区数量都会差不多（最多差一个分区） 消息交付语义 At most once——消息可能会丢失但绝不重传。 At least once——消息可以重传但绝不丢失。 Exactly once——这正是人们想要的, 每一条消息只被传递一次。 在kafka中分为生产者和消费者两个部分 生产者如果一个 producer 在试图发送消息的时候发生了网络故障， 则不确定网络错误发生在消息提交之前还是之后。0.11.0.0 之前的版本中, 如果 producer 没有收到表明消息已经被提交的响应, 那么 producer 除了将消息重传之外别无选择。 这里提供的是 at-least-once 的消息交付语义。从 0.11.0.0 版本开始，broker 给每个 producer 都分配了一个 ID ，并且 producer 给每条被发送的消息分配了一个序列号来避免产生重复的消息（幂等性）。（Exactly once）同时，也是从 0.11.0.0 版本开始, producer 新增了使用类似事务性的语义将消息发送到多个 topic partition 的功能，要么所有的消息都被成功的写入到了 log，要么一个都没写进去（Exactly once）但是如要实现幂等性和事务还需要其他的配置 消费者Consumer 先读取消息，然后将它的位置保存到 log 中，最后再对消息进行处理。（at-most-once）Consumer 可以先读取消息，然后处理消息，最后再保存它的位置。（at-least-once）在许多应用场景中，消息都设有一个主键，所以更新操作是幂等的（相同的消息接收两次时，第二次写入会覆盖掉第一次写入的记录）。 如何实现 exactly once ? 当从一个 kafka topic 中消费并输出到另一个 topic可以使用事务型 producer 写入外部系统的应用场景解决这一问题的经典方法是在 consumer offset 的存储和 consumer 的输出结果的存储之间引入 two-phase commit。（这个后面再写写代码研究） Replication创建副本的单位是 topic 的 partition ，正常情况下， 每个partition都有一个 leader 和零或多个 followers 。分为首领副本(leader) 和 跟随者副本(followers) 首领副本 处理所有的读写操作 维护ISR列表（搞清楚哪些跟随着跟自己的数据是同步的） 跟随者副本像普通的 consumer 那样从 leader 节点那里拉取消息并保存在自己的日志文件中，且这些请求是有序的。例如，先请求消息1，接着请求消息2，在收到2这个消息的请求之前，是不会发送消息3的。 判断节点是否存活 节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接。 如果节点是个 follower ，它必须能及时的同步 leader 的写操作，并且延时不能太久。 如果有节点挂掉了, 或是写超时, 或是心跳超时, leader 就会把它从同步副本列表（ISR）中移除。 同步超时和写超时的时间由 replica.lag.time.max.ms 配置确定。 Quorums，ISR，首领副本（Leader）选举Quorum如果选择写入时候需要保证一定数量的副本写入成功，读取时需要保证读取一定数量的副本，读取和写入之间有重叠。这样的读写机制称为 Quorum。这种权衡的一种常见方法是对提交决策和 leader 选举使用多数投票机制。Kafka 没有采取这种方式，但是我们还是要研究一下这种投票机制，来理解其中蕴含的权衡。假设我们有2f + 1个副本，如果在 leader 宣布消息提交之前必须有f+1个副本收到 该消息，并且如果我们从这至少f+1个副本之中，有着最完整的日志记录的 follower 里来选择一个新的 leader，那么在故障次数少于f的情况下，选举出的 leader 保证具有所有提交的消息。这是因为在任意f+1个副本中，至少有一个副本一定包含 了所有提交的消息。该副本的日志将是最完整的，因此将被选为新的 leader。这个算法都必须处理许多其他细节（例如精确定义怎样使日志更加完整，确保在 leader down 掉期间, 保证日志一致性或者副本服务器的副本集的改变），但是现在我们将忽略这些细节。(Zookeeper)这种大多数投票方法有一个非常好的优点：延迟是取决于最快的服务器。也就是说，如果副本数是3，则备份完成的等待时间取决于最快的 Follwer 。“少数服从多数”的方式也有一些劣势，为了保证leader选举的正常进行，它所能容忍的失败的follower数比较少，如果要容忍1个follower挂掉，那么至少要3个以上的副本，如果要容忍2个follower挂掉，必须要有5个以上的副本。在一个系统中，仅仅靠冗余来避免单点故障是不够的，但是每写5次，对磁盘空间需求是5倍， 吞吐量下降到 1/5，这对于处理海量数据问题是不切实际的。这可能是为什么 quorum 算法更常用于共享集群配置（如 ZooKeeper ）， 而不适用于原始数据存储的原因。 ISRKafka 动态维护了一个同步状态的备份的集合 （a set of in-sync replicas）， 简称 ISR ，在这个集合中的节点都是和 leader 保持高度一致的，只有这个集合的成员才有资格被选举为 leader（unclean.leader.election.enable=false）。 在这种模式下，对于f+1个副本，一个Kafka topic能在保证不丢失已经commit消息的前提下容忍f个副本的失败。而选择哪个作为新的leader是由controller来决定的 复制原理和同步方式对于每个partition，有HW，和 LEOLEO，LogEndOffset的缩写，表示每个partition的log最后一条Message的位置。HW是HighWatermark的缩写，是指consumer能够看到的此partition的位置。对于leader新写入的消息，consumer不能立刻消费，leader会等待该消息被所有ISR中的replicas同步后更新HW，此时消息才能被consumer消费。这样就保证了如果leader所在的broker失效，该消息仍然可以从新选举的leader中获取。对于来自内部broker的读取请求，没有HW的限制。由此可见，Kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower都复制完，这条消息才会被commit，这种复制方式极大的影响了吞吐率。而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下如果follower都还没有复制完，落后于leader时，突然leader宕机，则会丢失数据。而Kafka的这种使用ISR的方式则很好的均衡了确保数据不丢失以及吞吐率。 Unclean leader 选举: 如果节点全挂了？unclean.leader.election.enable默认为false请注意，Kafka 对于数据不会丢失的保证，是基于至少一个节点在保持同步状态，一旦分区上的所有备份节点都挂了，就无法保证了。 等待一个 ISR 的副本重新恢复正常服务，并选择这个副本作为领 leader （它有极大可能拥有全部数据）。 选择第一个重新恢复正常服务的副本（不一定是 ISR 中的）作为leader。 分区分配 kafka要尽量保证在broker之间平均的分配副本 确保每个分区的副本在不同的broker上 如果为broker指定了机架，那么尽量把每一个分区副本放在不同的机架上 现有6个broker，打算创建一个包含10个分区的主题，且复制系数为3，那么kafka就有30个分区副本。 没有配置机架的情况 先随机选择一个broker(4) 使用轮询方式给每个broker分配分区来确定首领分区的位置首领分区0 -&gt; broker4，首领分区1 -&gt; broker5，首领分区2 -&gt; broker0，等等 从首领分区开始，依次分配跟随着副本。分区0首领在broker4上，那么follower0-0在broker5，follower0-1在broker0，等等。 配置了机架的情况假设 broker0、1、2在同一个机架上，broker3、4、5在同一个机架上。也是用轮序的方式分配，只不过轮序的顺序是按照机架交错的，0、3、1、4、2、5 控制器控制器其实就是一个broker，只不过在一般broker之外，还有分区首领选择的功能。 controller的选择利用zookeeper，创建一个 /controller 的临时节点让自己成为控制器。如果挂掉了，那么其他broker会收到通知，又再一次创建 /controller 节点，竞争成为新的控制器 脑裂通过 controller_epoch 解决。broker收到了较旧的 epoch，就会忽略它们 broker离开当发现有broker离开集群，那么控制器就会找出失去了首领的那些分区，并遍历这些分区，确定新的首领副本，发送首领变更的请求 broker加入当新的broker加入的时候，控制器检查新加入的broker是否有现有分区的副本，如果有，就通知其他broker,并且新加入的broker开始复制消息 可靠性和持久性保证producer 设置 ack: ack = 0 不等待broker返回确认消息 ack = 1 leader保存成功返回 ack = -1(all) 所有备份都保存成功返回 这里面要注意的是 所有备份都保存成功返回 并不意味着所有的副本都写入了消息。这个跟 broker 的 min.insync.replicas 有关，其默认为1。那么有可能ISR列表中有些副本没有写入。这里有一个经典的配置方法：123topic 的 replication = 3min.insync.replicas = 2producer 的 ack = -1 这将确保如果大多数副本没有写入producer则抛出异常（NotEnoughReplicasExceptoin）。 高可靠性配置 topic的配置：replication.factor&gt;=3, 即副本数至少是3个；2&lt;=min.insync.replicas&lt;=replication.factor broker的配置：leader的选举条件 unclean.leader.election.enable=false producer的配置：request.required.acks=-1(all) acks=1producer发送数据到leader，leader写本地日志成功，返回客户端成功；此时ISR中的副本还没有来得及拉取该消息，leader就宕机了，那么此次发送的消息就会丢失。 acks=-1replication.factor&gt;=2 且 min.insync.replicas&gt;=2的情况下，不会丢失数据 HW的进一步探讨如上图，某个topic的某partition有三个副本，分别为A、B、C。A作为leader肯定是LEO最高，B紧随其后，C机器由于配置比较低，网络比较差，故而同步最慢。这个时候A机器宕机，这时候如果B成为leader，假如没有HW，在A重新恢复之后会做同步(makeFollower)操作，在宕机时log文件之后直接做追加操作，而假如B的LEO已经达到了A的LEO，会产生数据不一致的情况，所以使用HW来避免这种情况。A在做同步操作的时候，先将log文件截断到之前自己的HW的位置，即3，之后再从B中拉取消息进行同步。如果失败的follower恢复过来，它首先将自己的log文件截断到上次checkpointed时刻的HW的位置，之后再从leader中同步消息。leader挂掉会重新选举，新的leader会发送“指令”让其余的follower截断至自身的HW的位置然后再拉取新的消息。 文件存储个人觉得Kafka官方文档没有更新到最新的版本。因为它说存储的文件是 .kafka 结尾的，然而，我实际上看见的文件格式是 .index .log物理上一个topic由多个partition组成（如果设置了多个partition），一个partition就是一个文件夹，partition的名称规则为：topic名称+有序序号，第一个序号从0开始计。partition是实际物理上的概念，而topic是逻辑上的概念。而partition又是以segment存储的，segment是一个个小的文件。 相关配置12345678# 单个日志段文件最大大小log.segment.bytes = 1073741824# 从文件系统中删除一个日志段文件前的保留时间log.segment.delete.delay.ms = 60000# 新日志段轮转时间间隔log.roll.hours = 168log.roll.ms = null segment存储segment文件由两部分组成，分别为 “.index” 文件和 “.log” 文件，分别表示为segment索引文件和数据文件。这两个文件的命令规则为：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值，数值大小为64位，20位数字字符长度，没有数字用0填充，如下：12345600000000000000000000.index00000000000000000000.log00000000000000170410.index00000000000000170410.log00000000000000239430.index00000000000000239430.log 他们之间的关系如下如上图，“.index” 索引文件存储大量的元数据，“.log” 数据文件存储大量的消息，索引文件中的元数据指向对应数据文件中message的物理偏移地址。其中以“.index”索引文件中的元数据 [3, 348] 为例，在“.log”数据文件表示第3个消息，即在全局partition中表示 170410+3=170413 个消息，该消息的物理偏移地址为348。那么如何从partition中通过offset查找message呢？以上图为例，读取offset=170418的消息 首先查找segment文件，其中00000000000000000000.index为最开始的文件，第二个文件为00000000000000170410.index（起始偏移为170410+1=170411），而第三个文件为00000000000000239430.index（起始偏移为239430+1=239431），所以这个offset=170418就落到了第二个文件之中。其他后续文件可以依次类推，以其实偏移量命名并排列这些文件 然后根据二分查找法就可以快速定位到具体文件位置。其次根据00000000000000170410.index文件中的 [8,1325] 定位到00000000000000170410.log文件中的1325的位置进行读取。 日志清理几个重要的配置1234567# 下面的都是默认值log.cleaner.enable = true log.cleanup.policy = delete# 日志中脏数据清理比例log.cleaner.min.cleanable.ratio = 0.5# 消息在日志中保持未压缩的最短时间。 仅适用于正在压缩的日志log.cleaner.min.compaction.lag.ms = 0 清理策略压缩策略由 log.cleanup.policy 指定。清理策略分为 delete和 compact delete delete 就是单纯的删除。是默认的策略，跟它相关的配置有12345678log.retention.bytes 默认 -1log.retention.ms / log.retention.hours / log.retention.minutes# 从文件系统中删除一个日志段文件前的保留时间log.segment.delete.delay.ms = 60000# 日志清理器检查是否有日志符合删除的频率log.retention.check.interval.ms = 300000 删除的时候，会先将segment标记为 .delete ，然后在 log.segment.delete.delay.ms 之后，由另外一个定时器线程删除 compactcompact 是对于数据进行压缩清理日志分为两个部分，log tail是已经压缩了的日志，log head是还没有压缩的日志。对于上面的这个，36、37、38都是指的是38这个位置。compact 其实就是保留最新的 k-v 键值对，示意图如下如果我们要删除一个数据，那么要经过下面几个过程： 程序发送包含该键且值为null的消息 进行常规清理，只保留为null的消息（墓碑消息，tomestone） 墓碑消息会保留一段时间 假如消费者在通过kafka进行数据处理的时候，发现key为null，就应该知道，这个数据被删除了 到时间之后，移除墓碑消息 墓碑移除的时间由 log.cleaner.delete.retention.ms 控制，默认24小时清理的时候，清理线程会选择污浊率较高的分区进行清理（log head占总分区的比例）。log.cleaner.min.compaction.lag.ms 默认为0，所以默认不会清理最后一个活动的segment。故，可以通过配置 log.cleaner.min.compaction.lag.ms，保证消息在配置的时长内不被压缩。活动的 segment 是不会被压缩的，即使它保存的消息的滞留时长已经超过了配置的最小压缩时间长。扫描的频率由 log.cleaner.backoff.ms 控制 一个生产环境服务器配置示例1234567891011121314# ZooKeeperzookeeper.connect=[list of ZooKeeper servers] # Log configurationnum.partitions=8default.replication.factor=3log.dir=[List of directories. Kafka should have its own dedicated disk(s) or SSD(s).] # Other configurationsbroker.id=[An integer. Start with 0 and increment by 1 for each new broker.]listeners=[list of listeners]auto.create.topics.enable=falsemin.insync.replicas=2queued.max.requests=[number of concurrent requests] 参考kafka1.0 中文文档kafka数据可靠性深度解读Kafka设计解析（八）- Kafka事务机制与Exactly Once语义实现原理Kafka日志清理之Log CompactionKafka配置消息保存时间的方法Kafka日志删除源码分析Kafka源码分析-Content TableKafka消费组(consumer group)Matt’s Blog (挺厉害的，对于kafka理解很深)]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2018%2F11%2F19%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[作用及基本用法代码1234567891011121314151617public class ThreadLocalBasic &#123; private static ThreadLocal&lt;Integer&gt; local = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException &#123; Thread child = new Thread(() -&gt; &#123; System.out.println("child init " + local.get()); local.set(200); System.out.println("child final " + local.get()); &#125;); local.set(100); child.start(); child.join(); System.out.println("main final " + local.get()); &#125;&#125; 输出1234main init nullchild init nullchild final 200main final 100 分析ThreadLocal就是说，每一个都有同一个变量的独有拷贝。从结果可以看出，main线程对于变量的设置对于child线程不起作用，child线程对local变量的改变也不会影响main线程。他们虽然访问的都是同一个local，但是每一个线程都有自己的值，这就是线程本地变量。 基本实现原理set123456789101112131415161718192021222324252627282930313233public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;``` 可以看出，每一个线程对象 `Thread` 都有一个 Map，类型为 `ThreadLocalMap`，调用 `set` 实际上是在线程自己的 Map 里面设置了一个值，键为当前的 `ThreadLocal` 对象。这个 Map 不同于一般的 Map，它的键类型为 `WeakReference&lt;ThreadLocal&lt;?&gt;&gt;`。## get```javapublic T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; get 就是访问 Thread 的 Map，以 ThreadLocal 对象为键从 Map 中获取value，如果 Map 中没有，则调用 setInitialValue setInitialValue12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 其中就是调用 initialValue 获得初始值 深入分析ThreadLocalMapThreadLocalMap 是在Thread中实际存储值的对象。ThreadLocalMap是一个定制的哈希映射，只适合维护线程本地值。在ThreadLocal类之外不导出任何操作。类是包私有的，允许在类线程中声明字段。为了帮助处理非常大的长期使用，哈希表条目对键使用弱引用。但是，由于没有使用引用队列，只有当表开始耗尽空间时，过时的条目才会被删除。 存储方式 内部使用一个Entry[] table来保存数据 Entry[] table的大小必须是2的倍数（这有一定的数学依据） Entry[] table初始大小为16 如果使用的空间超过了Entry[] table的 2/3 ，那么会将数组大小扩大两倍（int newLen = oldLen * 2） 存储使用的是开放地址法，如果发现通过hash计算出的位置被占用了，那么就找下一个，一直找到有空的位置 Entry 保存的是一个 ThreadLocal 的 WeakReference，和一个value的强引用 这里贴一下 Entry 这个 ThreadLocalMap 的内部类，注意这个弱引用123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; hash算法每一个 ThreadLocal 在创建之后，它的hash值就已经确定了123456789101112131415161718192021222324private final int threadLocalHashCode = nextHashCode();/** * The next hash code to be given out. Updated atomically. Starts at * zero. */private static AtomicInteger nextHashCode = new AtomicInteger();/** * The difference between successively generated hash codes - turns * implicit sequential thread-local IDs into near-optimally spread * multiplicative hash values for power-of-two-sized tables. * 连续生成的哈希码之间的区别——将隐式顺序线程本地id转换为几乎最优分布的 * 乘法哈希值，用于大小为2的幂的表。 */private static final int HASH_INCREMENT = 0x61c88647;/** * Returns the next hash code. */private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; 可以看出，threadLocalHashCode 是一个常量，它通过 nextHashCode() 函数产生。nextHashCode() 函数其实就是在一个 AtomicInteger 变量（初始值为0）的基础上每次累加 0x61c88647，使用 AtomicInteger 为了保证每次的加法是原子操作。而 0x61c88647 这个就比较神奇了，它可以使 hashcode 均匀的分布在大小为 2 的 N 次方的数组里。（Fibonacci Hashing）这里写个代码测试一下123456789101112public static void main(String[] args) &#123; AtomicInteger nextHashCode = new AtomicInteger(); int hash_increment = 0x61c88647; int size = 16; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; size; i++) &#123; list.add(nextHashCode.getAndAdd(hash_increment) &amp; (size - 1)); &#125; System.out.println("original:" + list); Collections.sort(list); System.out.println("sort: " + list);&#125; 1234567891011// size=16original:[0, 7, 14, 5, 12, 3, 10, 1, 8, 15, 6, 13, 4, 11, 2, 9]sort: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]// size=32original:[0, 7, 14, 21, 28, 3, 10, 17, 24, 31, 6, 13, 20, 27, 2, 9, 16, 23, 30, 5, 12, 19, 26, 1, 8, 15, 22, 29, 4, 11, 18, 25]sort: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]// size=64original:[0, 7, 14, 21, 28, 35, 42, 49, 56, 63, 6, 13, 20, 27, 34, 41, 48, 55, 62, 5, 12, 19, 26, 33, 40, 47, 54, 61, 4, 11, 18, 25, 32, 39, 46, 53, 60, 3, 10, 17, 24, 31, 38, 45, 52, 59, 2, 9, 16, 23, 30, 37, 44, 51, 58, 1, 8, 15, 22, 29, 36, 43, 50, 57]sort: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] 可以看到随着 size 的变化，hashcode 总能均匀的分布。 ThreadLocalMap.set123456789101112131415161718192021222324252627282930313233343536373839private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; // 获得hash值对应于数组的哪儿 int i = key.threadLocalHashCode &amp; (len-1); // 如果当前位置已经有元素了，那么使用开放地址法，找下一个 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // 获得已经占用的这个元素的Reference的referent属性 // 如果被gc了，那么这个k会是null ThreadLocal&lt;?&gt; k = e.get(); // 如果k和现在的这个key是同一个“引用” // 那么直接替换掉原来的值 if (k == key) &#123; e.value = value; return; &#125; // 如果k为null（被gc了） // 清理掉原来的entry，设置新的值 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; // 找到了空的位置 tab[i] = new Entry(key, value); int sz = ++size; // 如果没有清理出空的位置（清理掉k为null的entry） // 且所占用的空间已经超过总大小的2/3 // 那么进行扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; ThreadLocalMap.cleanSomeSlots1234567891011121314151617181920212223/** * 启发式地扫描一些单元格，寻找过时的条目。在添加新元素或删除另一个陈旧元素时调用此函数。 * 它执行对数次扫描，作为不扫描(快速但保留垃圾)和与元素数量成比例的扫描次数之间的平衡， * 扫描的时候将查找所有垃圾，但会导致一些插入花费O(n)时间。 */private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; // 发现了垃圾，启发式的将扫描范围扩大 n = len; removed = true; // i为环形向后访问最近的一个entry为null的位置 // 详细见下面的expungeStaleEntry i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125; 参数 i开始进行脏数据扫描的位置，注意从代码中可以看出，cleanSomeSlots约定 i 这个位置一定不是脏数据 n主要用于扫描控制（scan control），从while中是通过n来进行条件判断的说明n就是用来控制扫描趟数（循环次数）的。在扫描过程中，如果没有遇到脏entry就整个扫描过程持续log2(n)次，log2(n)的得来是因为n &gt;&gt;&gt;= 1，每次n右移一位相当于n除以2。如果在扫描过程中遇到脏entry的话就会令n为当前hash表的长度（n=len），再扫描log2(n)趟，注意此时n增加无非就是多增加了循环次数从而通过nextIndex往后搜索的范围扩大，示意图如下按照n的初始值，搜索范围为黑线，当遇到了脏entry，此时n变成了哈希数组的长度（n取值增大），搜索范围log2(n)增大，红线表示。如果在整个搜索过程没遇到脏entry的话，搜索结束，采用这种方式的主要是用于时间效率上的平衡。如果是在set方法插入新的entry后调用，n位当前已经插入的entry个数size；如果是在replaceSateleEntry方法中调用n为哈希表的长度len。 ThreadLocalMap.expungeStaleEntry123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 清除当前脏数据，并继续向后扫描，清除在扫描过程中的脏数据 * 一直到找到一个空位置（为null） * 返回这个为null的序号 */private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot // 将这个地方的value设为null，value会被gc // 再把这个地方的值设为null tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; // 继续向后面搜索，直到遇见一个为null的entry for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; // 如果在向后搜索过程中再次遇到脏entry（key被gc了） // 那么清除这个entry e.value = null; tab[i] = null; size--; &#125; else &#123; // 如果不是脏数据 // 那么重新计算其应该在数组中的位置，并尽量将它挪到离hash值更近一点的地方 int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; // 将现在用的这个位置的entry“引用”清掉 tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. // 从期望的最优hash位置开始，重新向后找到一个空位置 while (tab[h] != null) h = nextIndex(h, len); // 放到新的位置 tab[h] = e; &#125; &#125; &#125; // 返回遇见的第一个为null的地方 return i;&#125; expungeStaleEntry 并不是单纯的就是清掉 staleSlot 所指的 entry，除此之外还做了几件事情： 清除当前脏entry，将entry的value置为null，这样gc的时候就会被回收掉 然后，继续向后面搜索，如果发现了脏数据，那么继续清理掉 如果遇见的不是脏数据，那么重新放置这个数据，让它尽量靠近直接计算出来的最优的hash位置（因为使用的是开放地址法） 当遇见了一个为null的entry，那么函数返回 cleanSomeSlots小结cleanSomeSlots的大体流程如下： 从i开始（不包括i）开始向后面在log2(n)的范围里面查找脏元素 如果发现了脏元素，那么调用expungeStaleEntry （expungeStaleEntry开始） 清除当前脏元素 继续向后面扫描，发现了脏元素就清理，不是脏元素那么重新进行hash存储，便于以后访问的加速 一直扫描，直到遇见了一个为null的entry 返回这个为null的entry的序号 （expungeStaleEntry结束） 重置n为整个数组长度，i赋值为expungeStaleEntry返回的为null的序号 循环直到log2(n)范围扫描完 举个例子：假设现在i=1，size=10 nextInt为2，这个entry为null，继续向下面找 现在 i=3，发现这是一个脏数据，那么调用expungeStaleEntry进行清理 expungeStaleEntry清理了 i=3这个数据之后，继续工作，清理了 4、5 expungeStaleEntry 发现 6 不是一个脏数据，那么就为它重新找一个尽量好的位置（最接近hash的最优位置），它的hashIndex为8，但是8这个位置已经有数据了，继续向下，发现9是空的，那么现在就把它挪到了9了 expungeStaleEntry 发现 7 是一个空位置，函数返回，返回 7 这个位置 cleanSomeSlots i 现在赋值为 7，由于进行了数据的清理，启发式的将 n = len 扩大搜索范围，进入下一个循环 ThreadLocalMap.replaceStaleEntry在 ThreadLocalMap.set 里面，还调用了 replaceStaleEntry 下面来看一看1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; // Back up to check for prior stale entry in current run. // We clean out whole runs at a time to avoid continual // incremental rehashing due to garbage collector freeing // up refs in bunches (i.e., whenever the collector runs). // 向前找到直到遇见null entry // 记录最前面的entryId int slotToExpunge = staleSlot; for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // Find either the key or trailing null slot of run, whichever // occurs first // 向后找，直到遇见null entry for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; // e是现在访问的这个entry ThreadLocal&lt;?&gt; k = e.get(); // If we find key, then we need to swap it // with the stale entry to maintain hash table order. // The newly stale slot, or any other stale slot // encountered above it, can then be sent to expungeStaleEntry // to remove or rehash all of the other entries in run. if (k == key) &#123; // 如果找到了一样的key // 那么将其value修改 // Pa e.value = value; // i是现在访问的这个entry的序号 // staleSlot是传进来的脏entry的序号 // 将这个重复key值的entry同哪个脏entry进行交换 tab[i] = tab[staleSlot]; tab[staleSlot] = e; // Start expunge at preceding stale entry if it exists if (slotToExpunge == staleSlot) // 如果向前搜索的时候，没有找到脏entry // 那么就以当前位置（现在已经发生了交换，是一个脏entry了）开始进行清理 // Pb slotToExpunge = i; // 进行清理 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. // 如果向前查找没有找到脏entry，而在向后查找过程遇到脏entry的话 // 后面就以此时这个位置作为起点执行cleanSomeSlots if (k == null &amp;&amp; slotToExpunge == staleSlot) // Pc slotToExpunge = i; &#125; // If key not found, put new entry in stale slot // 如果在查找过程中，没有找到可以覆盖的entry // 那么使用新entry覆盖脏entry // 这里将value置为了null，便于gc // Pd tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them // 如果在运行中，找到了任何一个脏entry，那么开始清理 if (slotToExpunge != staleSlot) // Pe cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 下面以几个例子来说明 前向有脏entry后向环形查找找到可覆盖的entry 向前找到了脏entry，更新slotToExpunge 向后找，找到了key相同的，覆盖并同staleSlot交换（Pa） 现在脏entry就到了红色的那个地方，staleSlot现在是新的数据了 如果有必要的话（找到了除了staleSlot以外的其他脏数据），以slotToExpunge开始，向后清理 函数返回 后向环形查找未找到可覆盖的entry 同样，向前找到了脏entry，更新slotToExpunge 现在向后找，并没有找到同样的key或者脏entry，遇见了null entry 将新值覆盖staleSlot那个位置（Pd） 如果有必要的话（找到了除了staleSlot以外的其他脏数据），以slotToExpunge开始，向后清理 函数返回 前向没有脏entry后向环形查找找到可覆盖的entry 向前找，没有找到脏entry，现在的slotToExpunge等于staleSlot 向后找，找到了一个脏数据，那么由于向前搜索的时候没有找到脏数据（slotToExpunge没有变），将slotToExpunge赋值为当前序号（Pc） 继续向后找，找到了一个重复的key，覆盖并同staleSlot交换（Pa）。如果在整个过程中还是没有遇到脏entry的话，将slotToExpunge赋值为现在的序号（Pb） 如果有必要的话（找到了除了staleSlot以外的其他脏数据），以slotToExpunge开始，向后清理 函数返回 后向环形查找未找到可覆盖的entry 向前找，没有找到脏entry，现在的slotToExpunge等于staleSlot 向后找，如果找到了一个脏数据，那么由于向前搜索的时候没有找到脏数据（slotToExpunge没有变），将slotToExpunge赋值为当前序号（Pc） 遇到了null entry，结束向后找 没有找到重复的key，将新值覆盖staleSlot那个位置（Pd） 如果有必要的话（找到了除了staleSlot以外的其他脏数据），以slotToExpunge开始，向后清理 函数返回 ThreadLocalMap.getEntry/getEntryAfterMiss这个两个一起说，因为在前文的基础上，这两个比较简单了。直接看代码12345678910111213141516171819202122232425262728293031private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; // 获得hashId int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) // 如果找到了，直接返回 return e; else // 如果没有，那么向后继续找 return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; // 一直找，直到遇见null entry // 如果遇见了null entry，那么说明没有对应的值 while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) // 如果发现了一个脏数据，那么进行清理 expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125; ThreadLocalMap.removeremove比较简单12345678910111213141516private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; // 调用Reference clear方法 e.clear(); // 从当前开始，向后清理 expungeStaleEntry(i); return; &#125; &#125;&#125; 思考在replaceStaleEntry中为什么只有在向后搜索的时候，才会有把新值覆盖旧值的操作？回看 set 函数，它是从最优的hashId开始向后找的，故，应该尽量的将数据放在最优的hashId向右距离最近的地方。而如果在向前搜索的时候将数据放了进去，那么进行查询操作的时候，距离可能会变得比较远。而且，在 set 中，是从最优位置开始，如果由重复的，那么就直接覆盖了，如果发现了第一个脏数据，就会调用本函数，所以，向前查找出来的脏数据会是在最优位置左边。 在replaceStaleEntry中为什么向后查找的时候，如果发现脏数据并不覆盖？这要秉承一个思想，放的位置离最优位置向后距离越近越好。现在我已经有了一个更近的位置了，那就是 staleSlot，为什么还要放这个更远一点的位置呢？之所以同样的key值的操作是同 staleSlot 交换也是这个道理。 getEntryAfterMiss 里，发现了脏entry，expungeStaleEntry 调用之后，i这个地方不是被清理了么，那么是不是就意味着一旦发现了一个脏数据就会跳出循环，返回null了？不是的。注意expungeStaleEntry除了有脏entry的清理功能，还有一个数据重排列的功能（当遇见的不是一个脏数据的时候）。那么就是意味着，如果 i 这个位置真的应该是有数据，只是由于开始位置被占了挪到后面去了的话，那么在expungeStaleEntry重排列数据之后，这个位置就会有值。 会不会出现要获得的值前面插了个null从而get不到的情况？在ThreadLocalMap的 set replaceStaleEntry 中，都是最终如果其他各种更优选择没有的情况下，那么就会使用离hashId最近的那个null entry。在 remove 的时候，也会调用expungeStaleEntry进行重拍，尽量使数据离最优的hashId进，尽量让数据紧凑，所有不会有这种情况发生。 小结每一个线程都有一个 Map，对于每一个 ThreadLocal 对象，调用其 get/set 实际上就是以 ThreadLocal 对象为键读写当前线程的 Map，这样就实现了每一个线程都有自己独立副本的效果。但是，要注意的是，ThreadLocal 并不是一种保证线程安全的手段。假如多个线程之间共享一个 ArrayList，那么这个 ArrayList 并不是线程安全的。（每个线程单独保存的是独立的“引用”，但是这个“引用”指向的依然是同一个内存空间） 参考http://mahl1990.iteye.com/blog/2347932https://www.jianshu.com/p/250798f9ff76https://www.cnblogs.com/windliu/p/7623369.htmlhttps://stackoverflow.com/questions/17968803/threadlocal-memory-leakhttps://blog.csdn.net/liu1pan2min3/article/details/80236105https://www.cnblogs.com/zhangjk1993/archive/2017/03/29/6641745.html#\_label3\_2一篇文章，从源码深入详解ThreadLocal内存泄漏问题 &gt;&gt;&gt;是什么]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 简单的使用总结]]></title>
    <url>%2F2018%2F11%2F13%2FKafka-Consumer%2F</url>
    <content type="text"><![CDATA[生产者简单的使用方法12345678910111213141516171819202122232425public class SimpleAsyncKafKaProducer &#123; public static void main(String[] args) &#123; final Map&lt;String, Object&gt; config = ImmutableMap.of( ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer" ); try (val producer = new KafkaProducer&lt;String, String&gt;(config)) &#123; val record = new ProducerRecord&lt;String, String&gt;("topic01", "key", "value2"); producer.send(record, (RecordMetadata metadata, Exception exception) -&gt; &#123; if (exception != null) &#123; exception.printStackTrace(); &#125; System.out.println("send success"); &#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; while (true) &#123; &#125; &#125;&#125; 分区器默认的分区器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class DefaultPartitioner implements Partitioner &#123; private final ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = new ConcurrentHashMap&lt;&gt;(); public void configure(Map&lt;String, ?&gt; configs) &#123;&#125; /** * Compute the partition for the given record. * * @param topic The topic name * @param key The key to partition on (or null if no key) * @param keyBytes serialized key to partition on (or null if no key) * @param value The value to partition on or null * @param valueBytes serialized value to partition on or null * @param cluster The current cluster metadata */ public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123; List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic); int numPartitions = partitions.size(); if (keyBytes == null) &#123; // 如果没有设置key值，则采用轮询的方式到各个分区上面 int nextValue = nextValue(topic); // 获得可用的分区 List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic); if (availablePartitions.size() &gt; 0) &#123; int part = Utils.toPositive(nextValue) % availablePartitions.size(); return availablePartitions.get(part).partition(); &#125; else &#123; // no partitions are available, give a non-available partition // 如果没有可用分区，那么就给一个不可用的分区 return Utils.toPositive(nextValue) % numPartitions; &#125; &#125; else &#123; // hash the keyBytes to choose a partition // 如果设置了key，那么使用kafka的hash算法计算分区 return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; &#125; &#125; private int nextValue(String topic) &#123; // 获得这个分区的计数器 AtomicInteger counter = topicCounterMap.get(topic); if (null == counter) &#123; // 生成一个随机数 // 意味着是从一个随机的分区开始的 counter = new AtomicInteger(ThreadLocalRandom.current().nextInt()); AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter); if (currentCounter != null) &#123; counter = currentCounter; &#125; &#125; return counter.getAndIncrement(); &#125; public void close() &#123;&#125;&#125; 自定义分区器定义12345678910111213141516171819public class MyPartitioner implements Partitioner &#123; @Override public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) &#123; List&lt;PartitionInfo&gt; partitionInfos = cluster.partitionsForTopic(topic); int numPartitions = partitionInfos.size(); return (Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions); &#125; @Override public void close() &#123; &#125; @Override public void configure(Map&lt;String, ?&gt; configs) &#123; &#125;&#125; 使用1234567891011121314151617181920212223242526public class SimpleKafKaProducerPartition &#123; public static void main(String[] args) &#123; final Map&lt;String, Object&gt; config = ImmutableMap.of( ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer", // 注意这里 ProducerConfig.PARTITIONER_CLASS_CONFIG, "com.lk.producer.MyPartitioner" ); try (val producer = new KafkaProducer&lt;String, String&gt;(config)) &#123; for (int i = 0; i &lt; 3; i++) &#123; val record = new ProducerRecord&lt;String, String&gt;("topic01", "key", "value" + i); producer.send(record).get(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者简单的使用1234567891011121314151617181920212223242526272829303132public class SimpleConsumer &#123; public static void main(String[] args) &#123; val consumer = new KafkaConsumer&lt;String, String&gt;(ImmutableMap.of( ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer", ConsumerConfig.GROUP_ID_CONFIG, "group01" )); consumer.subscribe(ImmutableList.of("topic01")); try &#123; while (true) &#123; val records = consumer.poll(Duration.ofMillis(100)); for (val record : records) &#123; String str = "offset: " + record.offset() + " ,key: " + record.key() + " ,value: " + record.value(); System.out.println(str); &#125; &#125; &#125; finally &#123; consumer.close(); &#125; &#125;&#125; 再均衡和offset提交12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class OffsetCommitConsumer &#123; private static Map&lt;TopicPartition, OffsetAndMetadata&gt; currentOffset = new HashMap&lt;&gt;(); public static void main(String[] args) &#123; val consumer = new KafkaConsumer&lt;String, String&gt;(ImmutableMap.of( ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer", ConsumerConfig.GROUP_ID_CONFIG, "group01" )); consumer.subscribe(ImmutableList.of("topic01"), new ConsumerRebalanceListener() &#123; @Override // 再均衡之前，停止读取消息之后 public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) &#123; System.out.println("onPartitionsRevoked"); consumer.commitSync(currentOffset); &#125; @Override // 被重新分配分区之后（再均衡之后），开始读取消息之前调用 public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) &#123; System.out.println("onPartitionsAssigned"); &#125; &#125;); try &#123; while (true) &#123; val records = consumer.poll(Duration.ofMillis(100)); for (val record : records) &#123; String str = "offset: " + record.offset() + " ,key: " + record.key() + " ,value: " + record.value(); System.out.println(str); currentOffset.put(new TopicPartition(record.topic(), record.partition()), new OffsetAndMetadata(record.offset() + 1, "no data")); &#125; // 这个是异步的提交，不会阻塞方法 // 也可以记录下处理的条数，当达到多少后，就提交，而不是全部处理完之后才提交 consumer.commitAsync(currentOffset, null); &#125; &#125; finally &#123; try &#123; consumer.commitSync(); &#125; finally &#123; consumer.close(); &#125; &#125; &#125;&#125; 安全的退出123456789101112131415161718192021222324252627282930313233343536373839404142434445public class SafeShutdown &#123; public static void main(String[] args) &#123; val consumer = new KafkaConsumer&lt;String, String&gt;(ImmutableMap.of( ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringDeserializer", ConsumerConfig.GROUP_ID_CONFIG, "group01" )); consumer.subscribe(ImmutableList.of("topic01")); val mainThread = Thread.currentThread(); Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123; System.out.println("exit ..."); // 触发wakeup consumer.wakeup(); try &#123; mainThread.join(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;)); try &#123; while (true) &#123; val records = consumer.poll(Duration.ofMillis(100)); for (val record : records) &#123; String str = "offset: " + record.offset() + " ,key: " + record.key() + " ,value: " + record.value(); System.out.println(str); &#125; &#125; &#125; catch (WakeupException ignored) &#123; // 如果是WakeupException，那么说明是退出 &#125; finally &#123; consumer.close(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java中的instanceof和getClass()]]></title>
    <url>%2F2018%2F11%2F12%2Fjava%E4%B8%AD%E7%9A%84instanceof%E5%92%8CgetClass%2F</url>
    <content type="text"><![CDATA[父类A1class A &#123; &#125; 子类B1class B extends A &#123; &#125; 构造对象12Object o1 = new A(); Object o2 = new B(); instanceof123456o1 instanceof A =&gt; true o1 instanceof B =&gt; false o2 instanceof A =&gt; true // &lt;================ HERE o2 instanceof B =&gt; true ``` - 用法 英文：result = object instanceof class中文：结果 = 某个实例对象 instanceof 某个类名12java 中的instanceof 运算符是用来在运行时指出对象是否是特定类的一个实例。instanceof通过返回一个布尔值来指出，这个对象是否是这个特定类或者是它的子类的一个实例。- 总结 S(Object) instanceof T(Class)1234567**简单来说，instanceof就是判断对象S是否是T类的实例，或者是T类的子类实例。**# getClass```javao1.getClass().equals(A.class) =&gt; true o1.getClass().equals(B.class) =&gt; false o2.getClass().equals(A.class) =&gt; false // &lt;===============HERE o2.getClass().equals(B.class) =&gt; true getClass方法在JDK1.8中定义如下：1234/*** Returns the runtime class of this Object*/public final native Class&lt;?&gt; getClass(); 功能 返回在运行时期对象的类。getClass() 会在你需要判断一个对象不是一个类的子类的时候很有用getClass() will be useful when you want to make sure your instance is NOT a subclass of the class you are comparing with. 总结instanceof 用来判断对象与类的关系，判断对象S是否是T类的实例，或者是T类的子类实例。getClass 获得运行时期对象的类。当限定到具体某一类时，则使用getClass+equals搭配。在 jdk ArryList 的构造函数中，elementData.getClass() != Object[].class 限制了 elementData 的类型一定要是 Object 的数组，如果是Object的子类什么的都不行（为什么要这么判断见Jdk Bug6260652 和 ArrayList）另外，对于 getClass() 和某个 class 比较，其实使用 equals 和 == 是一样的 参考java中instanceof和getClass()的作用]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Jdk Bug6260652]]></title>
    <url>%2F2018%2F11%2F12%2FJdk-Bug6260652%2F</url>
    <content type="text"><![CDATA[jdk 1.8 背景12BaseClass[] baseClasses = &#123;new BaseClass()&#125;;baseClasses[0] = new SubClass(); 对于这段代码，将 BaseClass 的数组中的元素赋值成 SubClass 是可以的。但是如果是，子类型的数组，是不能被赋值成父类型的。12SubClass[] subClasses = &#123;new SubClass()&#125;;subClasses[0] = new BaseClass(); // 编译不能通过 其实原因比较简单，因为符类型的元素并不能提供子类型所独有的功能，所以不能这么赋值。 复现test1123456789101112public static void test1() &#123; SubClass[] subArray = &#123;new SubClass(), new SubClass()&#125;; // class [Lcom.lk.Main$SubClass; System.out.println(subArray.getClass()); BaseClass[] baseArray = subArray; // class [Lcom.lk.Main$SubClass; System.out.println(baseArray.getClass()); // java.lang.ArrayStoreException baseArray[0] = new BaseClass();&#125; SubClass 继承自 BaseClass ，由于 SubClass 数组中每一个元素都是 SubClass 对象，所以 BaseClass[] baseArray = subArray; 这种强制类型转换不会报错。这其实就是java对象的向上转型，子类数组转换成父类数组是允许的。但是由于数组中元素类型都是SubClass类型的，所以 baseArray[0] = new BaseClass(); 会报错 java.lang.ArrayStoreException 。这也就是说假如我们有1个 Object[] 数组，并不代表着我们可以将 Object 对象存进去，这取决于数组中元素实际的类型。 test2123456789101112public static void test2() &#123; List&lt;String&gt; list = Arrays.asList("abc"); // class java.util.Arrays$ArrayList System.out.println(list.getClass()); Object[] objArray = list.toArray(); // class [Ljava.lang.String; System.out.println(objArray.getClass()); objArray[0] = new Object(); // cause ArrayStoreException&#125; List&lt;String&gt; list = Arrays.asList(&quot;abc&quot;); 需要注意，可以知道返回的实际类型是 java.util.Arrays$ArrayList ，而不是 ArrayList 。我们调用 Object[] objArray = list.toArray(); 返回是 String[] 数组，所以我们不能将Object对象，放到objArray数组中。 test31234567891011121314public static void test3() &#123; List&lt;String&gt; dataList = new ArrayList&lt;String&gt;(); dataList.add("one"); dataList.add("two"); Object[] listToArray = dataList.toArray(); // class [Ljava.lang.Object; // 返回的是Object数组 System.out.println(listToArray.getClass()); listToArray[0] = ""; listToArray[0] = 123; listToArray[0] = new Object();&#125; ArrayList对象的toArray()返回就是Object[]数组，所以我们可以将任意对象存放到返回的Object[]数组中。 小细节1234567Object[] objects1 = &#123;1, 2&#125;;// class [Ljava.lang.Object;System.out.println(objects1.getClass());Object[] objects2 = &#123;"1", "2"&#125;;// class [Ljava.lang.Object;System.out.println(objects2.getClass()); 总结toArray() 返回的这个 Object[] 数组并不一定是一个 Object[] ，而是一个 Object[] 的子类数组。所以这个 Object[] 并不一定可以放任意元素。（所以，ArrayList 的 Collection 构造函数里面对于这个情况进行了判断） 参考Java Bug 6260652 记录Jdk 6260652 Bug]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Snap离线安装]]></title>
    <url>%2F2018%2F11%2F11%2FSnap%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[1234567891011121314$ snap download hello-worldFetching snap &quot;hello-world&quot;Fetching assertions for &quot;hello-world&quot;kyrofa@Pandora:~$ sudo snap ack hello-world_27.assert kyrofa@Pandora:~$ sudo snap install hello-world_27.snaphello-world 6.3 from &apos;canonical&apos; installedkyrofa@Pandora:~$ snap listName Version Rev Developer Notes&lt;snip&gt;hello-world 6.3 27 canonical -]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ArrayList]]></title>
    <url>%2F2018%2F11%2F10%2FArrayList%2F</url>
    <content type="text"><![CDATA[版本 jdk1.8 概览、描述Java Collections Framework 成员之一。ArrayList是List的可变大小的数组的实现（resizable-array implementation）。实现了所有的list的操作，并可以存储所有的元素，包括 null。内部存储使用数组实现（array），同时也还提供了可以操作内部存储的数组的大小的方法。ArrayList类似于Vector，除了不是同步的。size, isEmpty, get, set, iterator, listIterator 这些操作都是在常数时间（constant time）完成。add 操作为 amortized constant time（均摊常数时间）,也就是说添加 n 个元素需要 O(n) 的时间。大致上说，所有的其他操作都是在线性时间。The constant factor is low compared to that for the LinkedList implementation每一个ArrayList都有一个容量（capacity）。capacity 是指存储列表中元素的数组的大小。它总是至少和列表的大小一样（等于或大于）。当元素被添加到ArrayList中时，其容量会自动增长。The details of the growth policy are not specified beyond the fact that adding an element has constant amortized time cost.在添加大量元素之前，可以调用 ensureCapacity 来增加 capacity。这样可以减少（may reduce）增量再分配的数量。需要注意的是，ArrayList并不是线程安全的。如果多个线程同时访问ArrayList实例，并且至少一个线程在结构上修改列表，则必须在外部对其进行同步。（结构修改是指任何一个操作增加、删除一个或者多个元素，或者显示的修改内部存储数组的大小；仅仅这是设置元素的值不是结构修改）。应该自行对于ArrayList进行线程同步，或者使用 Collections.synchronizedList 包裹ArrayList。这最好在创建时完成，以防止意外的非同步访问列表。1List list = Collections.synchronizedList(new ArrayList(...)); 由 iterator 和 listIterator 返回的迭代器是fail-fast的（故障快速失败）。如果在创建迭代器之后的任何时间以任何方式（除了通过迭代器自己的remove或add方法之外）对列表进行结构修改，迭代器将抛出一个ConcurrentModificationException。因此，在面临并发修改时，迭代器会快速的失败（fails quickly and cleanly），而不会在未来不确定的时间冒任意、非确定性行为的风险。但是要注意的是，fail-fast并不能在多线程的情况下完全保证，在并发情况下并不能作为hard guarantees。Fail-fast iterators会尽力（on a best-effort basis）的抛出ConcurrentModificationException。因此，编写依赖于此异常的程序来确保其正确性是错误的：迭代器的快速失败行为应该只用于检测bug。 成员elementData核心就是一个 elementData1transient Object[] elementData; 存储数组列表元素的数组缓冲区。数组的容量是这个数组缓冲器的长度。当添加第一个元素时，任何带有 elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA 的空ArrayList将被扩展为 DEFAULT_CAPACITY 。注意，这个 elementData 的访问级别不是 private，javaDoc里面说是为了便于嵌套的类的访问（non-private to simplify nested class access）。 sizeArrayList的大小，有多少个元素1private int size; DEFAULTCAPACITY_EMPTY_ELEMENTDATA描述空实例的共享对象。用这个以将此与 EMPTY_ELEMENTDATA 区分开来，以知道在添加第一个元素时要膨胀多少。1private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; EMPTY_ELEMENTDATA描述空数组的共享对象1private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; DEFAULT_CAPACITY默认初始化 capacity1private static final int DEFAULT_CAPACITY = 10; MAX_ARRAY_SIZE数组的最大大小有些VM在array里面保存了一些头，如果试图请求一个很大的array可能会导致OutOfMemoryError1234567/** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit*/private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; java.util.AbstractList#modCount1protected transient int modCount = 0; 对象的构造ArrayList 有3个构造函数 无参构造函数123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 这个将 elementData 初始化为 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 代表空对象，而在后面的逻辑中，如果是一个空对象，那么它的默认 capacity 是10 ArrayList(int initialCapacity)1234567891011public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 注意这里 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125; 这个构造函数传入了一个初始的 capacity ，传的多大，那么内部的数组开得就有多大。注意，如果为0，那么初始化为一个 EMPTY_ELEMENTDATA 空数组，而不是 new 了一个空的，个人觉得，这样的好处是可以方便的将空对象、空数组方便的区分开来。 ArrayList(Collection&lt;? extends E&gt; c)1234567891011121314public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // 注意这里，bug6260652 // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) // 返回生成一个 Object[] elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 如果是空的，那么替换为EMPTY_ELEMENTDATA // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 这个方法就是传入一个collection，并初始化为collection里面的元素。如果collection是空的，那么就初始化为 EMPTY_ELEMENTDATA。注意，代码里面提到了一个jdk的bug，6260652(参考，Jdk Bug6260652)还可以注意到，类型判断使用的是 elementData.getClass() != Object[].class ，这么写的原因参考 java中的instanceof和getClass() 附录Amortized Constant Time算法中Amortised time的理解constant-amortized-time ArrayList集合实现RandomAccess接口有何作用？为何LinkedList集合却没实现这接口]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 类加载分析]]></title>
    <url>%2F2018%2F11%2F09%2FJava-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[题目ex1问输出多少123456789101112131415161718192021public class SingleTon &#123; private static SingleTon singleTon = new SingleTon(); public static int count1; public static int count2 = 0; private SingleTon() &#123; count1++; count2++; &#125; public static SingleTon getInstance() &#123; return singleTon; &#125; public static void main(String[] args) &#123; SingleTon singleTon = SingleTon.getInstance(); System.out.println(&quot;count1=&quot; + singleTon.count1); System.out.println(&quot;count2=&quot; + singleTon.count2); &#125;&#125; 答案12count1=1count2=0 ex2问输出多少123456789101112131415161718192021public class SingleTon &#123; public static int count1; public static int count2 = 0; private static SingleTon singleTon = new SingleTon(); private SingleTon() &#123; count1++; count2++; &#125; public static SingleTon getInstance() &#123; return singleTon; &#125; public static void main(String[] args) &#123; SingleTon singleTon = SingleTon.getInstance(); System.out.println(&quot;count1=&quot; + singleTon.count1); System.out.println(&quot;count2=&quot; + singleTon.count2); &#125;&#125; 答案12count1=1count2=1 类加载的时机类从被加载到虚拟机内存中开始，直到卸载出内存为止，它的整个生命周期包括了：加载、验证、准备、解析、初始化、使用和卸载这7个阶段。其中，验证、准备和解析这三个部分统称为连接（linking）。其中，加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班的“开始”（仅仅指的是开始，而非执行或者结束，因为这些阶段通常都是互相交叉的混合进行，通常会在一个阶段执行的过程中调用或者激活另一个阶段），而解析阶段则不一定（它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定。 何时开始类的初始化什么情况下需要开始类加载过程的第一个阶段:”加载”。虚拟机规范中并没强行约束，这点可以交给虚拟机的的具体实现自由把握，但是对于初始化阶段虚拟机规范是严格规定了如下几种情况，如果类未初始化会对类进行初始化。 创建类的实例 访问类的静态变量(除常量【被final修辞的静态变量】原因:常量一种特殊的变量，因为编译器把他们当作值(value)而不是域(field)来对待。如果你的代码中用到了常变量(constant variable)，编译器并不会生成字节码来从对象中载入域的值，而是直接把这个值插入到字节码中。这是一种很有用的优化，但是如果你需要改变final域的值那么每一块用到那个域的代码都需要重新编译。 访问类的静态方法 反射如(Class.forName(“my.xyz.Test”)) 当初始化一个类时，发现其父类还未初始化，则先出发父类的初始化 虚拟机启动时，定义了main()方法的那个类先初始化 以上情况称为称对一个类进行“主动引用”，除此种情况之外，均不会触发类的初始化，称为“被动引用”接口的加载过程与类的加载过程稍有不同。接口中不能使用static{}块。当一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有真正在使用到父接口时（例如引用接口中定义的常量）才会初始化。 被动引用例子 子类调用父类的静态变量，子类不会被初始化。只有父类被初始化。对于静态字段，只有直接定义这个字段的类才会被初始化. 通过数组定义来引用类，不会触发类的初始化 访问类的常量，不会初始化类 12345678910111213141516171819class SuperClass &#123; static &#123; System.out.println("superclass init"); &#125; public static int value = 123;&#125; class SubClass extends SuperClass &#123; static &#123; System.out.println("subclass init"); &#125;&#125; public class Test &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value);// 被动应用1 SubClass[] sca = new SubClass[10];// 被动引用2 &#125;&#125; 程序运行输出12superclass init 123 从上面的输入结果证明了被动引用1与被动引用2123456789101112class ConstClass &#123; static &#123; System.out.println("ConstClass init"); &#125; public static final String HELLOWORLD = "hello world";&#125; public class Test &#123; public static void main(String[] args) &#123; System.out.println(ConstClass.HELLOWORLD);// 调用类常量 &#125;&#125; 程序输出结果1hello world 从上面的输出结果证明了被动引用3 类的加载过程加载 “加载”(Loading)阶段是“类加载”(Class Loading)过程的第一个阶段，在此阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区这些数据的访问入口。 加载阶段即可以使用系统提供的类加载器在完成，也可以由用户自定义的类加载器来完成。加载阶段与连接阶段的部分内容（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始。 验证验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。Java语言本身是相对安全的语言，使用Java编码是无法做到如访问数组边界以外的数据、将一个对象转型为它并未实现的类型等，如果这样做了，编译器将拒绝编译。但是，Class文件并不一定是由Java源码编译而来，可以使用任何途径，包括用十六进制编辑器(如UltraEdit)直接编写。如果直接编写了有害的“代码”(字节流)，而虚拟机在加载该Class时不进行检查的话，就有可能危害到虚拟机或程序的安全。不同的虚拟机，对类验证的实现可能有所不同，但大致都会完成下面四个阶段的验证：文件格式验证、元数据验证、字节码验证和符号引用验证。 文件格式验证，是要验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。如验证魔数是否0xCAFEBABE；主、次版本号是否正在当前虚拟机处理范围之内；常量池的常量中是否有不被支持的常量类型……，该验证阶段的主要目的是保证输入的字节流能正确地解析并存储于方法区中，经过这个阶段的验证后，字节流才会进入内存的方法区中存储，所以后面的三个验证阶段都是基于方法区的存储结构进行的。 元数据验证，是对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求。可能包括的验证如：这个类是否有父类；这个类的父类是否继承了不允许被继承的类；如果这个类不是抽象类，是否实现了其父类或接口中要求实现的所有方法…… 字节码验证，主要工作是进行数据流和控制流分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的行为。如果一个类方法体的字节码没有通过字节码验证，那肯定是有问题的；但如果一个方法体通过了字节码验证，也不能说明其一定就是安全的。 符号引用验证，发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在“解析阶段”中发生。验证符号引用中通过字符串描述的权限定名是否能找到对应的类；在指定类中是否存在符合方法字段的描述符及简单名称所描述的方法和字段；符号引用中的类、字段和方法的访问性（private、protected、public、default）是否可被当前类访问 验证阶段对于虚拟机的类加载机制来说，不一定是必要的阶段。如果所运行的全部代码确认是安全的，可以使用 -Xverify：none 参数来关闭大部分的类验证措施，以缩短虚拟机类加载时间。 准备准备阶段是为类的静态变量分配内存并将其初始化为默认值，这些内存都将在方法区中进行分配。准备阶段不分配类中的实例变量的内存，实例变量将会在对象实例化时随着对象一起分配在Java堆中。1public static int value=123; //在准备阶段value初始值为0 。在初始化阶段才会变为123 。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。符号引用（Symbolic Reference）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。直接引用（Direct Reference）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，如果有了直接引用，那么引用的目标必定已经在内存中存在。 初始化类初始化是类加载过程的最后一步，前面的类加载过程，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程。&lt;clinit&gt;()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的。 题目分析ex112345678910111213141516171819202122class SingleTon &#123; private static SingleTon singleTon = new SingleTon(); public static int count1; public static int count2 = 0; private SingleTon() &#123; count1++; count2++; &#125; public static SingleTon getInstance() &#123; return singleTon; &#125;&#125; public class Test &#123; public static void main(String[] args) &#123; SingleTon singleTon = SingleTon.getInstance(); System.out.println(&quot;count1=&quot; + singleTon.count1); System.out.println(&quot;count2=&quot; + singleTon.count2); &#125;&#125; 分析 SingleTon singleTon = SingleTon.getInstance(); 调用了类的SingleTon调用了类的静态方法，触发类的初始化 类加载的时候在准备过程中为类的静态变量分配内存并初始化默认值 singleton=null count1=0, count2=0 类初始化化，为类的静态变量赋值和执行静态代码快。singleton赋值为 new SingleTon() 调用类的构造方法。调用类的构造方法后 count=1; count2=1 继续为 count1 与 count2 赋值,此时 count1 没有赋值操作,所有 count1 为1,但是 count2 执行赋值操作就变为0]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis的持久化]]></title>
    <url>%2F2018%2F11%2F09%2FRedis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96-1%2F</url>
    <content type="text"><![CDATA[Redis有两种持久化的方式：快照（snapshotting），只追加文件（append-only file，AOF） 快照（RDB）创建存储在内存的某个时间的数据的副本 配置save可以写多个 或 关系的条件。这些条件只要有一个被满足就会执行快照；如果不写，那么就会完全禁用掉快照123save 900 1 # 900秒之后至少有1个key被修改，就快照save 300 10 # 300秒之后至少有10个key被修改，就快照save 60 10000 # 60秒之后至少有10000个key被修改，就快照 stop-writes-on-bgsave-error默认值 yes默认情况下，如果启用了RDB快照（至少一个保存点）并且最近的后台保存失败，Redis将停止接受写操作。这将使用户意识到数据没有正确地保存在磁盘上，否则很可能没有人会注意到并且会发生一些灾难。如果后台保存过程将再次开始工作，Redis将自动允许再次写入。但是，如果您已经对Redis服务器做了适当监视和持久性的配置，那么您可能希望禁用该特性，以便即使存在磁盘、权限等问题，Redis仍会像往常一样工作。 rdbcompression默认值 yes是否在创建dump(.rdb)文件的时候使用LZF对于字符串对象进行压缩。一般进行压缩是比较好的策略，但是如果想在减少一些CPU的使用，那么可以设为no dbfilename存储dump文件的文件名 创建快照的方法 发送 BGSAVEredis会fork（Windows不支持）一个子线程负责快照的写入，父进程继续处理请求。但是如果在一个内存占用比较高的redis，或者存储的数据很大的redis（数十GB）上，光是fork就会耗费很多的时间，而且子线程会同主线程争夺资源，可能会导致系统长时间的停顿（卡死） 发送 SAVEredis会在创建完快照前不会响应任何其他命令。很少用 根据 save 选项触发快照 收到 SHUTDOWN 命令关闭时，或者收到标准 TERM 信号关闭时redis会在关闭之前，执行一个 SAVE 服务器之间复制的时候SYNC 存在问题由于快照怎么配置都会有时间的延迟，保存的数据不会是实时的，所以一定会存在丢失数据的情况。所以，快照持久化只适用于即使丢失一部分数据也没有关系的应用程序。 AOF将被执行的命令写到aof文件末尾，恢复的时候需要从头到尾重新执行一次，注意，AOF和RDB可以同时开启，但是如果AOF开启了，那么启动的时候会优先读取AOF 配置appendonly开启或关闭 AOF appendfilenameAOF文件文件名，默认 “appendonly.aof” appendfsync操作系统文件写入的时候，会先写在缓存，然后再写入磁盘 always每个redis写命令都会被写入磁盘，但对于磁盘的写入太多了，收到磁盘性能的限制 no让操作系统来决定（可能会丢失数据） everysec每秒执行一次，显示写入磁盘no-appendfsync-on-rewrite 设置为yes。就相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，因此这样并不会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。在linux的操作系统的默认设置下，最多会丢失30s的数据。 默认设置为no。 auto-aof-rewrite-*当AOF文件大于64M,并且体积比上一次重写之后的大小大了一倍（100%）时，进行BGREWRITEAOF12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb aof-load-truncatedredis再恢复时，忽略最后一条可能存在问题的指令(因为最后一条指令可能存在问题，比如写一半时突然断电了) aof-use-rdb-preambleRedis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF格式的内存则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）。 BGREWRITEAOF 机制AOF 文件一般会很大，用户可以向redis发送 BGREWRITEAOF ，通过移除AOF文件中的冗余命令来重写AOF文件。BGREWRITEAOF机制，在一个子进程中进行AOF的重写，从而不阻塞主进程对其余命令的处理，同时解决了AOF文件过大问题。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Curator 事务操作]]></title>
    <url>%2F2018%2F11%2F06%2FCurator-%E4%BA%8B%E5%8A%A1%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[网上很多Curator事务操作使用的是client.inTransaction()，但现在已经废弃了。我使用的Curator版本为4.0.1 使用方法12345678910111213141516171819202122232425object Transaction extends App &#123; val retryPolicy = new ExponentialBackoffRetry(1000, 3) val client = CuratorFrameworkFactory.builder() .connectString(ZOOKEEPER_HOST) .sessionTimeoutMs(5000) .connectionTimeoutMs(1000) .retryPolicy(retryPolicy) .build() client.start() val transaction = client.transaction() val option = new util.ArrayList[CuratorOp]() for (i &lt;- 1 to 3) &#123; option.add(client.transactionOp().create().forPath(s"/path$i")) &#125; try &#123; val result = transaction.forOperations(option) result.forEach(r =&gt; println(s"&#123;type: $&#123;r.getType&#125;, forPath: $&#123;r.getForPath&#125;," + s" resultPath: $&#123;r.getResultPath&#125;, resultStat: $&#123;r.getResultStat&#125;&#125;")) &#125; catch &#123; case NonFatal(e) =&gt; System.err.print(e.getMessage) &#125;&#125; 123&#123;type: CREATE, forPath: /path1, resultPath: /path1, resultStat: null&#125;&#123;type: CREATE, forPath: /path2, resultPath: /path2, resultStat: null&#125;&#123;type: CREATE, forPath: /path3, resultPath: /path3, resultStat: null&#125; 存在问题TransactionOp的delete没有deletingChildrenIfNeeded，个人觉得很不方便，不知道有什么办法处理这个问题]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>Curator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper的工作原理]]></title>
    <url>%2F2018%2F11%2F05%2FZooKeeper%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[角色划分leader 事务请求的唯一调度者和处理者，保证集群事务处理的顺序性 集群内部各服务器的调度者 learnerfollower 处理客户端非事务请求，转发事务请求给leader。意味着，如果客户端要读取数据，那么就直接从follower本地拿，速度快。如果客户端要写数据，那么会将这个请求转发给leader，由leader进行统一的处理。 参与事务请求proposal的投票 参与leader选举的投票（可能会成为下一个leader） observer 对于客户端请求的处理和follower一样。处理客户端非事务请求，转发事务请求给leader。 不参与事务请求proposal的投票（仅仅同步leader的状态） 不参与leader的选举投票（不可能成为leader） ZooKeeper增加Observer部署模式提高性能 为什么要有observerobserver是为了系统的扩展性而存在的，可以提高系统读取的效率。一句话：在不伤害写性能的情况下扩展Zookeeper 尽管通过Client直接连接到Zookeeper集群的性能已经非常好了，但是这种架构如果要承受超大规模的Client，就必须增加Zookeeper集群的Server数量，随着Server的增加，Zookeeper集群的写性能必定下降，我们知道Zookeeper的Znode变更是要过半数投票通过，随着机器的增加，由于网络消耗等原因必然导致投票成本增加，从而导致写性能的下降。Observer是一种新型的Zookeeper节点，可以帮助解决上述问题，提供Zookeeper的可扩展性。Observer不参与投票，只是简单的接收投票结果，因此我们增加再多的Observer，也不会影响集群的写性能。除了这个差别，其他的和Follower基本上完全一样。例如：Client都可以连接到他们，并且都可以发送读写请求给他们，收到写请求都会上报到Leader。Observer有另外一个优势，因为它不参与投票，所以他们不属于Zookeeper集群的关键部位，即使他们Failed，或者从集群中断开，也不会影响集群的可用性。根据Observer的特点，我们可以使用Observer做跨数据中心部署。如果把Leader和Follower分散到多个数据中心的话，因为数据中心之间的网络的延迟，势必会导致集群性能的大幅度下降。使用Observer的话，将Observer跨机房部署，而Leader和Follower部署在单独的数据中心，这样更新操作会在同一个数据中心来处理，并将数据发送的其他数据中心（包含Observer的），然后Client就可以在其他数据中心查询数据了。但是使用了Observer并非就能完全消除数据中心之间的延迟，因为Observer还得接收Leader的同步结果合Observer有更新请求也必须转发到Leader，所以在网络延迟很大的情况下还是会有影响的，它的优势就为了本地读请求的快速响应。 client就是客户端，是请求的发起方 设计目的 最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。 可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。 实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。 等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。 原子性：更新只能成功或者失败，没有中间状态。 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。 工作原理ZooKeeper的核心是ZAB协议（ZooKeeper Atomic Broadcase），并没有完全采用Paxos。ZAB协议有两个基本模式，崩溃恢复和消息广播。 服务器状态 LOOKING：寻找leader状态。说明集群中没有leader，因此需要进入leader选举流程 FOLLOWING：表明当前服务器角色是follower LEADING：表明当前服务器角色是leader OBSERVING：表明当前服务器角色是observer 术语、数据SIDSID是一个数字，用来唯一标识一台ZooKeeper集群中的机器，每台机器不能重复，等于myid。myid配置在zoo.cfg配置文件的dataDir所值的目录下的myid文件中 ZXIDZXID事务ID，用来唯一标识服务器状态的变更。ZXID是一个64位的数字，其中低32位可以看成是一个简单的单调计数器，针对客户端的每一个事务请求，leader在产生新的proposal的时候，都会对这个计数器进行加一；高32位代表了leader周期的epoch编号，用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个 新的epoch，标识当前属于那个leader的统治时期。使用ZXID大大简化了数据恢复的流程。 Quorum过半数机器数。ZooKeeper有一个过半数的机制，ZooKeeper中的Quorum有两个作用： 集群中最少要Quorum个节点用来选举Leader，保证集群可用 通知客户端数据已经安全保存前集群中最少有Quorum个节点已经保存了该数据。一旦这些节点保存了该数据，客户端将被通知已经安全保存了，可以继续其他任务。而集群中剩余的节点将会最终也保存了该数据 而且很多人都说，ZooKeeper的节点数最好是奇数，原因如下： 容错从成本上来说，使用奇数个节点是最划算的。 123452台服务器，至少2台正常运行才行（2的半数为1，半数以上最少为2），正常运行1台服务器都不允许挂掉 3台服务器，至少2台正常运行才行（3的半数为1.5，半数以上最少为2），正常运行可以允许1台服务器挂掉 4台服务器，至少3台正常运行才行（4的半数为2，半数以上最少为3），正常运行可以允许1台服务器挂掉 5台服务器，至少3台正常运行才行（5的半数为2.5，半数以上最少为3），正常运行可以允许2台服务器挂掉 6台服务器，至少3台正常运行才行（6的半数为3，半数以上最少为4），正常运行可以允许2台服务器挂掉 防止脑裂（Split-Brain）这个是个人觉得是最重要的作用。Split-Brain问题说的是1个集群如果发生了网络故障，很可能出现1个集群分成了两部分，而这两个部分都不知道对方是否存活，不知道到底是网络问题还是直接机器down了，所以这两部分都要选举1个Leader，而一旦两部分都选出了Leader, 并且网络又恢复了，那么就会出现两个Brain的情况，整个集群的行为就不一致了。这样的方式可以确保leader的唯一性，要么选出唯一的一个leader，要么选举失败。但是很明显，如果是偶数个节点数，会出现集群不可用的情况。例如 1234一个集群3台服务器，全部运行正常，但是其中1台裂开了，和另外2台无法通讯。3台机器里面2台正常运行过半票可以选出一个leader。 一个集群4台服务器，全部运行正常，但是其中2台裂开了，和另外2台无法通讯。4台机器里面2台正常工作没有过半票以上达到3，无法选出leader正常运行。 一个集群5台服务器，全部运行正常，但是其中2台裂开了，和另外3台无法通讯。5台机器里面3台正常运行过半票可以选出一个leader。 一个集群6台服务器，全部运行正常，但是其中3台裂开了，和另外3台无法通讯。6台机器里面3台正常工作没有过半票以上达到4，无法选出leader正常运行。 崩溃恢复leader选举发生的时机： 服务器初始化启动 服务器运行期间无法同leader保持连接。leader和follower之间都通过心跳检测机制来感知彼此，如果在指定的超时时间内leader无法从过半的follower进程那里接收到心跳，或者TCP连接断开了，那么leader就会终止对当前周期的领导，转换为LOOKING状态。follower也会放弃这个leader，转换为LOOKING状态。 当一台机器进入leader选举的时候，集群可能存在两种状态： 已经存在一个leader 确实不存在leader 已经存在一个leader启动的时候，试图去选举leader的时候，会被告知已经存在leader，于是仅仅只需要和leader机器建立连接，同步状态即可。 确实不存在leader下面是一个简版的例子，实际的流程要复杂很多现有SID分别为1、2、3、4、5的机器，ZXID分别为9、9、9、8、8，并且此时SID为2的机器是leader。某一个时刻，1、2所在机器出现故障，于是开始leader选举。选票的格式表示为(SID, ZXID)（下面的例子是一个简化版本的，实际上） 第一次投票，每台机器都投自己，（3，9），（4，8），（5，8） 对于server3，收到（4，8），（5，8），自己的是（3，9），自己的ZXID大于接收到的，不变更投票 对于server4，收到（3，9），（5，8），自己的是（4，8），（3，9）的ZXID大于自己的，变更投票，将（3，9）发送给其他机器 对于server5，收到（3，9），（4，8），同理，变更投票，将（3，9）发送给其他机器 由于server3有超过半数的投票，确定server3为新的leader 通常，哪台服务器数据越新，越有可能成为leader，因为它的ZXID更大。 流程图这里面有两个关键的pk判断 判断选举轮次 外部投票的选举轮次大于自己的那么就清空已经收到的投票，更新自己的logicalclock，使用初始化的投票来判断是否需要更新内部投票，最终再将结果发送出去 外部投票的选举轮次小于自己的直接忽略，等待接收下一个外部投票（回到图上的接受外部投票） 外部投票的选举轮次等于自己的开始选票pk 选票pk 外部投票中推举的leader服务器的选举轮次大于自己的，那么变更投票 选举轮次一致，比较ZXID，ZXID大的获胜 ZXID一致，比较SID，SID大的获胜 注意，当统计后发现过半数认可了当前选票之后，并不会立即更新服务器状态，而是会等待一段时间（默认200毫秒）来确定是否有新的更优的投票 源码执行流程对应代码 org.apache.zookeeper.server.quorum.FastLeaderElection.lookForLeader注释版本FastLeaderElection.java FastLeaderElection与QuorumCnxManager关系选leader时消息的收发依赖QuorumCnxManager,它作为server之间的IO管理器 两个vote的全序大小比较规则总结依次根据peerEpoch，zxid，sid来（totalOrderPredicate） peerEpoch代表所处周期，越大则投票越新 peerEpoch相同时，zxid代表一个周期中的事务记录，越大则投票越新 peerEpoch，zxid均相同时，sid大的赢（两个投票一样新，只是为了决定leader需要有大小关系） 选举投票leader的验证问题 如果消息发送方state是looking，则termPredicate看是否过半即可 如果消息发送方state是following或者leading，则ooePredicate看是否过半，且leader机器发出ack知道了自己是leader即可 集群中是否所有机器是否都是网络互通三台机器ABC，AB网络不通但是A，B，C投票都给CC收到三张票，过半，自己成为leaderB知道C得到了两张票，分别是BC投给C（B不知道A投给了C），也过半，自己成为follower同理，A也成为follower 是否会出现looking机器和leader机器网络不通，但收了过半的leader投票，因此认定了leader的合理性123假设5台机器ABCDE，ABCD已经形成集群，以D为leader这时E以looking状态进来，收到了ABC以following状态的投票，这时就过半了E会不会把D当成leader 这就是checkLeader函数的意义里面会有检查123456if(leader != self.getId())&#123;// 自己不为leader if(votes.get(leader) == null) predicate = false;// 投票记录中，没有来自leader的投票 else if(votes.get(leader).getState() != ServerState.LEADING) predicate = false;//leader不知道自己是leader&#125; else if(logicalclock != electionEpoch) &#123;// 如果大家认为我是leader，但是逻辑时钟不等于选举周期 predicate = false;&#125; 如果网络不通，那么就会votes.get(leader) == null，因此E不会把D当成leader 竞选leader是”广播”吗？选举leader不是广播，后续一致性同步才是广播。这里就是所有server互相通信完成的 数据同步一旦leader选举完成，就开始进入恢复阶段，就是follower要同步leader上的数据信息这里面有几个数据： long lastProcessedZxid最后一次commit的事务请求的zxid LinkedList committedLog、long maxCommittedLog、long minCommittedLogZooKeeper会保存最近一段时间内执行的事务请求议案，个数限制默认为500个议案。上述committedLog就是用来保存议案的列表，上述maxCommittedLog表示最大议案的zxid，minCommittedLog表示committedLog中最小议案的zxid。 通信初始化leader会创建一个ServerSocket，接收follower的连接，leader会为每一个连接会用一个LearnerHandler线程来进行服务 重新为peerEpoch选举出一个新的peerEpochfollower会向leader发送一个Leader.FOLLOWERINFO信息，包含自己的peerEpoch信息leader的LearnerHandler会获取到上述peerEpoch信息，leader从中选出一个最大的peerEpoch，然后加1作为新的peerEpoch。然后leader的所有LearnerHandler会向各自的follower发送一个Leader.LEADERINFO信息，包含上述新的peerEpochfollower会使用上述peerEpoch来更新自己的peerEpoch，同时将自己的lastProcessedZxid发给leaderleader的所有LearnerHandler会记录上述各自follower的lastProcessedZxid，然后根据这个lastProcessedZxid和leader的lastProcessedZxid之间的差异进行同步 已经处理的事务议案的同步判断LearnerHandler中的lastProcessedZxid是否在minCommittedLog和maxCommittedLog之间 LearnerHandler中的lastProcessedZxid和leader的lastProcessedZxid一致，则说明已经保持同步了 如果lastProcessedZxid在minCommittedLog和maxCommittedLog之间从lastProcessedZxid开始到maxCommittedLog结束的这部分议案，重新发送给该LearnerHandler对应的follower，同时发送对应议案的commit命令 。 就是说leader会发送一堆的连续的PROPOSAL，COMMIT的消息上述可能存在一个问题：即lastProcessedZxid虽然在他们之间，但是并没有找到lastProcessedZxid对应的议案，即这个zxid是leader所没有的，此时的策略就是完全按照leader来同步，删除该follower这一部分的事务日志，然后重新发送这一部分的议案，并提交这些议案 如果lastProcessedZxid大于maxCommittedLog则删除该follower大于部分的事务日志 如果lastProcessedZxid小于minCommittedLog则直接采用快照的方式来恢复 未处理的事务议案的同步LearnerHandler还会从leader的toBeApplied数据中将大于该LearnerHandler中的lastProcessedZxid的议案进行发送和提交（toBeApplied是已经被确认为提交的）LearnerHandler还会从leader的outstandingProposals中大于该LearnerHandler中的lastProcessedZxid的议案进行发送，但是不提交（outstandingProposals是还没被被确认为提交的） 将LearnerHandler加入到正式follower列表中意味着该LearnerHandler正式接受请求。即此时leader可能正在处理客户端请求，leader针对该请求发出一个议案，然后对该正式follower列表才会进行执行发送工作。这里有一个地方就是：上述我们在比较lastProcessedZxid和minCommittedLog和maxCommittedLog差异的时候，必须要获取leader内存数据的读锁，即在此期间不能执行修改操作，当欠缺的数据包已经补上之后（先放置在一个队列中，异步发送），才能加入到正式的follower列表，否则就会出现顺序错乱的问题同时也说明了，一旦一个follower在和leader进行同步的过程（这个同步过程仅仅是确认要发送的议案，先放置到队列中即可等待异步发送，并不是说必须要发送过去），该leader是暂时阻塞一切写操作的。对于快照方式的同步，则是直接同步写入的，写入期间对数据的改动会放在上述队列中的，然后当同步写入完成之后，再启动对该队列的异步写入。上述的要理解的关键点就是：既要不能漏掉，又要保证顺序 LearnerHandler发送Leader.NEWLEADER以及Leader.UPTODATE命令该命令是在同步结束之后发的。对于DIFF类型的，会在一堆PROPOSAL，COMMIT之后发送NEWLEADER。follower收到该命令之后会执行一次版本快照等初始化操作，如果收到该命令的ACK则说明follower都已经完成同步了并完成了初始化之后进入过半等待阶段——leader会同其他learner服务器进行上述同样的数据同步，直到集群中有过半数的机器响应了。LearnerHandler向对应的follower发送Leader.UPTODATE，follower接收到之后，终止数据同步流程，集群正式开始对外服务 消息广播 数据字段 ConcurrentMap outstandingProposalsLeader拥有的属性，每当提出一个议案，都会将该议案存放至outstandingProposals，一旦议案被过半认同了，就要提交该议案，则从outstandingProposals中删除该议案 ConcurrentLinkedQueue toBeAppliedLeader拥有的属性，这个队列中保存了已经完成投票（即commit）的proposal，但是这些proposal还没有应用到本机的内存中（这个工作是由FinalRequestProcessor来完成的） 处理流程 leader针对客户端的事务请求（leader为该请求分配了zxid），创建出一个议案，并将zxid和该议案存放至leader的outstandingProposals中 leader开始向所有的follower发送该议案（Proposal），如果过半的follower回复OK的话（Ack），则leader认为可以提交该议案，则将该议案从outstandingProposals中删除，然后存放到toBeApplied中 leader对该议案进行提交（commit），会向所有的follower发送提交该议案的命令，leader自己也开始执行提交过程（传递给FinalRequestProcessor处理）。（FinalRequestProcessor）会将该请求的内容应用到ZooKeeper的内存树中，然后更新lastProcessedZxid为该请求的zxid，同时将该请求的议案存放到上述committedLog，同时更新maxCommittedLog和minCommittedLog 从toBeApplied中删除对应的proposal 参考Zookeeper的Quorum机制-谈谈怎样解决脑裂(split-brain)zookeeper集群为什么要是单数一直对zookeeper的应用和原理比较迷糊，今天看一篇文章，讲得很通透，分享如下zookeeper中的ZAB协议理解zk源码阅读30:leader选举:FastLeaderElection源码解析一个还不错的博客——赤子心ZAB]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[synchronized]]></title>
    <url>%2F2018%2F10%2F31%2Fsynchronized%2F</url>
    <content type="text"><![CDATA[锁在非静态方法上测试代码代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class ClassA &#123; public synchronized void f1() throws Exception &#123; System.out.println("f1 start"); Thread.sleep(1000); f3(); System.out.println("f1 end"); &#125; public synchronized void f2() throws Exception &#123; System.out.println("f2 start"); Thread.sleep(1000); System.out.println("f2 end"); &#125; public synchronized void f3() throws Exception &#123; System.out.println("f3 start"); Thread.sleep(1000); System.out.println("f3 end"); &#125; static void case1()&#123; System.out.println("case1================================="); final ClassA classA = new ClassA(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classA.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; classA.f2(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; static void case2()&#123; System.out.println("case2================================="); final ClassA classA1 = new ClassA(); final ClassA classA2 = new ClassA(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classA1.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; classA2.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; public static void main(String[] args) &#123; case1(); // case2(); &#125;&#125; 1234567case1=================================Thread-0 f1 startThread-0 f3 startThread-0 f3 endThread-0 f1 endThread-1 f2 startThread-1 f2 end 123456789case2=================================Thread-0 f1 startThread-1 f1 startThread-0 f3 startThread-1 f3 startThread-0 f3 endThread-1 f3 endThread-1 f1 endThread-0 f1 end 结果分析 可重入的 锁的是某一个具体的对象实例的所有方法 对于某个对象实例，同一时间只能调用这个实例的其中的一个方法 锁在静态方法上测试代码代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class ClassB &#123; public synchronized static void f1() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f1 start"); Thread.sleep(1000); f3(); System.out.println(Thread.currentThread().getName() + " f1 end"); &#125; public synchronized static void f2() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f2 start"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " f2 end"); &#125; public synchronized static void f3() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f3 start"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " f3 end"); &#125; static void case1() &#123; System.out.println("case1================================="); Thread t1 = new Thread(() -&gt; &#123; try &#123; ClassB.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; ClassB.f2(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; static void case2() &#123; System.out.println("case2================================="); Thread t1 = new Thread(() -&gt; &#123; try &#123; ClassB.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; ClassB.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; static void case3() &#123; System.out.println("case3================================="); ClassB classB1 = new ClassB(); ClassB classB2 = new ClassB(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classB1.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; classB2.f2(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; public static void main(String[] args) &#123; case3(); &#125;&#125; 测试结果1234567case1=================================Thread-0 f1 startThread-0 f3 startThread-0 f3 endThread-0 f1 endThread-1 f2 startThread-1 f2 end 123456789case2=================================Thread-0 f1 startThread-0 f3 startThread-0 f3 endThread-0 f1 endThread-1 f1 startThread-1 f3 startThread-1 f3 endThread-1 f1 end 1234567case3=================================Thread-0 f1 startThread-0 f3 startThread-0 f3 endThread-0 f1 endThread-1 f2 startThread-1 f2 end 结果分析 可重入的 锁的是所有加锁了的静态方法 无论是对于同一个对象 (classB1.f1(), classB1.f2()) 还是不同是对象 (classB1.f1(), classB2.f2())，或者没有对象(CLassB.f1(), ClassB.f2())（因为static不属于任何一个对象），同一时间都只能有一个调用其中的一个方法 锁在静态方法上，和不在静态方法上同时存在测试代码代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115public class ClassC &#123; public synchronized void f1() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f1 start"); Thread.sleep(1000); f3(); System.out.println(Thread.currentThread().getName() + " f1 end"); &#125; public synchronized void f2() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f2 start"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " f2 end"); &#125; public synchronized static void f3() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f3 start"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " f3 end"); &#125; public synchronized static void f4() throws Exception &#123; System.out.println(Thread.currentThread().getName() + " f4 start"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + " f4 end"); &#125; static void case1()&#123; System.out.println("case1================================="); final ClassC classC = new ClassC(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classC.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; ClassC.f3(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; static void case2()&#123; System.out.println("case1================================="); final ClassC classC = new ClassC(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classC.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; classC.f3(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; static void case3()&#123; System.out.println("case1================================="); final ClassC classC = new ClassC(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classC.f2(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; ClassC.f3(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; static void case4()&#123; System.out.println("case4================================="); final ClassC classC = new ClassC(); Thread t1 = new Thread(() -&gt; &#123; try &#123; classC.f1(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); Thread t2 = new Thread(() -&gt; &#123; try &#123; ClassC.f4(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); t1.start(); t2.start(); &#125; public static void main(String[] args) &#123; case3(); &#125;&#125; 测试结果1234567case1=================================Thread-1 f3 startThread-0 f1 startThread-1 f3 endThread-0 f3 startThread-0 f3 endThread-0 f1 end 1234567case2=================================Thread-1 f3 startThread-0 f1 startThread-1 f3 endThread-0 f3 startThread-0 f3 endThread-0 f1 end 12345case3=================================Thread-0 f2 startThread-1 f3 startThread-0 f2 endThread-1 f3 end 1234567case4=================================Thread-1 f4 startThread-0 f1 startThread-1 f4 endThread-0 f3 startThread-0 f3 endThread-0 f1 end 结果分析 非静态方法的锁 和 静态方法上的锁互不影响 意味着这两个会并行执行 如果在 非静态方法 中调用了 静态方法，同时有其他地方调用了静态方法，那么会相互之间竞争静态方法的使用权 静态方法中 synchronized (xxx.class)代码代码就不粘贴了，直接说结论。执行方式和 public synchronized static void 一样 synchronized (this)代码代码就不粘贴了，直接说结论。执行方式和 public synchronized void 一样 总结Java Synchronized Block for .class 个人理解，一个 ClassE.class 就类似于一个变量，synchronized(ClassE.class)就是在这个唯一的变量上加锁，所以如果在同一个类中，既有synchronized(ClassE.class)又有synchronized(ClassD.class)，那么这两个方法其实是可以并行执行的；如果在加在同一个ClassE.class上，无论是不是静态方法，甚至不是一个类（例如一个在ClassE，一个在ClassF），都会相互竞争。 synchronized(this)的锁和synchronized(ClassE.class)的锁不是一把锁。 synchronized(this) 在这个对象上加锁，仅仅是指的是内存中，这一个对象，跟其他同类型的其他对象没有关系。同一时间，只能有一个线程拿到这个对象的锁以运行代码。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Curator Barrier]]></title>
    <url>%2F2018%2F10%2F30%2FCurator-Barrier%2F</url>
    <content type="text"><![CDATA[Curator中有两种Barrier的实现。 DistributedBarrier 在子线程中等待阻塞，主线程中统一放行 DistributedDoubleBarrier 跟主线程就没有太大的联系了，子线程统一进入 barrier，统一离开 barrier DistributedBarrier使用方法123456789101112131415161718192021222324object CuratorBarrier01 extends App &#123; val PATH = "/barrier01" curatorContext &#123; client =&gt; val barrier = new DistributedBarrier(client, PATH) for (i &lt;- 0 until 5) &#123; new Thread(() =&gt; &#123; println(Thread.currentThread().getName) barrier.setBarrier() barrier.waitOnBarrier() println(s"$&#123;Thread.currentThread().getName&#125; start") &#125;).start() &#125; Thread.sleep(2000) barrier.removeBarrier() Thread.sleep(100) &#125;&#125; 实现思路DistributedBarrier 的实现比较简单，整体思路是所有子线程监听同一个节点路径，主线程删除了这个节点之后，子线程收到删除事件，就实现了统一的放行。代码很短，就不再赘述了。 DistributedDoubleBarrier使用方法1234567891011121314151617181920212223242526object CuratorBarrier02 extends App &#123; val PATH = "/barrier01" curatorContext &#123; client =&gt; for (i &lt;- 0 until 5) &#123; new Thread(() =&gt; &#123; val barrier = new DistributedDoubleBarrier(client, PATH, 5) Thread.sleep(Random.nextInt(5) * 1000) println(s"$&#123;Thread.currentThread().getName&#125; enter") barrier.enter() println(s"$&#123;Thread.currentThread().getName&#125; start ...") Thread.sleep(Random.nextInt(5) * 1000) barrier.leave() println(s"$&#123;Thread.currentThread().getName&#125; leave") &#125;).start() &#125; while (true) &#123;&#125; &#125;&#125; 123456789101112131415Thread-1 enterThread-3 enterThread-2 enterThread-5 enterThread-4 enterThread-2 start ...Thread-4 start ...Thread-1 start ...Thread-5 start ...Thread-3 start ...Thread-5 leaveThread-3 leaveThread-4 leaveThread-2 leaveThread-1 leave 实现思路构造函数123456789public DistributedDoubleBarrier(CuratorFramework client, String barrierPath, int memberQty) &#123; Preconditions.checkState(memberQty &gt; 0, "memberQty cannot be 0"); this.client = client; this.barrierPath = PathUtils.validatePath(barrierPath); this.memberQty = memberQty; ourPath = ZKPaths.makePath(barrierPath, UUID.randomUUID().toString()); readyPath = ZKPaths.makePath(barrierPath, READY_NODE);&#125; ourPath 是每个子线程都独有的节点 readyPath 当全部节点都enter之后，会创建这个节点，代表子线程都已经调用了enter可以继续运行了。其值是 {barrierPath}/ready enter123456789101112131415161718public boolean enter(long maxWait, TimeUnit unit) throws Exception &#123; long startMs = System.currentTimeMillis(); boolean hasMaxWait = (unit != null); long maxWaitMs = hasMaxWait ? TimeUnit.MILLISECONDS.convert(maxWait, unit) : Long.MAX_VALUE; // 判断readyPath是否已经存在了，并监听 boolean readyPathExists = (client.checkExists().usingWatcher(watcher).forPath(readyPath) != null); // 创建当前线程的节点 client.create().creatingParentContainersIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(ourPath); // internalEnter会阻塞，进入等待 boolean result = (readyPathExists || internalEnter(startMs, hasMaxWait, maxWaitMs)); if (connectionLost.get()) &#123; throw new KeeperException.ConnectionLossException(); &#125; return result;&#125; internalEnter是enter方法实际上阻塞的地方123456789101112131415161718192021222324252627282930313233343536private synchronized boolean internalEnter(long startMs, boolean hasMaxWait, long maxWaitMs) throws Exception &#123; boolean result = true; do &#123; // 获得子节点列表 List&lt;String&gt; children = getChildrenForEntering(); int count = (children != null) ? children.size() : 0; if (count &gt;= memberQty) &#123; // 如果数量已经达到了barrier的数量，则创建ready节点 try &#123; client.create().forPath(readyPath); &#125; catch (KeeperException.NodeExistsException ignore) &#123; // ignore &#125; break; &#125; if (hasMaxWait &amp;&amp; !hasBeenNotified.get()) &#123; long elapsed = System.currentTimeMillis() - startMs; long thisWaitMs = maxWaitMs - elapsed; if (thisWaitMs &lt;= 0) &#123; result = false; &#125; else &#123; wait(thisWaitMs); &#125; if (!hasBeenNotified.get()) &#123; result = false; &#125; &#125; else &#123; wait(); &#125; &#125; while (false); // 不知道为什么这里既然是false为什还要用 do while return result;&#125; 整体上的思路并不复杂 获得子节点列表 判断子节点数目是否达到了barrier要求的放行数目 如果达到了，则创建 ready 节点，函数返回；如果没有达到则 wait 由于在 enter 里面监听了 ready ，那么当某个子线程发现达到数目要求并创建 ready 节点的时候，会触发 watcher，通知所有子线程，函数结束返回。 存在几一个疑点 不知道 do while(false) 有什么用 leave、internalLeaveleave里面就是简单的处理了以下参数，然后调用了 internalLeave ，所以直接看 internalLeave。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586private boolean internalLeave(long startMs, boolean hasMaxWait, long maxWaitMs) throws Exception &#123; String ourPathName = ZKPaths.getNodeFromPath(ourPath); boolean ourNodeShouldExist = true; boolean result = true; for (; ; ) &#123; if (connectionLost.get()) &#123; throw new KeeperException.ConnectionLossException(); &#125; List&lt;String&gt; children; try &#123; // 获得所有子节点（这里面有ready节点） children = client.getChildren().forPath(barrierPath); &#125; catch (KeeperException.NoNodeException dummy) &#123; children = Lists.newArrayList(); &#125; // 把ready节点过滤掉并根据字典排序 children = filterAndSortChildren(children); if ((children == null) || (children.size() == 0)) &#123; // 没有子节点了，不再阻塞 break; &#125; // 当前线程的子节点位于子节点列表中的哪个位置 int ourIndex = children.indexOf(ourPathName); if ((ourIndex &lt; 0) &amp;&amp; ourNodeShouldExist) &#123; // 如果发现神奇的不存在，那么就说明出现问题了 if (connectionLost.get()) &#123; break; // connection was lost but we've reconnected. However, our ephemeral node is gone &#125; else &#123; throw new IllegalStateException(String.format("Our path (%s) is missing", ourPathName)); &#125; &#125; // 如果现在只剩下一个节点了 if (children.size() == 1) &#123; if (ourNodeShouldExist &amp;&amp; !children.get(0).equals(ourPathName)) &#123; // 如果发现神奇的不存在，那么就说明出现问题了 throw new IllegalStateException(String.format("Last path (%s) is not ours (%s)", children.get(0), ourPathName)); &#125; // 根据存在的状态将这个节点删除 checkDeleteOurPath(ourNodeShouldExist); break; &#125; Stat stat; boolean IsLowestNode = (ourIndex == 0); if (IsLowestNode) &#123; // 如果是第一个节点，那么检查最后的一个节点是否存在，并监听checkExists String highestNodePath = ZKPaths.makePath(barrierPath, children.get(children.size() - 1)); stat = client.checkExists().usingWatcher(watcher).forPath(highestNodePath); &#125; else &#123; // 不是第一个节点，或者当前节点已经不存在了，那么检查第一个节点是否存在，并监听checkExists String lowestNodePath = ZKPaths.makePath(barrierPath, children.get(0)); stat = client.checkExists().usingWatcher(watcher).forPath(lowestNodePath); // 然后根据存在的状态删除这个线程的节点 checkDeleteOurPath(ourNodeShouldExist); ourNodeShouldExist = false; &#125; if (stat != null) &#123; // 监听的节点存在 // 进入阻塞等待 if (hasMaxWait) &#123; long elapsed = System.currentTimeMillis() - startMs; long thisWaitMs = maxWaitMs - elapsed; if (thisWaitMs &lt;= 0) &#123; result = false; &#125; else &#123; wait(thisWaitMs); &#125; &#125; else &#123; wait(); &#125; &#125; &#125; try &#123; // 删除ready节点 client.delete().forPath(readyPath); &#125; catch (KeeperException.NoNodeException ignore) &#123; // ignore &#125; return result;&#125; 以一个例子来说明处理的流程现在有 L1、L2、L3、L4 4个子线程的节点。 首先，L1 leave，因为是子节点列表中的第一个节点，所以就单纯的监听列表中的最后一个节点，最后阻塞。 L4 leave，不是首个节点，删除自己，并监听第一个节点，置ourNodeShouldExist为false。触发了 L1 的 watcher，notifyAll 阻塞的子线程（L1，L4)。L1重新监听现在的最后的一个节点 L3，最后再一次阻塞。L4 由于ourNodeShouldExist为false，所以实际上并不执行什么实际上的逻辑，监听第一个节点，再一次阻塞。 L2 leave，不是首个节点，删除自己，并监听第一个节点，置ourNodeShouldExist为false。最后阻塞。 L3 leave，不是首个节点，删除自己，并监听第一个节点，置ourNodeShouldExist为false。触发了 L1 的 watcher，notifyAll 阻塞的子线程（L1，L2，L3，L4)，除了L1，其他的ourNodeShouldExist都为false，所以没有什么操作。L1 的子线程发现现在只有自己了，则删除自己，L1 子线程继续执行。L1 删除触发 watcher，其他子线程发现子节点列表为空，不再阻塞，子线程继续执行。]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
        <tag>Curator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Curator DistributedAtomicInteger]]></title>
    <url>%2F2018%2F10%2F30%2FCurator-DistributedAtomicInteger%2F</url>
    <content type="text"><![CDATA[DistributedAtomicInteger 提供分布式的计数器 使用方法123456789101112object AtomicInt extends App &#123; val PATH = "/atomicInt" curatorContext &#123; client =&gt; val atomicInt = new DistributedAtomicInteger(client, PATH, new RetryNTimes(3, 1000)) val res = atomicInt.add(8) println(s"Result: $&#123;res.preValue()&#125; $&#123;res.postValue()&#125;") &#125;&#125; 原理解析DistributedAtomicInteger 整体来说不难。其内部只有一个成员变量1private final DistributedAtomicValue value; 其实它的所有操作其实都是调用的DistributedAtomicValue的方法。 值的修改DistributedAtomicInteger 的 add、subtract、decrement、increment 其实都是调用的 DistributedAtomicInteger 的 worker方法，而在worker里面核心又是调用的 DistributedAtomicValue 的 trySet方法123456789101112131415private AtomicValue&lt;Integer&gt; worker(final Integer addAmount) throws Exception &#123; Preconditions.checkNotNull(addAmount, "addAmount cannot be null"); MakeValue makeValue = new MakeValue() &#123; @Override public byte[] makeFrom(byte[] previous) &#123; int previousValue = (previous != null) ? bytesToValue(previous) : 0; int newValue = previousValue + addAmount; return valueToBytes(newValue); &#125; &#125;; AtomicValue&lt;byte[]&gt; result = value.trySet(makeValue); return new AtomicInteger(result);&#125; MakeValue 告诉了 DistributedAtomicValue 如何将原来的值变成现在要设置的值，这里实现了加法 DistributedAtomicValue.trySet12345678910111213AtomicValue&lt;byte[]&gt; trySet(MakeValue makeValue) throws Exception &#123; MutableAtomicValue&lt;byte[]&gt; result = new MutableAtomicValue&lt;byte[]&gt;(null, null, false); // 试图通过乐观锁设置值（通过版本号） tryOptimistic(result, makeValue); if (!result.succeeded() &amp;&amp; (mutex != null)) &#123; // 如果通过乐观锁设置失败了，且提供了锁 // 则再次尝试通过在乐观锁的基础上再加一个悲观锁更新值 tryWithMutex(result, makeValue); &#125; return result;&#125; 首先，试图通过乐观锁设置值（通过版本号） 然后，如果通过乐观锁设置失败了，且提供了锁，则再次尝试通过在乐观锁的基础上再加一个悲观锁（代码里面将这种锁成为promoted lock）更新值 Result 描述了操作是否成功，上次的值和新的值，以及AtomicStats AtomicStats 包含了乐观锁的尝试次数，使用时间；提升锁(promoted lock)的尝试次数，使用时间DistributedAtomicValue.tryOptimistic（乐观锁修改）12345678910111213141516171819202122private void tryOptimistic(MutableAtomicValue&lt;byte[]&gt; result, MakeValue makeValue) throws Exception &#123; long startMs = System.currentTimeMillis(); int retryCount = 0; boolean done = false; while (!done) &#123; result.stats.incrementOptimisticTries(); // 尝试修改一次 // tryOnce用的是version保证的原子性 if (tryOnce(result, makeValue)) &#123; result.succeeded = true; done = true; &#125; else &#123; // 判断是否需要重试 if (!retryPolicy.allowRetry(retryCount++, System.currentTimeMillis() - startMs, RetryLoop.getDefaultRetrySleeper())) &#123; done = true; &#125; &#125; &#125; result.stats.setOptimisticTimeMs(System.currentTimeMillis() - startMs);&#125; 逻辑很简单，主要是调用的tryOnce进行的值的修改 DistributedAtomicValue.tryWithMutex（加锁修改）1234567891011121314151617181920212223242526private void tryWithMutex(MutableAtomicValue&lt;byte[]&gt; result, MakeValue makeValue) throws Exception &#123; long startMs = System.currentTimeMillis(); int retryCount = 0; // 相对于tryOptimistic多了一个获取锁的操作 if (mutex.acquire(promotedToLock.getMaxLockTime(), promotedToLock.getMaxLockTimeUnit())) &#123; try &#123; boolean done = false; while (!done) &#123; result.stats.incrementPromotedTries(); if (tryOnce(result, makeValue)) &#123; result.succeeded = true; done = true; &#125; else &#123; if (!promotedToLock.getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMs, RetryLoop.getDefaultRetrySleeper())) &#123; done = true; &#125; &#125; &#125; &#125; finally &#123; mutex.release(); &#125; &#125; result.stats.setPromotedTimeMs(System.currentTimeMillis() - startMs);&#125; DistributedAtomicValue.tryOnce（真正的值的修改）12345678910111213141516171819202122232425262728private boolean tryOnce(MutableAtomicValue&lt;byte[]&gt; result, MakeValue makeValue) throws Exception &#123; Stat stat = new Stat(); // 将当前值和节点信息获取到result和stat中，并获取是否需要创建节点 boolean createIt = getCurrentValue(result, stat); boolean success = false; try &#123; // 通过旧值，获得新值 byte[] newValue = makeValue.makeFrom(result.preValue); if (createIt) &#123; // 节点不存在，则创建并初始化值 client.create().creatingParentContainersIfNeeded().forPath(path, newValue); &#125; else &#123; // 节点存在，通过版本修改值 client.setData().withVersion(stat.getVersion()).forPath(path, newValue); &#125; result.postValue = Arrays.copyOf(newValue, newValue.length); success = true; &#125; catch (KeeperException.NodeExistsException e) &#123; // 捕获异常并忽略，让外面的方法根据重试策略重试 &#125; catch (KeeperException.BadVersionException e) &#123; // 捕获异常并忽略，让外面的方法根据重试策略重试 &#125; catch (KeeperException.NoNodeException e) &#123; // 捕获异常并忽略，让外面的方法根据重试策略重试 &#125; return success;&#125; 值的获取值的获取没有什么特别的，仅仅就是通过getData获取而已]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
        <tag>Curator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Curator InterProcessMutex]]></title>
    <url>%2F2018%2F10%2F29%2FCurator-InterProcessMutex%2F</url>
    <content type="text"><![CDATA[InterProcessMutex的使用Lock.scala12345678910111213141516171819202122232425262728293031323334object Lock extends App &#123; val LOCK_PATH = "/lock" curatorContext &#123; client =&gt; val mutex = new InterProcessMutex(client, LOCK_PATH) for (i &lt;- 0 until 10) &#123; new Thread(() =&gt; &#123; try &#123; println(s"Thread $&#123;Thread.currentThread().getName&#125;") mutex.acquire() &#125; catch &#123; case NonFatal(e) =&gt; &#125; println(s"Thread $&#123;Thread.currentThread().getName&#125; start") val sdf = new SimpleDateFormat("HH:mm:ss|SSS") println(s"Order No. : $&#123;sdf.format(new Date)&#125;") try &#123; mutex.release() println(s"Thread $&#123;Thread.currentThread().getName&#125; finish") &#125; catch &#123; case NonFatal(e) =&gt; &#125; &#125;).start() &#125; while (true) &#123;&#125; &#125;&#125; 效果12345678910111213141516171819202122232425262728293031323334353637383940Thread Thread-1Thread Thread-9Thread Thread-5Thread Thread-10Thread Thread-8Thread Thread-7Thread Thread-2Thread Thread-6Thread Thread-3Thread Thread-4Thread Thread-2 startOrder No. : 10:05:15|616Thread Thread-2 finishThread Thread-7 startOrder No. : 10:05:15|636Thread Thread-7 finishThread Thread-10 startOrder No. : 10:05:15|659Thread Thread-10 finishThread Thread-4 startOrder No. : 10:05:15|666Thread Thread-4 finishThread Thread-3 startOrder No. : 10:05:15|675Thread Thread-3 finishThread Thread-8 startOrder No. : 10:05:15|683Thread Thread-8 finishThread Thread-9 startOrder No. : 10:05:15|695Thread Thread-9 finishThread Thread-5 startOrder No. : 10:05:15|701Thread Thread-5 finishThread Thread-6 startOrder No. : 10:05:15|727Thread Thread-6 finishThread Thread-1 startOrder No. : 10:05:15|742Thread Thread-1 finish 概念分布式锁各个方案的优缺点 Curator的分布式锁介绍Curator主要提供了几种分布式锁，类图如下 可重入锁和不可重入锁广义上的可重入锁指的是可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class），这样的锁就叫做可重入锁。Java中ReentrantLock和synchronized是可重入锁。所谓不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到而被阻塞。InterProcessMutex是可重入锁 InterProcessMutex执行过程创建创建其实没有什么，只不过这里面默认的有一个StandardLockInternalsDriver，这个是默认的驱动器,这个是做什么的后面再说。 client：curator实现的zookeeper客户端 path：要在zookeeper加锁的路径，即后面创建临时节点的父节点 1234567public InterProcessMutex(CuratorFramework client, String path) &#123; this(client, path, new StandardLockInternalsDriver());&#125;public InterProcessMutex(CuratorFramework client, String path, LockInternalsDriver driver) &#123; this(client, path, LOCK_NAME, 1, driver);&#125; 最终调用的是一个可见范围为包的构造函数1234InterProcessMutex(CuratorFramework client, String path, String lockName, int maxLeases, LockInternalsDriver driver) &#123; basePath = PathUtils.validatePath(path); internals = new LockInternals(client, driver, path, lockName, maxLeases); &#125; 注意，这里的maxLeases为1，LOCK_NAME为lock-new LockInternals也是一个可见范围为包的构造函数，里面就是对于参数进行了值的初始化和检查123456789LockInternals(CuratorFramework client, LockInternalsDriver driver, String path, String lockName, int maxLeases) &#123; this.driver = driver; this.lockName = lockName; this.maxLeases = maxLeases; this.client = client.newWatcherRemoveCuratorFramework(); this.basePath = PathUtils.validatePath(path); this.path = ZKPaths.makePath(path, lockName); &#125; acquire加锁调用 acquire 方法里面没有什么，其实调用的是 internalLock1234567891011@Overridepublic void acquire() throws Exception &#123; if (!internalLock(-1, null)) &#123; throw new IOException("Lost connection while trying to acquire lock: " + basePath); &#125;&#125;@Overridepublic boolean acquire(long time, TimeUnit unit) throws Exception &#123; return internalLock(time, unit);&#125; internalLock实现了锁的可重入1234567891011121314151617181920212223242526272829private boolean internalLock(long time, TimeUnit unit) throws Exception &#123; /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary 一个lockData仅仅只会在一个线程中访问（因为是根据线程进行保存的），所以没必要加锁 */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); if (lockData != null) &#123; // 可重入锁 // 如果任意线程在获取到锁之后，再次获取该锁而不会被该锁所阻塞 // 关联一个线程持有者+计数器，重入意味着锁操作的颗粒度为“线程” // re-entering lockData.lockCount.incrementAndGet(); return true; &#125; // 开始竞争获取锁 String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if (lockPath != null) &#123; // 拿到了锁 LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; &#125; return false;&#125; 这段代码里面，实现了锁的可重入。每个 InterProcessMutex 实例，都会持有一个 ConcurrentMap 类型的 threadData 对象，以线程对象作为 Key，以 LockData 作为 Value 值。通过判断当前线程 threadData 是否有值，如果有，则表示线程可以重入该锁，于是将 lockData 的 lockCount 进行累加；如果没有，则进行锁的抢夺。internals.attemptLock 方法返回 lockPath!=null 时，表明了该线程已经成功持有了这把锁，于是乎 LockData 对象被 new 了出来，并存放到 threadData 中。这里为什么要用一个 ConcurrentMap 来保存呢？回顾开头的 InterProcessMutex的使用 ，这10个线程其实用的是同一个 InterProcessMutex 对象，所以需要 ConcurrentMap 保存。 锁的竞争attemptLock1234567891011121314151617181920212223242526272829303132333435String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception &#123; final long startMillis = System.currentTimeMillis(); final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes; int retryCount = 0; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; while (!isDone) &#123; isDone = true; try &#123; // 这个就是单纯的创建一个临时节点，返回路径 // /lock/_c_c29bfdef-d575-4930-9140-39befca73e42-lock-0000000060 ourPath = driver.createsTheLock(client, path, localLockNodeBytes); hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); &#125; catch (KeeperException.NoNodeException e) &#123; // gets thrown by StandardLockInternalsDriver when it can't find the lock node // this can happen when the session expires, etc. So, if the retry allows, just try it all again if (client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper())) &#123; isDone = false; &#125; else &#123; throw e; &#125; &#125; &#125; if (hasTheLock) &#123; return ourPath; &#125; return null;&#125; while循环正常来说，会在下一次结束。但是当出现NoNodeException异常时，会根据zookeeper客户端的重试策略，进行有限次数的重新获取锁。 driver.createsTheLock 创建锁，其实就是单纯的创建一个临时序列节点的方法。 internalLockLoop 是一个阻塞的方法，当它正常返回的时候，就意味着已经拿到锁了 driver.createsTheLock创建一个临时序列节点作为锁，并返回创建的路径。注意，创了一个并不代表获得了锁。也可以注意到，创建的这个节点是带withProtection()的。InterProcessMutex的lockNodeBytes为null1234567891011121314151617public String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception &#123; String ourPath; if (lockNodeBytes != null) &#123; ourPath = client.create() .creatingParentContainersIfNeeded() .withProtection() .withMode(CreateMode.EPHEMERAL_SEQUENTIAL) .forPath(path, lockNodeBytes); &#125; else &#123; ourPath = client.create() .creatingParentContainersIfNeeded() .withProtection() .withMode(CreateMode.EPHEMERAL_SEQUENTIAL) .forPath(path); &#125; return ourPath;&#125; driver.internalLockLoop判断自身是否能够持有锁。如果不能，进入wait，等待被唤醒。正常情况下，internalLockLoop 只有在超时或者拿到了锁才返回。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception &#123; // ourPath /lock/_c_c29bfdef-d575-4930-9140-39befca73e42-lock-0000000060 boolean haveTheLock = false; boolean doDelete = false; try &#123; if (revocable.get() != null) &#123; client.getData().usingWatcher(revocableWatcher).forPath(ourPath); &#125; while ((client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock) &#123; // 获取到所有子节点列表，并且从小到大根据节点名称排序 List&lt;String&gt; children = getSortedChildren(); // +1 to include the slash // _c_c29bfdef-d575-4930-9140-39befca73e42-lock-0000000060 String sequenceNodeName = ourPath.substring(basePath.length() + 1); // maxLeases 在 InterProcessMutex 为 1 // 判断是否可以持有锁，判断规则： // 当前创建的节点(sequenceNodeName)是否在上一步获取到的子节点列表(children)的第maxLeases位置 PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); if (predicateResults.getsTheLock()) &#123; haveTheLock = true; &#125; else &#123; // pathToWatch 是前maxLeases个节点 // 对于InterProcessMutex，是指前面一个节点 String previousSequencePath = basePath + "/" + predicateResults.getPathToWatch(); synchronized (this) &#123; try &#123; // use getData() instead of exists() to avoid leaving unneeded watchers which is a type of resource leak // watcher 会在监视的节点删除、更新（释放锁用的是删除，所以不会触发更新）的时候被触发 // 然后watcher里面会调用 notifyAll() 唤醒线程 client.getData().usingWatcher(watcher).forPath(previousSequencePath); if (millisToWait != null) &#123; millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if (millisToWait &lt;= 0) &#123; // timed out - delete our node doDelete = true; break; &#125; wait(millisToWait); &#125; else &#123; wait(); &#125; &#125; catch (KeeperException.NoNodeException e) &#123; // it has been deleted (i.e. lock released). Try to acquire again &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; ThreadUtils.checkInterrupted(e); doDelete = true; throw e; &#125; finally &#123; if (doDelete) &#123; deleteOurPath(ourPath); &#125; &#125; return haveTheLock;&#125; while 循环如果没有设置超时间，那么这个 while 是一个死循环。如果设置了，那么会 wait 一段时间，如果超时了,那么会进入下一个 while 循环，然后判断超时 break 出去。如果没有设置超时，会在被唤醒之后，进入下一个循环，直到 haveTheLock 为 true 之后才退出循环。 getSortedChildren这个方法比较简单，就是获取到所有子节点列表，并且从小到大根据节点名称后10位数字进行排序。在上面提到了，创建的是序列节点。 driver.getsTheLock12345678910111213public PredicateResults getsTheLock(CuratorFramework client, List&lt;String&gt; children, String sequenceNodeName, int maxLeases) throws Exception &#123; int ourIndex = children.indexOf(sequenceNodeName); // 判断 index 是否合法 // index 是否大于0，大于0合法 // 小于0说明出现了异常，创建的锁节点不见了 validateOurIndex(sequenceNodeName, ourIndex); // 这里是判断是否成功拿到锁 boolean getsTheLock = ourIndex &lt; maxLeases; String pathToWatch = getsTheLock ? null : children.get(ourIndex - maxLeases); return new PredicateResults(pathToWatch, getsTheLock);&#125; 锁获取重试的规则对于 InterProcessMutex ，由于 maxLeases=1 。所以是判断当前节点是不是在子节点列表的第一个。如果是第一个，则获得锁成功。如果获取失败，则监听前一个节点，调用wait，线程交出cpu的占用，进入等待状态，等到被唤醒，监听删除的触发事件 watcher（getData 的 watcher）。watcher 被触发时调用 notifyAll() release释放锁123456789101112131415161718192021222324252627public void release() throws Exception &#123; /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); if (lockData == null) &#123; throw new IllegalMonitorStateException("You do not own the lock: " + basePath); &#125; // 因为是可重入锁，所以，计数减1 int newLockCount = lockData.lockCount.decrementAndGet(); if (newLockCount &gt; 0) &#123; // 没有减到0，则直接返回 return; &#125; if (newLockCount &lt; 0) &#123; throw new IllegalMonitorStateException("Lock count has gone negative for lock: " + basePath); &#125; try &#123; internals.releaseLock(lockData.lockPath); &#125; finally &#123; threadData.remove(currentThread); &#125;&#125; 减少重入锁的计数，直到变成0。 释放锁，即移除移除 watchers &amp; 删除创建的节点 从 threadData 中，删除自己线程的缓存 锁驱动类锁驱动类有3个方法，通过这个方法，我们可以自定义一些过程。 getsTheLock：判断是够获取到了锁 createsTheLock：在zookeeper的指定路径上，创建一个临时序列节点。 fixForSorting：修改lock节点的路径字符串以进行排序，在StandardLockInternalsDriver的实现中，即获取到临时节点的最后序列数，进行排序。 总结多个线程竞争锁，这些线程都在同一个ZooKeeper路径下创建临时的递增的子节点序列，如果某一个线程创建的节点位于所有子节点序列的第一个，则获得到锁。如果不是，则失败，监听前面的一个节点的的getData，当前面一个节点被删除（即锁完全释放），则被重新唤醒，重新进行锁的竞争。对于锁的重入，如果已经拿到了锁，就简单的将内部的 ConcurrentMap 的当前线程的计数加一。对于锁的释放，首先将内部的当前线程的计数器减一，如果没有减到零，则返回。如果减到零了，则移除 watchers，删除创建自己的锁节点（这会触发监听它的 watcher，进入下一轮的竞争）。删除自己线程的缓存。 参考curator笔记-分布式锁的实现与原理]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
        <tag>Curator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拆箱空指针异常]]></title>
    <url>%2F2018%2F10%2F29%2F%E6%8B%86%E7%AE%B1%E7%A9%BA%E6%8C%87%E9%92%88%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[背景项目里面用了一个参数校验的工具类，里面有个方法大致上是这样子的12345public static void checkParameter(boolean expression, String errorMsg) &#123; if (!expression) &#123; throw new ParameterException(errorMsg); &#125;&#125; 然后报了空指针异常 原因由于调用的时候出现了类似这个的写法12Boolean b = null;checkParameter(b, "msg"); 这里b是一个Boolean类，而参数是boolean类型，所以，在自动拆箱的时候报了空指针异常 解决12345public static void checkParameter(Boolean expression, String errorMsg) &#123; if (expression == null || !expression) &#123; throw new ParameterException(errorMsg); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Swagger配置]]></title>
    <url>%2F2018%2F10%2F28%2FSwagger%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[解决方案主要是Swagger的资源文件的映射问题。核心代码(配置WebMvcConfigurerAdapter)12345678@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; super.addResourceHandlers(registry); registry.addResourceHandler("swagger-ui.html") .addResourceLocations("classpath:/META-INF/resources/"); registry.addResourceHandler("/webjars/**") .addResourceLocations("classpath:/META-INF/resources/webjars/");&#125; 然后，如果进行了登录拦截，需要将这些路径放行1234&quot;/swagger-ui.html&quot;,&quot;/swagger-*/**&quot;,&quot;/webjars/**&quot;,&quot;/v2/api-docs&quot; 我怎么找到的这些资源路径？这些资源文件都在springfox-swagger-ui的META-INF下面 代码CommonSwaggerConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Configuration@EnableSwagger2public class CommonSwaggerConfig extends WebMvcConfigurerAdapter &#123; @Autowired private SwaggerProperties swaggerProperties; @Bean public Docket docket() &#123; Assert.state(!StringUtils.isEmpty(swaggerProperties.getBasePackage()), "swagger.basePackage 不可为空"); return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(swaggerProperties.getBasePackage())) .paths(PathSelectors.any()) .build() .securitySchemes(securitySchemes()) .securityContexts(securityContexts()); &#125; private List&lt;ApiKey&gt; securitySchemes() &#123; return Lists.newArrayList(new ApiKey("Authorization", "Authorization", "header")); &#125; private List&lt;SecurityContext&gt; securityContexts() &#123; return Lists.newArrayList( SecurityContext.builder() .securityReferences(securityReferences()) .forPaths(PathSelectors.any()) .build() ); &#125; private List&lt;SecurityReference&gt; securityReferences() &#123; AuthorizationScope authorizationScope = new AuthorizationScope("global", "accessEverything"); AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; authorizationScopes[0] = authorizationScope; return Lists.newArrayList(new SecurityReference("Authorization", authorizationScopes)); &#125; private ApiInfo apiInfo() &#123; Assert.state(!StringUtils.isEmpty(swaggerProperties.getTitle()), "swagger.title 不可为空"); Assert.state(!StringUtils.isEmpty(swaggerProperties.getVersion()), "swagger.version 不可为空"); return new ApiInfoBuilder() .title(swaggerProperties.getTitle()) .version(swaggerProperties.getVersion()) .build(); &#125; @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; super.addResourceHandlers(registry); registry.addResourceHandler("swagger-ui.html") .addResourceLocations("classpath:/META-INF/resources/"); registry.addResourceHandler("/webjars/**") .addResourceLocations("classpath:/META-INF/resources/webjars/"); &#125;&#125; SwaggerProperties123456789101112@Getter@Setter@Configuration@ConfigurationProperties(prefix = "swagger")public class SwaggerProperties &#123; private String basePackage; private String title; private String version;&#125; 使用上面的那些类可以打成jar包，其他微服务就可以直接使用文档服务了。application.yml1234swagger: basePackage: "com.company.controller" title: "Api文档" version: "1.0"]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Swagger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringSecurity OAuth2踩坑记录]]></title>
    <url>%2F2018%2F10%2F28%2FSpringSecurity-OAuth2%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[背景，用户权限什么的使用的JWT Principal自定义解析由于生成的token的内容和SpringSecurity默认的不一样，所以需要自定义解析12345678910111213public class OAuth2PrincipalExtractor implements PrincipalExtractor &#123; @Override public Object extractPrincipal(Map&lt;String, Object&gt; map) &#123; try &#123; ObjectMapper objectMapper = new ObjectMapper(); String jsonVal = objectMapper.writeValueAsString(map); return objectMapper.readValue(jsonVal, AuthUser.class); &#125; catch (Exception e) &#123; return null; &#125; &#125;&#125; 然后注册成一个Bean就好了 Authorities自定义解析同样，然后注册成一个Bean12345678910111213141516public class OAuth2AuthoritiesExtractor implements AuthoritiesExtractor &#123; @Override public List&lt;GrantedAuthority&gt; extractAuthorities(Map&lt;String, Object&gt; map) &#123; try &#123; ObjectMapper objectMapper = new ObjectMapper(); String jsonVal = objectMapper.writeValueAsString(map); Collection&lt;AuthUserAuthority&gt; authorities = objectMapper .readValue(jsonVal, AuthUser.class) .getAuthorities(); return new ArrayList&lt;&gt;(authorities); &#125; catch (Exception e) &#123; return Collections.EMPTY_LIST; &#125; &#125;&#125; 为什么要自定义解析这样之后的好处，可以直接使用SpringSecurity的hasAuthority和@PreAuthorize(“hasAuthority(‘SUPPLY’)”)123456789101112131415@EnableResourceServer@Configurationpublic class ResourceServerConfiguration extends BaseResourceServerConfig &#123; @Override public void configure(HttpSecurity http) throws Exception &#123; http .csrf().disable() .authorizeRequests() .antMatchers("/customer") .hasAuthority("CUSTOMER") .antMatchers("/supply") .hasAuthority("SUPPLY"); &#125;&#125; 原来由于Spring不知道怎么解析你的数据，所以这些东西都不能用。 OPTIONS请求401错误由于前端发过来OPTIONS请求没有token，而且这个请求一般都是浏览器发的，所以不应该拦截，但是不知道SpringSecurity为什么拦截了 方法一12345678910@Configuration@EnableWebSecurity@Order(ConfigOrder.SECURITY_CONFIGURATION)public class CommonSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Override public void configure(WebSecurity web) throws Exception &#123; web.ignoring().antMatchers(HttpMethod.OPTIONS); &#125;&#125; 方法二使用Filter123456789101112131415@Slf4j@Component@Order(ConfigOrder.CROSS_ORIGIN_FILTER)public class CommonFilter implements Filter &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; if("OPTIONS".equalsIgnoreCase(request.getMethod()))&#123; response.setStatus(HttpServletResponse.SC_OK); &#125;else &#123; filterChain.doFilter(servletRequest, response); &#125; &#125;&#125; permitAll的路径如果带上了token，还是会验证token思路，注册一个优先级高于 ResourceServerConfig的WebSecurityConfigurer，在这里面放行 CommonSecurityConfiguration123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configuration@EnableWebSecurity@Order(ConfigOrder.SECURITY_CONFIGURATION) //Ordered.HIGHEST_PRECEDENCE + 2public class CommonSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; private final NoAuthPathProperties noAuthPathProperties; @Autowired public CommonSecurityConfiguration(NoAuthPathProperties noAuthPathProperties) &#123; this.noAuthPathProperties = noAuthPathProperties; &#125; @Override public void configure(WebSecurity web) throws Exception &#123; web.ignoring().antMatchers(HttpMethod.OPTIONS); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; List&lt;RequestMatcher&gt; requestMatchers = getRequestMatcherList(); http .requestMatcher(new OrRequestMatcher(requestMatchers)) .csrf().disable() .authorizeRequests() .anyRequest() .permitAll(); &#125; private List&lt;RequestMatcher&gt; getRequestMatcherList() &#123; List&lt;RequestMatcher&gt; res = Arrays.stream(SwaggerRequestUrl.URLS).map(AntPathRequestMatcher::new) .collect(Collectors.toList()); if (Objects.nonNull(noAuthPathProperties.getUrls()) &amp;&amp; !noAuthPathProperties.getUrls().isEmpty()) &#123; List&lt;RequestMatcher&gt; noauth = noAuthPathProperties.getUrls().stream() .map(AntPathRequestMatcher::new) .collect(Collectors.toList()); res.addAll(noauth); &#125; return res; &#125;&#125; NoAuthPathProperties作为一个放行路径的配置文件，便于使用12345678@Getter@Setter@Configuration@ConfigurationProperties(prefix = "no-auth-path")public class NoAuthPathProperties &#123; private List&lt;String&gt; urls;&#125; 1234no-auth-path: urls: - "/login" - "/view/**" 一些要注意的点注意这段代码123456http .requestMatcher(new OrRequestMatcher(requestMatchers)) .csrf().disable() .authorizeRequests() .anyRequest() .permitAll(); requestMatcher意味着这个HttpSecurity仅仅只在匹配的这些地址下运行。由于我们想要的就是放行，所以，仅仅只需要在这些路径下的anyRequest（所有地址）permitAll就可以了。不在这些路径的权限就丢给后面的HttpSecurity了。这样还有一个好处，就是，由于这个在ResourceServerConfig前面执行，所以，ResourceServerConfig只需要专注要登录验证的路径就好了，甚至可以直接123456789//ResourceServerConfig.java@Overridepublic void configure(HttpSecurity http) throws Exception &#123; http .csrf().disable() .authorizeRequests() .anyRequest() .authenticated();&#125; 这里的anyRequest其实指的是除开放行的路径剩下的。 自定义AccessDeniedException处理12345678910111213@Slf4jpublic class CommonAccessDeniedHandler implements AccessDeniedHandler &#123; @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException &#123; MsgResult&lt;Void&gt; result = new MsgResult&lt;&gt;(ResultCode.UNAUTHORIZED, accessDeniedException.getMessage()); //这里其实就是response.getWriter().write写数据 ResponseUtil.response(response, result); &#125;&#125; 然后在ResourceServerConfig里面配置12345678910public class BaseResourceServerConfig extends ResourceServerConfigurerAdapter &#123; @Autowired private AccessDeniedHandler accessDeniedHandler; @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception &#123; resources.accessDeniedHandler(accessDeniedHandler); &#125;&#125; @Order提示 java: 元素值必须为常量表达式这个其实是Java语法的问题，不知道写在哪儿就先写在这里吧。开始我是这么写的123456public final class ConfigOrder &#123; public static final Integer CROSS_ORIGIN_FILTER = Ordered.HIGHEST_PRECEDENCE + 1; public static final Integer SECURITY_CONFIGURATION = CROSS_ORIGIN_FILTER + 1;&#125; 注意，Integer应该写成int，就可以了123456public final class ConfigOrder &#123; public static final int CROSS_ORIGIN_FILTER = Ordered.HIGHEST_PRECEDENCE + 1; public static final int SECURITY_CONFIGURATION = CROSS_ORIGIN_FILTER + 1;&#125;]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Curator NodeCache学习]]></title>
    <url>%2F2018%2F10%2F25%2FCurator-NodeCache%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[NodeCache的使用package.scala12345678910111213141516171819package object curator &#123; def curatorContext(f: CuratorFramework =&gt; Unit)(implicit nameSpace: String = "curator"): Unit = &#123; val retryPolicy = new ExponentialBackoffRetry(1000, 3) val client = CuratorFrameworkFactory.builder() .connectString(ZOOKEEPER_HOST) .sessionTimeoutMs(5000) .connectionTimeoutMs(1000) .retryPolicy(retryPolicy) .namespace(nameSpace) .build() client.start() f(client) client.close() &#125;&#125; NodeCacheSample.scala12345678910111213141516171819202122232425object NodeCacheSample extends App &#123; curatorContext &#123; client =&gt; val path = "/c1" client.create() .creatingParentsIfNeeded() .withMode(CreateMode.EPHEMERAL) .forPath(path, "init".getBytes) val cache = new NodeCache(client, path, false) cache.start(false) cache.getListenable.addListener(() =&gt; &#123; println(s"Node data changed new data is " + s"$&#123;new String(cache.getCurrentData.getData)&#125;") &#125;) client.setData().forPath(path, "d1".getBytes) Thread.sleep(1000) client.setData().forPath(path, "d2".getBytes) Thread.sleep(5000) &#125;&#125; NodeCache的执行过程NodeCache的代码不长，逻辑不是很复杂 （虽然我还是看了好久） 几个关键的成员变量12345678// 保存最新的节点数据private final AtomicReference&lt;ChildData&gt; data = new AtomicReference&lt;ChildData&gt;(null);// NodeCache的状态，LATENT（未启动），STARTED（正在运行），CLOSED（已关闭）private final AtomicReference&lt;State&gt; state = new AtomicReference&lt;State&gt;(State.LATENT);// 保存的Listenerprivate final ListenerContainer&lt;NodeCacheListener&gt; listeners = new ListenerContainer&lt;NodeCacheListener&gt;();// Zookeeper连接状态，是否已经连接上了private final AtomicBoolean isConnected = new AtomicBoolean(true); 创建12345public NodeCache(CuratorFramework client, String path, boolean dataIsCompressed) &#123; this.client = client.newWatcherRemoveCuratorFramework(); this.path = PathUtils.validatePath(path); this.dataIsCompressed = dataIsCompressed;&#125; 注意这一行client.newWatcherRemoveCuratorFramework();返回的是一个WatcherRemoveCuratorFramework这个接口在原有的CuratorFramework上多了一个removeWatchers的方法，这个方法可以移除掉所有的watchers start123456789101112131415public void start(boolean buildInitial) throws Exception &#123; Preconditions.checkState(state.compareAndSet(State.LATENT, State.STARTED), "Cannot be started more than once"); // 监听client的连接状态 // 根据连接状态修改isConnected的值 client.getConnectionStateListenable().addListener(connectionStateListener); if (buildInitial) &#123; client.checkExists().creatingParentContainersIfNeeded().forPath(path); internalRebuild(); &#125; //核心方法 reset();&#125; resetreset方法是NodeCache的核心方法12345678910111213private void reset() throws Exception &#123; // 判断NodeCache是否已经启动，并且连接已经建立 if ((state.get() == State.STARTED) &amp;&amp; isConnected.get()) &#123; // 获得node的Stat，并注册了一个watcher // watcher会在节点创建、删除、更新值的时候被触发 // 并且异步执行exists操作，结果回掉backgroundCallback client.checkExists() .creatingParentContainersIfNeeded() .usingWatcher(watcher) .inBackground(backgroundCallback) .forPath(path); &#125;&#125; watcherNodeCache的核心。watcher实现了watcher的重新注册和监听123456789101112private Watcher watcher = new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; try &#123; // 调用reset，重新进行监听 reset(); &#125; catch (Exception e) &#123; ThreadUtils.checkInterrupted(e); handleException(e); &#125; &#125;&#125;; backgroundCallback也是NodeCache的核心。其对于event进行处理，根据不同的event进行不同的处理1234567private final BackgroundCallback backgroundCallback = new BackgroundCallback() &#123; @Override public void processResult(CuratorFramework client, CuratorEvent event) throws Exception &#123; //实际的处理过程在这个方法里面 processBackgroundResult(event); &#125;&#125;; 1234567891011121314151617181920212223242526272829303132333435363738private void processBackgroundResult(CuratorEvent event) throws Exception &#123; switch (event.getType()) &#123; // 如果是 getData() 的回掉 case GET_DATA: &#123; if (event.getResultCode() == KeeperException.Code.OK.intValue()) &#123; // 数据获取成功 // 更新成员变量 data，并根据 listeners 通知 listener ChildData childData = new ChildData(path, event.getStat(), event.getData()); setNewData(childData); &#125; break; &#125; // 如果是 checkExists() 的回掉 case EXISTS: &#123; if (event.getResultCode() == KeeperException.Code.NONODE.intValue()) &#123; // 如果节点已经不存在了，则将成员变量 data 设为null // 并根据 listeners 通知 listener setNewData(null); &#125; else if (event.getResultCode() == KeeperException.Code.OK.intValue()) &#123; // 节点存在，获取节点数据 // 则注册watcher，将在节点数据更新或者节点被删除的时候被触发 // 并异步执行，回掉 backgroundCallback if (dataIsCompressed) &#123; client.getData().decompressed() .usingWatcher(watcher) .inBackground(backgroundCallback) .forPath(path); &#125; else &#123; client.getData().usingWatcher(watcher) .inBackground(backgroundCallback) .forPath(path); &#125; &#125; break; &#125; &#125;&#125; setNewDatasetNewData是将数据的更新事件发送给各个listener。由于ZooKeeper的更新事件是节点数据版本有变化就会触发，所以，有更新事件并不代表节点数据变化了，NodeCache 使用了Objects.equal(previousData, newData) 判断了数据有没有变化，数据有变化才会触发各个listener12345678910111213141516171819202122232425262728293031private void setNewData(ChildData newData) throws InterruptedException &#123; ChildData previousData = data.getAndSet(newData); // 如果数据有变化 if (!Objects.equal(previousData, newData)) &#123; // 通知各个listener listeners.forEach( new Function&lt;NodeCacheListener, Void&gt;() &#123; @Override public Void apply(NodeCacheListener listener) &#123; try &#123; listener.nodeChanged(); &#125; catch (Exception e) &#123; ThreadUtils.checkInterrupted(e); log.error("Calling listener", e); &#125; return null; &#125; &#125; ); // 下面的代码应该是测试用的代码 // 但具体有什么用，还不清楚 if (rebuildTestExchanger != null) &#123; try &#123; rebuildTestExchanger.exchange(new Object()); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125;&#125; getCurrentData还有个getCurrentData方法，返回节点的数据。但是使用这个方法要注意，这个方法并不保证获得到的数据一定是最新的，但至少是接近最新的。因为这是多线程的情况，有可能刚刚拿到数据节点的数据就被更新了。123public ChildData getCurrentData() &#123; return data.get();&#125; 调用流程这里虽然代码里面的 watcher 使用的是同一个，为了描述清楚，将通过 checkExists 设置的 watcher 和通过 getData 设置的 watcher 分开了。下面将执行的流程打印出来 思考可以发现，代码里面设置了不止一次 watcher ，那为什么只会触发一次呢？网上说ZooKeeper里面的 watcher 是存在 HashMap 里面的（Apache ZooKeeper Watcher 机制源码解释 watch2Paths）那么，因为使用的是同一个 watcher ，所以后面设置的会替换掉原来设置的。 那么如果我设置了两个 watcher 那会发生什么呢？调用的过程如下：可以看出一个数据的修改会调用两次 setNewData ，原因是 ExistsWatcher 和 DataWatcher 都收到了数据修改的消息，然后都去获取数据，当然，在 setNewData 里面第二次查询就会发现数据没有变，就不会调用listener。同时可以看出，如果注册了两个不同 watcher ，那么都会被调用，而且是按照 watcher 注册的顺序的（这个也是在上面那篇文章说的，客户端 Watcher 回调的过程是一个串行同步的过程）]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
        <tag>Curator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 去除数据库支持]]></title>
    <url>%2F2018%2F10%2F25%2FSpringBoot-%E5%8E%BB%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[一般SpringBoot默认有数据库支持，但是要去除数据库支持怎么办。 方法，在启动类上添加1@EnableAutoConfiguration(exclude = &#123;DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class&#125;)]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何判断运算是否越界]]></title>
    <url>%2F2018%2F10%2F22%2F%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E8%BF%90%E7%AE%97%E6%98%AF%E5%90%A6%E8%B6%8A%E7%95%8C%2F</url>
    <content type="text"><![CDATA[原问题 字符串转整数 (atoi) 这道题我觉得重点是符合判断运算是否越界了当然，如果你用Long来进行运算，然后判断下结果是否越界也是可以的（例如res是不是大于了Integer.MAX_VALUE），但如果用Integer进行运算怎么判断呢这里应该逆向验证，注意，开始我以为正数越界就一定是负数，并用这个性质判断是否越界，这是错误的。如果不考虑越界，期望的代码是这样的1res = res * 10 + digit 错误的判断是否越界的代码123456//错误代码newRes = res * 10 + digit;if(newRes &lt; res)&#123; //越界&#125;res = newRes; 正确的作法12345if (Integer.MAX_VALUE / 10 &lt; res || (Integer.MAX_VALUE / 10 == res &amp;&amp; Integer.MAX_VALUE % 10 &lt; digit)) &#123; //越界&#125;res = res * 10 + digit; 参考——判断运算是否越界]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark groupByKey和reduceByKey]]></title>
    <url>%2F2018%2F10%2F13%2FSpark-groupByKey%2F</url>
    <content type="text"><![CDATA[Spark里面其实有两个不同的groupByKey RDD里面的groupByKey这个其实是PairRDDFunctions里面的，需要是RDD[(K,V)]才可以调用，这个就是网上很多人说的那个groupByKey。在一个 (K, V) pair 的 dataset 上调用时，返回一个 (K, Iterable) .Note: 如果分组是为了在每一个 key 上执行聚合操作（例如，sum 或 average)，此时使用 reduceByKey 或 aggregateByKey 来计算性能会更好.Note: 默认情况下，并行度取决于父 RDD 的分区数。可以传递一个可选的 numTasks 参数来设置不同的任务数.groupBykey是把所有的键值对集合都加载到内存中存储计算，所以如果一个键对应的值太多的话，就会导致内存溢出的错误，这是需要重点关注的地方Spark源码之reduceByKey与GroupByKey DataSet里面的groupByKeydataSet里面的groupByKey其实就是类似于数据库sql的groupByReturns a [[KeyValueGroupedDataset]] where the data is grouped by the given key `func`.根据key `func` group by 数据dataSet里面没有reduceByKey]]></content>
      <categories>
        <category>Spark</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LeetCode 两个数组的交集 II]]></title>
    <url>%2F2018%2F09%2F28%2FLeetCode-%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E7%9A%84%E4%BA%A4%E9%9B%86-II%2F</url>
    <content type="text"><![CDATA[题目 如果给定的数组已经排好序呢？你将如何优化你的算法？ 1234567891011121314151617181920212223242526public static int[] intersect1(int[] nums1, int[] nums2) &#123; if (nums1.length &gt; nums2.length) &#123; return intersect2(nums2, nums1); &#125; if (nums1.length == 0 || nums2.length == 0) &#123; return new int[0]; &#125; Arrays.sort(nums1); Arrays.sort(nums2); List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for (int i = 0, j = 0; i &lt; nums1.length &amp;&amp; j &lt; nums2.length; ) &#123; if (nums1[i] == nums2[j]) &#123; res.add(nums1[i]); i++; j++; &#125; else if (nums1[i] &lt; nums2[j]) &#123; //如果nums1的小了，那么换一个大一点的跟nums2比较 i++; &#125; else &#123; //如果nums2的小了，那么换一个大一点的跟nums1比较 j++; &#125; &#125; return res.stream().mapToInt(n -&gt; n).toArray(); &#125; 如果 nums2 的元素存储在磁盘上，磁盘内存是有限的，并且你不能一次加载所有的元素到内存中，你该怎么办？ 1234567891011121314151617181920212223242526public static int[] intersect(int[] nums1, int[] nums2) &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); Map&lt;Integer, Integer&gt; numMap = new HashMap&lt;&gt;(); for (int n : nums1) &#123; if (numMap.containsKey(n)) &#123; numMap.put(n, numMap.get(n) + 1); &#125; else &#123; numMap.put(n, 1); &#125; &#125; //nums2很大，所以，相当于读取的是一个nums2的流 Arrays.stream(nums2).forEach(n -&gt; &#123; Integer nV = numMap.get(n); if (nV != null) &#123; if (nV == 0) &#123; numMap.remove(n); &#125; else &#123; res.add(n); nV--; numMap.put(n, nV); &#125; &#125; &#125;); return res.stream().mapToInt(n -&gt; n).toArray(); &#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Sklearn CountVectorizer]]></title>
    <url>%2F2018%2F09%2F04%2FSklearn-CountVectorizer%2F</url>
    <content type="text"><![CDATA[一直不知道CountVectorizer输出的结果到底是什么意思，现在终于弄明白了12345678910111213141516from sklearn.feature_extraction.text import CountVectorizertexts=["dog cat fish","dog cat cat","fish bird", 'bird']cv = CountVectorizer()cv_fit=cv.fit_transform(texts)print(cv.get_feature_names())print(cv_fit.toarray())#['bird', 'cat', 'dog', 'fish']#[[0 1 1 1]# [0 2 1 0]# [1 0 0 1]# [1 0 0 0]]print(cv_fit.toarray().sum(axis=0))#[2 3 2 2] [0 1 1 1]意思就是，第一段话”dog cat fish”对应单词表[‘bird’, ‘cat’, ‘dog’, ‘fish’]，bird出现了0次，cat出现了1次，以此类推。由此可以看出，形成的矩阵一般是一个稀疏矩阵，需要进行特征的提取和降维。]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sklearn SelectFromModel]]></title>
    <url>%2F2018%2F09%2F04%2FSklearn-SelectFromModel%2F</url>
    <content type="text"><![CDATA[原博客 SelectFromModelsklearn在Feature selection模块中内置了一个SelectFromModel，该模型可以通过Model本身给出的指标对特征进行选择，其作用与其名字高度一致，select （feature） from model。SelectFromModel 是一个通用转换器,其需要的Model只需要带有conef_或者feature_importances属性,那么就可以作为SelectFromModel的Model来使用. 如果相关的coef_或者featureimportances属性值低于预先设置的阈值，这些特征将会被认为不重要并且移除掉。除了指定数值上的阈值之外，还可以通过给定字符串参数来使用内置的启发式方法找到一个合适的阈值。可以使用的启发式方法有 mean、median 以及使用浮点数乘以这些（例如，0.1*mean ）。 根据基础学习的不同，在estimator中有两种选择方式 第一种是基于L1的特征选择，使用L1正则化的线性模型会得到稀疏解，当目标是降低维度的时候，可以使用sklearn中的给予L1正则化的线性模型，比如LinearSVC，逻辑回归，或者Lasso。但是要注意的是：在 SVM 和逻辑回归中，参数 C 是用来控制稀疏性的：小的 C 会导致少的特征被选择。使用 Lasso，alpha 的值越大，越少的特征会被选择。 第二种是给予Tree的特征选择，Tree类的算法包括决策树，随机森林等会在训练后，得出不同特征的重要程度，我们也可以利用这一重要属性对特征进行选择。 但是无论选择哪一种学习器,我们都要记住的是我们的特征选择的最终标准应当是选择最好的特征,而非必须依照某种方法进行选择 几个重要的参数，属性，方法 threshold ： 阈值，string, float, optional default None 可以使用：median 或者 mean 或者 1.25 * mean 这种格式。 如果使用参数惩罚设置为L1，则使用的阈值为1e-5，否则默认使用用mean prefit ：布尔，默认为False，是否为训练完的模型，（注意不能是cv，GridSearchCV或者clone the estimator得到的），如果是False的话则先fit，再transform。 threshold_ ：采用的阈值 简单的示例使用L1进行特征选择12345678910111213from sklearn.svm import LinearSVCfrom sklearn.datasets import load_irisfrom sklearn.feature_selection import SelectFromModel# Load the boston dataset.load_iris = load_iris()X, y = load_iris['data'], load_iris['target']print("X 共有 %s 个特征"%X.shape[1])lsvc = LinearSVC(C=0.01, penalty="l1", dual=False).fit(X, y)model = SelectFromModel(lsvc,prefit=True)X_new = model.transform(X)print("X_new 共有 %s 个特征"%X_new.shape[1]) 12X 共有 4 个特征X_new 共有 3 个特征]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sklearn笔记]]></title>
    <url>%2F2018%2F08%2F20%2FSklearn%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[使用sklearn做特征工程Sklearn SelectFromModelSklearn CountVectorizer]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Sklearn</tag>
        <tag>Catalog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决FeignClient默认不传递token的问题]]></title>
    <url>%2F2018%2F08%2F11%2FFeignClient%E9%BB%98%E8%AE%A4%E4%B8%8D%E4%BC%A0%E9%80%92token%2F</url>
    <content type="text"><![CDATA[在使用的过程中，发现如果使用token机制进行用户的验证标识，使用FeignClient不会默认传递Header中Authorization字段的token，需要对于token的传递进行特殊的自定义处理 最终的实现效果使用自定义的@OAuth2FeignClient代替原来的@FeignClient12345@OAuth2FeignClient(name = "servera")public interface ServerAClient &#123; @GetMapping("/user") HashMap&lt;String, Object&gt; authDemo();&#125; 并在启动类上添加@EnableFeignClients和@EnableOAuth2Client注解 @OAuth2FeignClient123456789101112131415161718192021222324252627282930@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@FeignClient(configuration = OAuth2FeignAutoConfiguration.class)public @interface OAuth2FeignClient &#123; @AliasFor(annotation = FeignClient.class) String name(); @AliasFor(annotation = FeignClient.class) String qualifier() default ""; @AliasFor(annotation = FeignClient.class) String url() default ""; @AliasFor(annotation = FeignClient.class) boolean decode404() default false; @AliasFor(annotation = FeignClient.class) Class&lt;?&gt; fallback() default void.class; @AliasFor(annotation = FeignClient.class) Class&lt;?&gt; fallbackFactory() default void.class; @AliasFor(annotation = FeignClient.class) String path() default ""; @AliasFor(annotation = FeignClient.class) boolean primary() default true;&#125; OAuth2FeignAutoConfiguration12345678@Configurationpublic class OAuth2FeignAutoConfiguration &#123; @Bean public RequestInterceptor oauth2FeignRequestInterceptor(OAuth2ClientContext oauth2ClientContext) &#123; return new OAuth2FeignRequestInterceptor(oauth2ClientContext); &#125;&#125; 核心OAuth2FeignRequestInterceptor这个类将token添加到feign请求的头里面去12345678910111213141516171819202122232425262728293031323334353637383940public class OAuth2FeignRequestInterceptor implements RequestInterceptor &#123; private static final String AUTHORIZATION_HEADER = "Authorization"; private static final String BEARER_TOKEN_TYPE = "Bearer"; private final OAuth2ClientContext oauth2ClientContext; public OAuth2FeignRequestInterceptor(OAuth2ClientContext oauth2ClientContext) &#123; Assert.notNull(oauth2ClientContext, "Context can not be null"); this.oauth2ClientContext = oauth2ClientContext; &#125; @Override public void apply(RequestTemplate template) &#123; if (template.headers().containsKey(AUTHORIZATION_HEADER)) &#123; return; &#125; String token = null; try &#123; OAuth2AccessToken oAuth2AccessToken = oauth2ClientContext.getAccessToken(); token = oAuth2AccessToken.getValue(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; if (token == null) &#123; try &#123; OAuth2AccessToken oAuth2AccessToken = oauth2ClientContext.getAccessTokenRequest().getExistingToken(); token = oAuth2AccessToken.getValue(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; if(token != null)&#123; //设置header template.header(AUTHORIZATION_HEADER, String.format("%s %s", BEARER_TOKEN_TYPE, token)); &#125; &#125;&#125; @EnableOAuthFeignClient可以将@EnableFeignClients和@EnableOAuth2Client合并为一个注解，方便使用1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@EnableFeignClients@EnableOAuth2Clientpublic @interface EnableOAuthFeignClient &#123;&#125; 附录 版本1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Edgware.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot项目打包的各种异常]]></title>
    <url>%2F2018%2F08%2F11%2FSpringBoot%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[修改项目jdk版本由于maven默认的jdk版本为1.5，所以maven项目报错。虽然可以手动修改idea的Target bytecode version等为1.8，但是每更新一次maven文件就要手动改一次，非常麻烦。 解决方法: 修改pom.xml123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;configuration&gt; &lt;compilerArgument&gt;-parameters&lt;/compilerArgument&gt; &lt;testCompilerArgument&gt;-parameters&lt;/testCompilerArgument&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt; lombok和mapstruct共存问题由于在项目中需要同时使用lombok和mapstruct，发现本来单独使用都可以，一同时使用就会出现lombok自动生成的方法找不到的问题。 解决方法：修改pom.xml123456789101112131415161718192021222324&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;configuration&gt; &lt;compilerArgument&gt;-parameters&lt;/compilerArgument&gt; &lt;testCompilerArgument&gt;-parameters&lt;/testCompilerArgument&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;annotationProcessorPaths&gt; &lt;path&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;org.mapstruct.version&#125;&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;/configuration&gt;&lt;/plugin&gt; SpringBoot项目打成jar包后无法启动使用mvn install打包后，运行jar包说找不到或无法加载主类。 解决:首先需要检查下是否配置了spring-boot-maven-plugin插件12345&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/plugin&gt; 但是我遇见了虽然配置了这个插件，但是可能是由于项目里面同时配置了maven-compiler-plugin（因为不配置会出现jdk版本问题，详见第一个），的原因，打包过后依然无法运行。 解决:使用命令1mvn package spring-boot:repackage 在由于spring-boot:repackage需要依赖sources文件，所以，如果没有没有生成xxx-sources.jar需要修改pom.xml123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git clone 代理配置]]></title>
    <url>%2F2018%2F08%2F10%2Fgit-clone-%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[设置代理12git config --global https.proxy 127.0.0.1:8087git config --global http.proxy 127.0.0.1:8087 取消已设置的代理12git config --global --unset http.proxygit config --global --unset https.proxy]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker修改镜像和启动异常]]></title>
    <url>%2F2018%2F08%2F03%2Fdocker%E4%BF%AE%E6%94%B9%E9%95%9C%E5%83%8F%E5%92%8C%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[配置 sudo vim /etc/docker/daemon.json 文件1234567&#123; "hosts": [ "tcp://127.0.0.1:2375", "unix:///var/run/docker.sock" ], "registry-mirrors": ["https://registry.docker-cn.com"]&#125; 重启服务的时候可能会报错1Job for docker.service failed because the control process exited with error code.See "systemctl status docker.service" and "journalctl -xe" for details. 错误原因：docker的socket配置出现了冲突，docker在运行时有一个启动入口文件：/lib/systemd/system/docker.service，而我们在修改镜像加速器的时候又给它生成了一个配置文件：/etc/docker/daemon.json，两个文件对host进行了配置，所以发生冲突。 解决方法：将docker启动入口文件中的-H fd://删除再重启服务，或者在启动入口配置监听的端口和本地socket信息：12345vim /lib/systemd/system/docker.service#原:ExecStart=/usr/bin/dockerd -H fd:// $DOCKER_OPTSExecStart=/usr/bin/dockerd#或者改成：ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock]]></content>
  </entry>
  <entry>
    <title><![CDATA[MyBatis遗忘知识点]]></title>
    <url>%2F2018%2F03%2F24%2FMyBatis%E9%81%97%E5%BF%98%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[(MyBatis官方文档)[http://www.mybatis.org/mybatis-3/zh/] 关联的嵌套结果 属性 描述 resultMap 这是结果映射的 ID,可以映射关联的嵌套结果到一个合适的对象图中。这 是一种替代方法来调用另外一个查询语句。这允许你联合多个表来合成到 resultMap 一个单独的结果集。这样的结果集可能包含重复,数据的重复组需要被分 解,合理映射到一个嵌套的对象图。为了使它变得容易,MyBatis 让你“链 接”结果映射,来处理嵌套结果。 columnPrefix 当连接多表时，你将不得不使用列别名来避免ResultSet中的重复列名。指定columnPrefix允许你映射列名到一个外部的结果集中。 notNullColumn 默认情况下，子对象仅在至少一个列映射到其属性非空时才创建。 通过对这个属性指定非空的列将改变默认行为，这样做之后Mybatis将仅在这些列非空时才创建一个子对象。 可以指定多个列名，使用逗号分隔。默认值：未设置(unset)。 autoMapping 如果使用了，当映射结果到当前属性时，Mybatis将启用或者禁用自动映射。 该属性覆盖全局的自动映射行为。 注意它对外部结果集无影响，所以在select or resultMap属性中这个是毫无意义的。 默认值：未设置(unset)。 在上面你已经看到了一个非常复杂的嵌套关联的示例。 下面这个是一个非常简单的示例 来说明它如何工作。代替了执行一个分离的语句,我们联合博客表和作者表在一起:Author的resultMap将定义如下：1234567&lt;resultMap id="authorResult" type="Author"&gt; &lt;id property="id" column="author_id"/&gt; &lt;result property="username" column="author_username"/&gt; &lt;result property="password" column="author_password"/&gt; &lt;result property="email" column="author_email"/&gt; &lt;result property="bio" column="author_bio"/&gt;&lt;/resultMap&gt; 因为结果中的列名与resultMap中的列名不同。 你需要指定columnPrefix去重用映射co-author结果的resultMap。注意columnPrefix属性1234567891011121314151617181920212223242526272829303132333435363738&lt;resultMap id="authorResult" type="Author"&gt; &lt;id property="id" column="author_id"/&gt; &lt;result property="username" column="author_username"/&gt; &lt;result property="password" column="author_password"/&gt; &lt;result property="email" column="author_email"/&gt; &lt;result property="bio" column="author_bio"/&gt;&lt;/resultMap&gt;&lt;resultMap id="blogResult" type="Blog"&gt; &lt;id property="id" column="blog_id" /&gt; &lt;result property="title" column="blog_title"/&gt; &lt;association property="author" resultMap="authorResult" /&gt; &lt;association property="coAuthor" resultMap="authorResult" columnPrefix="co_" /&gt;&lt;/resultMap&gt;&lt;select id="selectBlog" resultMap="blogResult"&gt; select B.id as blog_id, B.title as blog_title, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio, CA.id as co_author_id, CA.username as co_author_username, CA.password as co_author_password, CA.email as co_author_email, CA.bio as co_author_bio from Blog B left outer join Author A on B.author_id = A.id left outer join Author CA on B.co_author_id = CA.id where B.id = #&#123;id&#125;&lt;/select&gt;]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 5.7 中 Your password does not satisfy the current policy requirements]]></title>
    <url>%2F2018%2F03%2F14%2FMySQL-5-7-%E4%B8%AD-Your-password-does-not-satisfy-the-current-policy-requirements%2F</url>
    <content type="text"><![CDATA[http://blog.csdn.net/maxsky/article/details/51171474 1set global validate_password_policy=0; 更改强度为 LOW，代表密码任意，但长度在 8 位或以上。但是，LOW 强度允许我们设置为纯数字纯字母等密码，但是我们还是不能设置 123456，因为最低要求 8 位 1set global validate_password_length=4; 其实不管你设置 1、2、3、4，最低长度都是 4]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[高性能MySQL学习（三）]]></title>
    <url>%2F2018%2F03%2F10%2F%E9%AB%98%E6%80%A7%E8%83%BDMySQL%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[对应《高性能MySQL》第5章 索引的类型在存储引擎层实现，没有统一的标准 B-Tree索引]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>高性能MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 命令记录]]></title>
    <url>%2F2018%2F03%2F03%2Fcentos-%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[防火墙(Centos 7)123456firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）systemctl stop firewalld.service #停止firewallsystemctl disable firewalld.service #禁止firewall开机启动firewall-cmd --list-ports #查看已经开放的端口firewall-cmd --zone=public --add-port=80/tcp --permanent #开启端口 压缩、解压压缩1tar -zcvf 压缩文件名.tar.gz 被压缩文件名 解压1tar -zxvf 压缩文件名.tar.gz -C 目标目录 软件的安装和卸载查看已安装的PHP1rpm -qa |grep php 查询rpm包的安装时间和详情1rpm -qi php-cli-5.4.16-42.el7.x86_64 卸载1yum remove php* MySQL的安装CentOS上默认的mysql是mariadb，安装真正的mysql可以参考官网 Download MySQL Yum Repository 在CentOS7上安装MySQL的辛路历程 123rpm -Uvh mysql57-community-release-el7-9.noarch.rpmyum install mysql-community-serverservice mysqld start 查看Linux版本1uname -a]]></content>
  </entry>
  <entry>
    <title><![CDATA[高性能MySQL学习（二）]]></title>
    <url>%2F2018%2F02%2F11%2F%E9%AB%98%E6%80%A7%E8%83%BDMySQL%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[对应《高性能MySQL》第4章 数据类型的选择 更小的通常更好但是要确保没有低估需要存储的值的范围 简单就好使用简单的数据类型（例如，整型比字符串操作代价更低） 尽量避免NULL 可为NULL的列使得索引、索引统计和值比较都更复杂。然而，通常把NULL改成NOT NULL带来的性能提升比较小，但是，如果计划在列上建索引，就应该尽量避免设计成可为NULL 整数类型TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT分别使用8，16，24，32，64位存储空间存储范围从 -pow(2, N-1) 到 pow(2, N-1)-1整数还有 UNSIGNED 属性 字符串类型每个字符串列可以定义自己的字符集和排序规则（校对规则），这些会很大程度影响性能（详细在第7章讲）。下面在InnoDB或者MyISAM的情况下对比VARCHAR和CHAR VARCHAR用于存储可变长的字符串。仅存储必要的空间，越短的字符串使用的空间越少。（例外情况：如果MySQL表使用ROW_RORMAT=FIXED创建，每行都会使用定长存储，会浪费空间）需要1或2个额外字节记录字符串长度。如果列的最大长度小于等于255字节，则需要1个字节表示，否则使用2个字节。（或许这就是Navicat VARCHAR默认是255的原因吧） CHAR定长。当存储CHAR值时，MySQL会删除所有末尾的空格（因为，CHAR值会根据需要采用空格进行填充以便于比较）。适合存储很短的字符串，或所有值的长度都差不多（比如密码的MD5值）。对于经常变的数据，CHAR也比VARCHAR更好。 BLOB和TEXT仅有的区别： BLOB存储的是二进制数据，没有排序规则或字符集 TEXT有字符集和排序规则 BLOB等于SMALLBOLB，属于TINYBLOB，SMALLBLOB，MEDIUMBLOB，LONGBLOBTEXT等于SMALLTEXT，属于TINYTEXT，SMALLTEXT，MEDIUMTEXT，LONGTEXT 当太大的时候，InnoDB会将数据保存于“外部”存储区，在每个值的位置只保存指针 对于它们的排序不同于其他，只对于前面的一小部分字符进行排序 使用枚举类型代替字符串类型 MYSQL数据库中的枚举类型和集合类型 感觉对于固定的永远都不变的分类什么的，直接使用MySQL的枚举类型比较方便（比如，性别），但实际上的应用场景也不是很多。枚举类型在处理的时候是转化成数字了的，所以，在查找时采用整数主键对于查询的速度比较快 日期和时间MySQL最小时间粒度为秒（MariaDB支持微秒），但MySQL可以使用微秒进行临时计算。 DATETIME保存大范围的时间（从1001年到9999年）。与时区无关。 TIMESTAMP保存从1970.1.1以来的秒数（从1970年到2038年）。与时区有关。 总结通常尽量使用TIMESTAMP，因为其空间效率更高。 mysql5.6.4以后的版本，支持带毫秒、微妙的时间数据。使用DATETIME(6)、TIMESTAMP(6)、CURRENT_TIMESTAMP(6)既可以精确到秒后面6位了。查询方法1234SELECT DATE_FORMAT( create_time, '%Y-%m-%d %T.%f' ) AS createTimeStr FROM time_stu 标识符（identifier）选择哪个类型作为主键 整数类型通常是最好的选择 ENUM、SET不好。只适用于存储固定信息。而且内部使用整数存储，比较时转换为字符串 字符串类型避免使用字符串作为标识列。对于完全“随机”的字符串（如，MD5，SHA1，UUID产生的），这些值的取值范围过大，于是INSERT已经SELECT语句变得很慢。如果存储UUID，应移除 “-” 符号。更好的做法，用UNHEX()转换为16字节数字，并存储于BINARY(16)列中。检索时通过 HEX()还原 MySQL schema 设计中的陷阱 太多的列 太多的关联 全能的枚举防止过度使用枚举。修改枚举的值需要 ALTER TABLE操作 变相的枚举 Not Invent Here 的 NULL避免使用NULL，可以使用其他值来代替NULL。但不要过于极端。（MySQL会在索引中存储NULL值，而Oracle则不会） 范式与反范式范式 范式化的更新操作通常更快 修改是只需要修改更少的数据 范式化的表通常更小 很少有多余的数据意味着检索列表数据时更少需要DISTINCT或者GROUP BY]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>高性能MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能MySQL学习（一）]]></title>
    <url>%2F2018%2F02%2F09%2F%E9%AB%98%E6%80%A7%E8%83%BDMySQL%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[MySQL逻辑架构 最上层是大多数基于网络的客户端/服务器都有的。比如连接处理、授权、安全等。 第二层为MySQL服务器。包括SQL解析、分析、优化、缓存以及所有内置函数，所有跨存储引擎的功能的实现（存储过程、触发器、视图等）。 第三层为存储引擎。负责数据的存储和读取，例如InnoDB。存储引擎API包含几十个底层函数，用于执行“开始一个事物”、“根据主键提取一行记录”等操作。但存储引擎不会去解析SQL（InnoDB是例外，由于MySQL服务器本身没有实现外键，其会解析外键），不同存储引擎之间也不会相互通信。 并发控制读写锁 读锁，又称共享锁。相互之间不阻塞。多客户可以同时读取。 写锁，又称排他锁。一个写锁会阻塞其他写锁和读锁。 锁粒度每种MySQL存储引擎都可以实现自己的锁策略和锁粒度。 表锁MySQL中最基本的锁策略，开销最小。会锁住整张表。在特定场景，表锁可能有良好的性能。另外，写锁有比读锁更高的优先级，因此一个写锁请求可能会被插入到读锁队列前面。尽管存储引擎可以管理自己的锁，MySQL本身还是会使用各种有效的表锁实现不同的目的。例如，对于ALTER TABLE之类的使用表锁，而忽略存储引擎的锁机制。 行级锁可以最大程度地支持并发，同时，也带来了最大的锁开销。（例如InnoDB和XtarDB）行级锁只在存储引擎实现，而MySQL服务器层没有实现。 事务事务的ACID概念。ACID表示原子性（atomicity）、一致性（consistency）、隔离性（isolation）、持久性（durability）。 隔离级别 READ UNCOMMITTED（未提交读）事务中的修改，即使没有提交，对其他事务也都是可见的（脏读）。实际很少用。 READ COMMITTED（提交读）大多数数据库默认的隔离级别（Sql Server，Oracle。但MySQL不是）。一个事务开始时，只能“看见”已经提交的事务所做的修改。也称为不可重复读，执行两次同样的查询，结果可能不同。singo拿着工资卡去消费，系统读取到卡里确实有2000元，而此时她的老婆也正好在网上转账，把singo工资卡的2000元转到另一账户，并在 singo之前提交了事务，当singo扣款时，系统检查到singo的工资卡已经没有钱，扣款失败，singo十分纳闷，明明卡里有钱，怎么没了。 REPEATABLE READ（可重复读）MySQL默认隔离级别。存在幻读问题。即指，在某个事物在读取某个范围内的记录时，另外一个事务又在该范围插入了新的纪录，当之前的事务再次读取该范围的记录时，会产生换行。InnoDB和XtraDB通过多版本并发控制（MVCC）解决了此问题。singo的老婆工作在银行部门，她时常通过银行内部系统查看singo的信用卡消费记录。有一天，她正在查询到singo当月信用卡的总消费金额 （select sum(amount) from transaction where month = 本月）为80元，而singo此时正好在外面胡吃海塞后在收银台买单，消费1000元，即新增了一条1000元的消费记录（insert transaction … ），并提交了事务，随后singo的老婆将singo当月信用卡消费的明细打印到A4纸上，却发现消费总额为1080元，singo的老婆很诧异，以为出 现了幻觉，幻读就这样产生了。 SERIALIZABLE（可串行化）最高隔离级别。强制事务串行执行。实际中很少用。 死锁对于死锁的解决是在存储引擎。解决死锁的方法： 检测死锁的循环依赖 当查询的时间达到锁等待超时的设定后放弃锁请求，但这种方式通常不太好。InnoDB目前的处理方式是，将持有最少行级排他锁的事务进行回滚。 事务日志可以帮助提高事务的效率。存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到之久在硬盘的事务日志中，而不用每次都将修改数据本身持久到磁盘。日志持久之后，内存中被修改的数据在后台可以慢慢刷回到磁盘。 多版本并发控制 MySQL InnoDB引擎 MVCC并发控制 只在RC和RR隔离级别工作。因为RU总是读取最新的数据行，而SERIALIZABLE则会对所有读取的行都加锁。 MySQL的存储引擎除非万不得已，否则不要混合使用多种存储引擎 InnoDBMySQL默认事务型引擎。用于处理大量的短期事务（大多正常提交，很少会被回滚）。可自动崩溃恢复。InnoDB采用MVCC支持高并发，并通过 Next-key Lock（Next-key Lock = Record Lock + Gap Lock）策略防止幻读的出现。间隙锁使InnoDB不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。但是MVCC是解决幻读的，Next-key Lock也是解决幻读的，两者之间的的关系还搞得不太清楚。 MVCC和Next-key Lock的关系 MyISAMMySQL 5.1及其之前的默认引擎。不支持事务和行级所，崩溃后无法安全恢复。相对于InnoDB，支持全文索引，支持地理空间搜索。 例子日志型应用对于插入的速度要求很高，使用MyISAM或者Archive比较合适，它们开销低，且插入速度非常快。如果要对日志进行报表分析，生成报表的SQL很可能导致插入的效率明显降低。解决方法： 利用MySQL内置的复制方案将数据复制到备库上，在备库上执行查询 将日志的记录按照时间分表（例如：web_logs_2012_01）。这样可以在已经没有插入操作的历史表上做频繁的查询操作。 表引擎的修改 方法1：ALTER TABLE 1mysql&gt; ALTER TABLE mytable ENGINE = InnoDB 存在问题：需要执行很长时间。MySQL会按行将数据从原表复制到一张新表中，会消耗大量I/O能力，同时原表上会加上读锁。因此，在繁忙表上要小心。 方法2：导入与导出手动导出原表，手动修改再导入 方法3：创建与查询不需要导出整个表的数据，先创建一个新的存储引擎的表，在利用INSERT…SELECT完成 123CREATE TABLE innodb_table LIKE myisam_table;ALTER TABLE innodb_table ENGINE = InnoDB;INSERT INTO innodb_table SELECT * FROM myisam_table; 数据量很大，可以进行分批处理，避免大事物产生过多的undo123START TRANSACTION;INSERT INTO innodb_table SELECT * FROM myisam_table WHERE id BETWEEN x AND y;COMMIT; 附录幻读 关于幻读，可重复读的真实用例是什么? 由于MySQL通过MVCC解决了幻读，所以，对于MySQL的幻读并不是对于范围数据的修改产生的。如下：1234users： id 主键1、T1：select * from users where id = 1;2、T2：insert into `users`(`id`, `name`) values (1, 'big cat');3、T1：insert into `users`(`id`, `name`) values (1, 'big cat'); &emsp;&emsp;T1 ：主事务，检测表中是否有 id 为 1 的记录，没有则插入，这是我们期望的正常业务逻辑。&emsp;&emsp;T2 ：干扰事务，目的在于扰乱 T1 的正常的事务执行。&emsp;&emsp;在 RR 隔离级别下，1、2 是会正常执行的，3 则会报错主键冲突，对于 T1 的业务来说是执行失败的，这里 T1 就是发生了幻读，因为T1读取的数据状态并不能支持他的下一步的业务，见鬼了一样。&emsp;&emsp;在 Serializable 隔离级别下，1 执行时是会隐式的添加 gap 共享锁的，从而 2 会被阻塞，3 会正常执行，对于 T1 来说业务是正确的，成功的扼杀了扰乱业务的T2，对于T1来说他读取的状态是可以拿来支持业务的。&emsp;&emsp;所以 mysql 的幻读并非什么读取两次返回结果集不同，而是事务在插入事先检测不存在的记录时，惊奇的发现这些数据已经存在了，之前的检测读获取到的数据如同鬼影一般。&emsp;&emsp;这里要灵活的理解读取的意思，第一次select是读取，第二次的 insert 其实也属于隐式的读取，只不过是在 mysql 的机制中读取的，插入数据也是要先读取一下有没有主键冲突才能决定是否执行插入。&emsp;&emsp;不可重复读侧重表达 读-读，幻读则是说 读-写，用写来证实读的是鬼影。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>高性能MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Data Query]]></title>
    <url>%2F2018%2F01%2F26%2FSpring-Data-Query%2F</url>
    <content type="text"><![CDATA[Spring Data JPA 2.0.3 Reference 在看《SpringData实战》的过程中发现居然不用写sql，定义一个Repository接口，写上几个接口方法名，然后，就能使用这些接口方法了。感觉很是厉害！！就看了下SpringData的官方文档，学习了下。 Query creation对于List findByEmailAddressAndLastname(EmailAddress emailAddress, String lastname)Spring会把find…By, read…By, query…By, count…By和get…By这些前缀去掉，而只处理之后的字符串。例如，以下方法名，在Spring看来，就是EmailAddressAndLastname而已。而And和Or都被作为保留关键字，并起到SQL中AND和OR的作用。当然，你定义的Person对象，必须含有emailAddress和lastname属性，否则Spring找不到这些属性就会出错。12345678910111213141516171819interface PersonRepository extends Repository&lt;User, Long&gt; &#123; List&lt;Person&gt; findByEmailAddressAndLastname(EmailAddress emailAddress, String lastname); // Enables the distinct flag for the query List&lt;Person&gt; findDistinctPeopleByLastnameOrFirstname(String lastname, String firstname); List&lt;Person&gt; findPeopleDistinctByLastnameOrFirstname(String lastname, String firstname); // Enabling ignoring case for an individual property // 无视大小写 List&lt;Person&gt; findByLastnameIgnoreCase(String lastname); // Enabling ignoring case for all suitable properties List&lt;Person&gt; findByLastnameAndFirstnameAllIgnoreCase(String lastname, String firstname); // Enabling static ORDER BY for a query // 排序 List&lt;Person&gt; findByLastnameOrderByFirstnameAsc(String lastname); List&lt;Person&gt; findByLastnameOrderByFirstnameDesc(String lastname);&#125; 需要知道的几点： 除了AND, OR之外，也支持Between, LessThan, GreaterThan, Like。这些运算符的实际效果取决于使用的底层数据库 IgnoreCase用于无视特定属性的大小写，AllIgnoreCase用于无视所有的支持无视操作的属性（一般是String）。是否有效实际上还是取决于数据库。 Property expressions如果Person有Address属性，而Address有ZipCode属性，那么以下方法名仍能生成你心里想着的query。过程如下： Spring在Person里找AddressZipCode属性，没找到 Spring按驼峰从右往左分割，第一次，它分割为AddressZip和Code，但还是没找到AddressZip属性。 Spring将分割点左移，分割为Address和ZipCode，它在Person找到了Address属性，又在Address中找到了ZipCode属性，成功。 1List&lt;Person&gt; findByAddressZipCode(ZipCode zipCode); 以上仍可能出错，例如Person有Address，AddressZip属性，而Address有ZipCode属性，AddressZip没有Code属性，那么Spring匹配进AddressZip里边，结果没找到Code，就失败。更好的方法是用下划线，下划线被Spring保留为分隔符，Address_ZipCode直接被分割成Address和ZipCode。既然如此，也要求我们在定义Person，Address类时，属性名不要使用下划线，而使用纯正的驼峰命名。1List&lt;Person&gt; findByAddress_ZipCode(ZipCode zipCode); Special parameter handling1234567Page&lt;User&gt; findByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findByLastname(String lastname, Pageable pageable);List&lt;User&gt; findByLastname(String lastname, Sort sort);List&lt;User&gt; findByLastname(String lastname, Pageable pageable); 第一个函数允许传入一个Pageable来动态的分页查询。一个Page知道可用元素和页面的总数。它通过触发一个计数查询来计算总的数量。这就可以在一定程度上会占用很大的内存，这个时候就可以用Slice。Slice仅仅知道是否是否还有下一个Slice。从类的关系上来说，Slice是Page的子类。 Limiting query results查询的结果的数量可以用first或者top来限制，这两个是等价的。1234567891011User findFirstByOrderByLastnameAsc();User findTopByOrderByAgeDesc();Page&lt;User&gt; queryFirst10ByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findTop3ByLastname(String lastname, Pageable pageable);List&lt;User&gt; findFirst10ByLastname(String lastname, Sort sort);List&lt;User&gt; findTop10ByLastname(String lastname, Pageable pageable); limiting expressions同样支持Distinct关键词。当将结果限制到一个的时候，Optional是支持的。limiting query同Sort相结合可以进行K最小或者K最大的查询。 Streaming query results1234567@Query("select u from User u")Stream&lt;User&gt; findAllByCustomQueryAndStream();Stream&lt;User&gt; readAllByFirstnameNotNull();@Query("select u from User u")Stream&lt;User&gt; streamAllPaged(Pageable pageable); 返回结果可以是Java8的Stream，但要注意要关闭流，建议使用Java7的try-with-resources block123try (Stream&lt;User&gt; stream = repository.findAllByCustomQueryAndStream()) &#123; stream.forEach(…);&#125; 并不是所有的Spring Data modules都支持Stream的返回值 Async query results可以很便捷的实现异步的操作1234567891011// Use java.util.concurrent.Future as return type.@AsyncFuture&lt;User&gt; findByFirstname(String firstname);// Use a Java 8 java.util.concurrent.CompletableFuture as return type.@AsyncCompletableFuture&lt;User&gt; findOneByFirstname(String firstname);//Use a org.springframework.util.concurrent.ListenableFuture as return type.@AsyncListenableFuture&lt;User&gt; findOneByLastname(String lastname);]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>SpringData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot JPA]]></title>
    <url>%2F2018%2F01%2F26%2FSpringBoot-JPA%2F</url>
    <content type="text"><![CDATA[单元测试的时候，报no session的错需要在单元测试类上面添加注解1@Transactional 也可以继承单元测试类1AbstractTransactionalJUnit4SpringContextTests 单元测试的时候，数据库会自动回滚在使用单元测试的时候，发现对于数据库的插入、更新等操作在单元测试程序结束后会自动回滚在单元测试类上面添加 @Rollback(false) 注解1234567@RunWith(SpringRunner.class)@SpringBootTest@Transactional@Rollback(false)public class CustomerRepositoryTest &#123; //...&#125; 在将hibernate查出来的类以json格式返回的时候，报lazyInit错误对于open session in view，SpringBoot已经默认配置为开启了，不用再多余的配置了 (open-in-view: true) 可以使用配置1234spring: jackson: serialization: fail-on-empty-beans: false 的方式解决，但是出来的json字符串里面会有多余的 “handler”: {}, “hibernateLazyInitializer”: {} 字段 更好的方法。jackson官方有为hibernate提供的库，以解决懒加载的问题12345&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-hibernate5&lt;/artifactId&gt; &lt;version&gt;2.9.3&lt;/version&gt;&lt;/dependency&gt; 1234567@Beanpublic Module module() &#123; Hibernate5Module module = new Hibernate5Module(); module.disable(Hibernate5Module.Feature.USE_TRANSIENT_ANNOTATION); module.enable(Hibernate5Module.Feature.FORCE_LAZY_LOADING); return module;&#125; lombok导致死循环类相互之间有相互的引用，调用lombok自动生成的 toString() 或者 hashCode() 方法会导致死循环。 Entity之间有循环引用的时候，导致转换成json字符串的时候死循环（JsonView）可以使用JsonView自定义要转成json的字段属性，个人觉得这是一个类似于DTO的方法Latest Jackson integration improvements in Spring12345678910111213141516171819202122232425262728293031323334353637383940public class View &#123; public interface Summary &#123; &#125; public interface SummaryWithDetail extends Summary &#123; &#125;&#125;@Getter@Setter@Entity@Builder@NoArgsConstructor@AllArgsConstructorpublic class Customer &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @JsonView(View.Summary.class) private Long id; @JsonView(View.Summary.class) private String firstName; @JsonView(View.Summary.class) private String lastName; @JsonView(View.SummaryWithDetail.class) @OneToMany(cascade = CascadeType.ALL, mappedBy = "customer") private Set&lt;Address&gt; addressSet;&#125;@RestController@RequestMapping("/")public class HomeController &#123; @JsonView(View.SummaryWithDetail.class) @GetMapping("/cus") public Customer customer()&#123; return customerService.get(4L); &#125;&#125; SpringBoot打印hibernate的sql语句方法一SpringBoot自带，但是只能显示语句，不能显示参数123spring: jpa: show-sql: true 方法二使用log4jdbc。其可以显示底层执行的sql语句。还会显示sql执行的时间pom.xml 文件12345&lt;dependency&gt; &lt;groupId&gt;com.googlecode.log4jdbc&lt;/groupId&gt; &lt;artifactId&gt;log4jdbc&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt; application.yml 文件1234spring: datasource: url: jdbc:log4jdbc:mysql://localhost:3306/springdata driver-class-name: net.sf.log4jdbc.DriverSpy]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>SpringData</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate遗忘知识点记录]]></title>
    <url>%2F2018%2F01%2F24%2FHibernate%E9%81%97%E5%BF%98%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[怎么级联保存/更新可以设置 ‘cascade’ 属性。一般在 one-to-many 比较常见的需求，对于one-to-many在 \&lt;set> 标签中设置1234&lt;set name="ProductModelSet" lazy="true" inverse="true" cascade="save-update"&gt; &lt;key column="catalog_id"/&gt; &lt;one-to-many class="com.lk.model.ProductModel"/&gt; &lt;/set&gt; boolean属性怎么配置hibernate中boolean与sql的关系如下：12345hibernate映射类型 java类型 标准sql类型true_false boolean/Boolean char(1)yes_no boolean/Boolean char(1)byte boolean/Booleannumber(1) xml格式123&lt;property name="tag" column="tag" type="yes_no"/&gt;&lt;property name="tag" column="tag" type="true_false"/&gt;&lt;property name="tag" column="tag" type="byte"/&gt; annotation注解123456@org.hibernate.annotations.Type(type="yes_no")//或@org.hibernate.annotations.Type(type="true_false")//或@org.hibernate.annotations.Type(type="byte")private boolean tag; 如何插入的时候不插入为NULL的，更新的时候不更新为NULL的设置 dynamic-update 和 dynamic-insert 属性123&lt;class name="catalog" table="catalog" dynamic-update="true" dynamic-insert="true"&gt;&lt;/class&gt; Inverse和CascadeInverse：inverse的真正作用就是指定由哪一方来维护之间的关联关系。负责控制关系，默认为false，也就是关系的两端都能控制，但这样会造成一些问题，更新的时候会因为两端都控制关系，于是重复更新。一般来说有一端要设为true。Cascade：负责控制关联对象的级联操作。包括更新、删除等，也就是说对一个对象进行更新、删除时，其它对象也受影响，比如我删除一个对象，那么跟它是多对一关系的对象也全部被删除。举例说明区别：删除“一”那一端一个对象O的时候，如果“多”的那一端的Inverse设为true，则把“多”的那一端所有与O相关联的对象外键清空；如果“多”的那一端的Cascade设为Delete，则把“多”的那一端所有与O相关联的对象全部删除。 设置createTime和updateTime12345678910111213@Getter@Setter@MappedSuperclasspublic class TimeEntity extends AbstractEntity&#123; @CreationTimestamp @Temporal(TemporalType.TIMESTAMP) private Date createTime; @UpdateTimestamp @Temporal(TemporalType.TIMESTAMP) private Date updateTime;&#125; 注解@Temporal可以设置java.util.Date or java.util.Calendar所映射的类型。 TemporalType.DATE 对应MySQL中的 date TemporalType.TIME 对应MySQL中的 time TemporalType.TIMESTAMP 对应MySQL中的 datetime]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[np-array]]></title>
    <url>%2F2018%2F01%2F10%2Fnp-array%2F</url>
    <content type="text"><![CDATA[np.array array(object, dtype=None, copy=True, order=’K’, subok=False, ndmin=0) See Also：empty, empty_like, zeros, zeros_like, ones, ones_like, full, full_like NumPy的数组中比较重要ndarray对象属性有 ndarray.ndim数组的维数（即数组轴的个数），等于秩。最常见的为二维数组（矩阵）。 ndarray.shape数组的维度。为一个表示数组在每个维度上大小的整数元组。例如二维数组中，表示数组的“行数”和“列数”。ndarray.shape返回一个元组，这个元组的长度就是维度的数目，即ndim属性。 ndarray.size数组元素的总个数，等于shape属性中元组元素的乘积。 ndarray.dtype表示数组中元素类型的对象，可使用标准的Python类型创建或指定dtype。另外也可使用前一篇文章中介绍的NumPy提供的数据类型。 ndarray.itemsize数组中每个元素的字节大小。例如，一个元素类型为float64的数组itemsiz属性值为8(float64占用64个bits，每个字节长度为8，所以64/8，占用8个字节），又如，一个元素类型为complex32的数组item属性为4（32/8）。 ndarray.data包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。 参数 object : array_likeAn array, any object exposing the array interface（暴露array接口的object）, an object whose __array__ method returns an array（array方法返回array类型的object）, or any (nested) sequence dtype : data-type（array的数据类型）, optionalThe desired data-type for the array. 如果没有被指定，会自动确定需要的最小的数据类型 copy : bool, optional默认为true。如果为true，则object将会被复制。操作为object的副本 order : {‘K’, ‘A’, ‘C’, ‘F’}, optionalSpecify the memory layout of the array. 默认为K subok : bool, optionalIf True, then sub-classes will be passed-through默认为false。the returned array will be forced to be a base-class array ndmin : int, optional数组的最小维度 例子创建12&gt;&gt;&gt; np.array([1, 2, 3])array([1, 2, 3]) Upcasting12&gt;&gt;&gt; np.array([1, 2, 3.0])array([ 1., 2., 3.]) More than one dimension123&gt;&gt;&gt; np.array([[1, 2], [3, 4]])array([[1, 2], [3, 4]]) Minimum dimensions 2:12&gt;&gt;&gt; np.array([1, 2, 3], ndmin=2)array([[1, 2, 3]]) Type provided:12&gt;&gt;&gt; np.array([1, 2, 3], dtype=complex)array([ 1.+0.j, 2.+0.j, 3.+0.j]) Data-type consisting of more than one element:123&gt;&gt;&gt; x = np.array([(1,2),(3,4)],dtype=[('a','&lt;i4'),('b','&lt;i4')])&gt;&gt;&gt; x['a']array([1, 3]) Creating an array from sub-classes:1234567&gt;&gt;&gt; np.array(np.mat('1 2; 3 4'))array([[1, 2], [3, 4]])&gt;&gt;&gt; np.array(np.mat('1 2; 3 4'), subok=True)matrix([[1, 2], [3, 4]])]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow官方mnist基础例子学习]]></title>
    <url>%2F2017%2F12%2F30%2FTensorflow%E5%AE%98%E6%96%B9mnist%E5%9F%BA%E7%A1%80%E4%BE%8B%E5%AD%90%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[官方文档中文文档 (略微有点出入) tf.placeholder1tf.placeholder(dtype, shape=None, name=None) 此函数可以理解为形参，用于定义过程，在执行的时候再赋具体的值参数： shape数据形状。默认是None，就是一维值，也可以是多维，比如123[2, 3] #表示2行3列[None, 3] #表示列是3，行不定[10] #表示1行10列 tf.placeholder 与 tf.Variable tf.Variable：主要在于一些可训练变量 (trainable variables)，比如模型的权重 (weights，W)或者偏执值 tf.placeholder：用于得到传递进来的真实的训练样本。 reduce_sum的reduction_indices参数[3, 3]竖起来过来显示是为了说明reduction_indices=[1, 0]的过程中维度的信息是一直保留着的，所以它并不是一个列向量，亦即它不是[ [3], [3] ]，它本质还是[ 3, 3 ]，这也是为什么你在仅仅使用reduction_indices=1的时候，打印出来的是[ 3, 3 ]的原因。 代码中y = tf.matmul(x, W) + b维度不同怎么可以相加《Deep Learning》中文版第2.1节原文12345678910# 矩阵 None * 784x = tf.placeholder(tf.float32, [None, 784])# 矩阵 784 * 10W = tf.Variable(tf.zeros([784, 10]))# 矩阵 1 * 10b = tf.Variable(tf.zeros([10]))# x * W = None * 10的矩阵# 这里 None*10 的矩阵加上 1*10 的矩阵实际上是 None*10 每一行加上b# 所以最终计算出来的结果是 None*10y = tf.matmul(x, W) + b]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python函数]]></title>
    <url>%2F2017%2F12%2F30%2FPython%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数、关键字参数。 默认参数1def power(x, n=2): 默认参数必须指向不变对象！ 错误示范123def add_end(L=[]): L.append('END') return L 1234&gt;&gt;&gt; add_end()['END', 'END']&gt;&gt;&gt; add_end()['END', 'END', 'END'] 正确写法12345def add_end(L=None): if L is None: L = [] L.append('END') return L 原因：Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。 可变参数可变参数允许传入0个或任意个参数，这些可变参数在函数调用时自动组装为一个tuple12345def calc(*numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 调用123calc(1, 2)#在list或tuple前面加一个*号，把list或tuple的元素变成可变参数calc(*[1, 2, 3]) 关键字参数关键字参数允许传入0个或任意个含参数名的参数，这些关键字参数在函数内部自动组装为一个dict12def person(name, age, **kw): print('name:', name, 'age:', age, 'other:', kw) 123456&gt;&gt;&gt; person('Michael', 30)name: Michael age: 30 other: &#123;&#125;&gt;&gt;&gt; person('Bob', 35, city='Beijing')name: Bob age: 35 other: &#123;'city': 'Beijing'&#125;&gt;&gt;&gt; person('Adam', 45, gender='M', job='Engineer')name: Adam age: 45 other: &#123;'gender': 'M', 'job': 'Engineer'&#125; 123&gt;&gt;&gt; extra = &#123;'city': 'Beijing', 'job': 'Engineer'&#125;&gt;&gt;&gt; person('Jack', 24, **extra)name: Jack age: 24 other: &#123;'city': 'Beijing', 'job': 'Engineer'&#125; **extra表示把extra这个dict的所有key-value用关键字参数传入到函数的**kw参数，kw将获得一个dict，注意kw获得的dict是extra的一份拷贝，对kw的改动不会影响到函数外的extra。 命名关键字参数12def person(name, age, *, city, job): print(name, age, city, job) 调用必须传入参数名12&gt;&gt;&gt; person('Jack', 24, job='Engineer', city='Beijing')Jack 24 Beijing Engineer 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了12def person(name, age, *args, city, job): print(name, age, args, city, job) 例子123456def f2(a, b, c=0, *, d, **kw): # 位置参数，默认参数，命名关键字参数，关键字参数 print('a =', a, 'b =', b, 'c =', c, 'd =', d, 'kw =', kw)f2(1, 2, d=99, ext=None)# a = 1 b = 2 c = 0 d = 99 kw = &#123;'ext': None&#125;]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python基础]]></title>
    <url>%2F2017%2F12%2F30%2FPython%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[基本数据结构List1list = ['Michael', 'Bob', 'Tracy'] List的拷贝1234a = [1, 2]b = aa[0] = 5print(b) # [5, 2] 1234a = [1, 2]b = a[:]a[0] = 5print(b) # [1, 2] 其实，个人觉得更好的方式是使用 copy.copy() 方法和 copy.deepcopy() 方法（经过测试 a[:] 的方式类似于浅拷贝）。对于 copy.copy() 方法和 copy.deepcopy() 方法的自定义可以重写类的 __copy__ 和 __deepcopy__ 方法 Tuple不可变1234tuple = ('Michael', 'Bob', 'Tracy')#只有1个元素的tuple定义时必须加一个逗号,来消除歧义tuple = ('Michael',) Dict就是map1d = &#123;'Michael': 95, 'Bob': 75, 'Tracy': 85&#125; 判断key存不存在1234567891011&gt;&gt;&gt; 'Thomas' in dFalse#或者&gt;&gt;&gt; d.__contains__('Thomas')False#或者&gt;&gt;&gt; d.get('Thomas')&gt;&gt;&gt; d.get('Thomas', -1)-1 Set1s = set([1, 2, 3])]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
</search>
